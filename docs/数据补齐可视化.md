# 数据补齐可视化.md

> 第二版（详细可落地方案）：针对 11 项问题逐条展开，全面对齐现有 app 目录与 Postgres。全链路“秒级”处理，含表结构、算法公式、API 契约、代码示例与任务安排。压力量纲统一 MPa，扬程计算在公式中使用 Δp(MPa)×1e6/(ρg)。

## 导读与重组说明（不丢内容）

- 本次整理目标：
  - 在不删除任何原始内容的前提下，新增“数据库函数提效”章节，并在相关章节加入引用，指导在可视化/查询中优先使用数据库函数以提升效率。
  - 提供“阅读指引 + 推荐顺序”，帮助你快速定位关键方案与落地处。
- 内容保留说明：下方所有原始章节（A.\*、1–11、附等）均完整保留；本节仅新增导读与提效章节，并添加少量跨章节提示。

### 推荐阅读顺序（重组视图）

1. 数据库函数提效（强烈推荐先读）
1. 0. 总览与关键约定（单位、时间粒度、可视化契约）
1. A. 判定规则与方案选择（A1–A5，一页清晰版）
1. 1–3. 基础算法与策略（FFILL/MEAN/REG 与决策树/评分）
1. 四–七. 工程化实现（数据补齐/计算/优化流程与表结构）
1. 八–十. 可视化/API/性能与监控
1. 十一与附. 风险回退、与仓库对齐点、代码示例、任务拆解

______________________________________________________________________

## 数据库函数提效（强烈推荐接入）

为提升可视化与数据读取效率，建议在“按时间范围读取设备/站点指标”的场景中，优先使用以下数据库函数（JSONB 整形、下推分页、索引友好）：

- public.get_device_metrics_by_time_range(device_id bigint, start_ts timestamptz, end_ts timestamptz, limit integer)
  - 返回：(record_timestamp timestamptz, metrics_data jsonb, total_records bigint)
  - 适用：单设备时序查询/可视化回放
- public.get_station_devices_metrics_by_time_range(station_id bigint, start_ts timestamptz, end_ts timestamptz, limit integer)
  - 返回：(record_timestamp timestamptz, metrics_data jsonb, total_records bigint)
  - 适用：单站点多设备同时回放（多设备指标合并为一条 JSONB）

相较“generate_series + 左连接 fact_measurements”的手写 SQL，这两类函数具备：

- 将同一时刻多指标打包成 JSONB，显著减少传输/解析开销；
- 结合物化/聚合视图与索引，具备更优执行计划；
- limit 参数支持数据库端分页/截断，避免 API 层 N+1 与大结果集搬运。

参考：docs/数据库函数参考.md（包含签名速览）。

### Python 网关封装（可直接调用）

- app.adapters.db.gateway.get_device_metrics_by_time_range(conn, device_id, start_utc, end_utc, metric_ids: list\[int\]|None=None, granularity: str='auto') → list\[dict\]
- app.adapters.db.gateway.get_station_devices_metrics_by_time_range(conn, station_id, start_utc, end_utc, device_ids: list\[int\]|None=None, metric_ids: list\[int\]|None=None, granularity: str='auto') → list\[dict\]

示例（API 内部已采用，中文注释）：

```python
# 单设备（按时间范围）高效查询
def fetch_device_metrics(conn, device_id, start_ts, end_ts, limit=2000):
    sql = """
        SELECT record_timestamp, metrics_data, total_records
        FROM public.get_device_metrics_by_time_range(%(device_id)s, %(start_ts)s, %(end_ts)s, %(limit)s)
    """
    params = {"device_id": device_id, "start_ts": start_ts, "end_ts": end_ts, "limit": int(limit)}
    with conn.cursor() as cur:
        cur.execute(sql, params)
        return cur.fetchall()
```

### 在本文中的落位（已加提示/对齐）

- 3）与现有网关/报表函数的结合：新增“优先使用 public.get\_\*\_by_time_range，跨度大再用 reporting.get_metrics_auto_multi”。
- 七、只读 API：说明已有端点内部使用上述函数，统一返回包裹不变。
- 10. 秒级处理：补充“前端秒级回放优先用 get\_\*\_by_time_range，避免 API 层二次拼装”。

______________________________________________________________________

## 0. 总览与关键约定（整合 jjjj.md/jjj1.md 核心）

- 变量与单位（与 jjjj.md 一致）
  - 压力 p：MPa（不存 Pa）；流量 Q：m³/h；功率 P：kW；频率 f：Hz；扬程 H：m
  - H≈((p_out − p_in)×1e6)/(ρ·g)；η=(ρ·g·(Q/3600)·H)/(P×1000)
  - 并联分摊（首选）：w_i=(P_i^α·f_i^β)/Σ(P_j^α·f_j^β)，Q_i=C_Q·(Q_total·w_i)+b_Q
- 秒级粒度：ts_bucket 按秒对齐；所有检测、补齐、计算、优化均“1 秒一笔”。
- 可视化契约（与 jjj1.md 一致）：所有步骤保存 runs/steps，steps.rules_json 记录“阈值命中明细”\[{name,expr,left,right,pass}\]；右上角提供 trace_id/trace_url。

______________________________________________________________________

## A. 指标补齐“判定规则”与“方案选择”一页清晰版（重点回答你的两个问题）

A1. 需要补齐的“指标集合”如何判定？

- 来源与范围（强约束）：只在 dim_metric_config 中标记可补齐的指标上进行（is_imputable=true）。
  - 建议的初始集合：
    - 流量类：main_pipeline_flow_rate、pump_flow_rate（关键，后续优化也依赖）
    - 压力类：main_pipeline_outlet_pressure、main_pipeline_inlet_pressure、pump_inlet_pressure、pump_outlet_pressure（无泵出口时允许用替代）
    - 电参/频率：pump_active_power、pump_frequency（仅短缺口 FFILL，原则上作为“自变量”，大缺口不强制补）
- 时间与设备范围：按站点/设备在秒级时间轴上补齐（ts_bucket=秒）。
- 缺失/异常识别：
  - 缺失：fact_measurements 无记录（station_id, device_id, metric_id, ts_bucket）
  - 异常：越界、跳变、MAD 三类（按每个 metric_key 的阈值）
- 触发集合 G 构造（SQL 简化）：

```
WITH sec AS (
  SELECT generate_series($start::timestamptz,$end::timestamptz,'1 second') ts
), targets AS (
  SELECT d.id AS device_id, m.id AS metric_id, ds.id AS station_id
  FROM dim_devices d JOIN dim_metric_config m ON m.is_imputable
  JOIN dim_stations ds ON ds.id=d.station_id
  WHERE ($station_id IS NULL OR ds.id=$station_id)
)
SELECT t.station_id, t.device_id, t.metric_id, s.ts AS ts_bucket
FROM targets t
CROSS JOIN sec s
LEFT JOIN fact_measurements f
  ON f.station_id=t.station_id AND f.device_id=t.device_id AND f.metric_id=t.metric_id AND f.ts_bucket=s.ts
WHERE f.ts_bucket IS NULL  -- 缺失
   OR (f.value<cfg.bounds_min OR f.value>cfg.bounds_max OR abs(f.value-lag_val)>cfg.jump_thr OR is_mad_outlier)  -- 异常（伪）
ORDER BY ts_bucket;
```

- 阈值来源：每个 metric_key 的策略配置（见“策略表 DDL”）。

A2. 对于“需要补齐的指标”，如何选择具体计算方案？（决策树 + 每类指标默认策略）

- 决策树（统一）：
  1. 若缺口长度 L ≤ ffill_limit_sec 且存在有效前值 → FFILL
  1. 否则 若 L ≤ mean_limit_sec 且邻域覆盖率≥coverage_min → MEAN
  1. 否则 若 REG 模型可用且质量达标（R²≥r2_min 且样本≥n_min）→ REG
  1. 否则 放弃补齐（写入告警与 completion_audit）
- 指标类别默认策略（可被策略表覆盖）：
  - 流量类（Q）：优先 REG（若有 P、f 协变量且模型质量好），否则 FFILL→MEAN。说明：Q 与 P、f 强相关。
  - 压力类（p）：优先 FFILL（小缺口时最稳），其次 MEAN；REG 需谨慎（关系弱/偏置大）。
  - 电参/频率（P、f）：仅小缺口 FFILL；中/大缺口不补（作为自变量，避免放大误差）。
- 评分（可选）：FFILL/MEAN/REG 产出候选后，按 score=w1·数据覆盖 + w2·误差估计 + w3·物理一致性 选更优；
  - 物理一致性检查：Q≥0、H≥0、η∈\[0,1\]（H、η公式见 jjjj.md）。不满足即降级/放弃。

A3. 伪代码（简洁）

```
for (sid,did,mid,ts) in G:  # 需要补齐的点
  pol = load_policy(mid, sid, did)
  gap = get_gap_length(did, mid, ts)
  cand = []
  if gap<=pol.ffill_limit and has_prev_value(did,mid,ts):
      cand.append(('FFILL', val_prev, conf_ffill(gap,pol)))
  if gap<=pol.mean_limit and window_coverage(did,mid,ts)>=pol.coverage_min:
      cand.append(('MEAN', val_mean_window(ts), conf_mean(...)))
  if model_available(mid,sid,did) and model_quality(mid)>=pol.r2_min:
      x = features(P(ts), f(ts), ...)
      cand.append(('REG', model_predict(mid,x), conf_reg(...)))
  method,val,conf = select_best(cand, physics_guard=True)
  if method is None:
      audit_skip(...); continue
  upsert_fact(ts, sid,did,mid, val, hint=f"imputed_{method}")
  write_completion_audit(..., before/after/method/conf,...)
```

A4. “策略表”DDL（决定“哪些指标需要补齐”与“如何选方案”）

```
create table if not exists completion_metric_policy (
  metric_id int primary key references dim_metric_config(id),
  is_imputable boolean default true,         -- 是否纳入补齐
  category text check (category in ('flow','pressure','power','freq','other')),
  bounds_min double precision null,          -- 越界阈值（异常判定）
  bounds_max double precision null,
  jump_thr double precision null,            -- 跳变阈值（同单位）
  ffill_limit_sec int default 120,           -- FFILL 上限秒
  mean_limit_sec int default 600,            -- MEAN 上限秒
  coverage_min double precision default 0.5, -- MEAN 需要的邻域覆盖率
  reg_r2_min double precision default 0.6,   -- REG 质量门槛
  reg_n_min int default 200,                 -- REG 训练最小样本
  fallback_order text[] default '{FFILL,MEAN,REG}'
);
-- 设备/站点级覆盖（可选）：按需要引入 completion_metric_policy_override(metric_id, station_id, device_id, ...)
```

A5. 默认参数建议（可被策略覆盖）

- ffill_limit_sec：流量 180s、压力 120s、功率/频率 60s
- mean_limit_sec：流量 600s、压力 600s
- reg_r2_min：流量 0.7、压力 0.5
- coverage_min：0.5；jump_thr 与 bounds\_\* 按 metric_key 业务值配置

（以上为“判定”与“方案选择”的单独清晰版，后续章节继续保留详细表与全链路说明）

## 1. 数据补齐触发机制（判定需要补齐的时间点/设备/指标）

目标：在秒级时间轴上识别缺口与异常点，确定“需要补齐”的集合 G={(device_id, metric_id, ts_bucket)}。

- 1.1 关注指标集合 S（可配）：
  - 来自 dim_metric_config.metric_key，建议初始包含：
    - main_pipeline_flow_rate、main_pipeline_outlet_pressure、main_pipeline_inlet_pressure
    - pump_active_power、pump_frequency、pump_inlet_pressure、pump_outlet_pressure（若无用替代）
- 1.2 缺失判定（必选）：
  - 以 fact_measurements 为准：同一 (station_id, device_id, metric_id, ts_bucket) 不存在记录即为缺失
  - SQL 检测窗口 \[T−W, T)：
    - 先生成连续秒序列，再左连接 fact_measurements，NULL 即缺失
- 1.3 异常值判定（可选）：
  - 规则：
    - 越界：值\<0 或 >物理上限（按 metric_key 配置）
    - 跳变：|x\[t\]-x\[t-1\]| > δ_jump（按每项配置）
    - MAD 异常：|x- median| > k·MAD（k=3）
  - 异常值按“需要补齐”处理（即纳入 G），并记录 reason
- 1.4 门控/阈值：
  - 最大缺口长度 L_max（秒）：超过则放弃补齐，仅记录告警
  - 单批次上限 N_max：防止一次性补齐过多，超限分批处理

示例 SQL（检测某设备某指标在 1 分钟窗口缺失秒）

```
WITH sec AS (
  SELECT generate_series($1::timestamptz, $2::timestamptz, '1 second') AS ts
)
SELECT s.ts AS ts_bucket
FROM sec s
LEFT JOIN fact_measurements f
  ON f.station_id=$3 AND f.device_id=$4 AND f.metric_id=$5 AND f.ts_bucket=s.ts
WHERE f.ts_bucket IS NULL
ORDER BY s.ts;
```

______________________________________________________________________

## 2. 缺失数据计算方法（FFILL/MEAN/REG 算法细节）

- 2.1 前向填充 FFILL（短缺口优先）

  - 适用：缺口长度 L ≤ L_ffill（建议 60–180s）
  - 算法：x̂\[t\]=x\[t_prev\]，其中 t_prev 为缺口前最近一个有效点；若不存在则不适用
  - 复杂度：O(1) 查前值
  - 质量标注：source_hint='imputed_ffill'，confidence≈0.6–0.8（可按缺口长度衰减）

- 2.2 窗口均值 MEAN（中等缺口）

  - 适用：L_ffill \< L ≤ L_mean（建议 5–10min）
  - 算法：x̂\[t\]=avg(x\[t−W₁:t+W₂\])（使用邻域窗口的均值，尽量同一时段/同工况）
  - 复杂度：O(W) 或用滑动均值 O(1)
  - 质量标注：source_hint='imputed_mean'，confidence≈0.5–0.7

- 2.3 回归填充 REG（有协变量/长期优化）

  - 适用：存在强相关协变量，历史覆盖充分（如 Q 与 P、f 的关系）
  - 特征示例：x̂_Q = θ0 + θ1·P + θ2·f + θ3·(P·f) + ...（线性/岭回归），稳态样本训练
  - 在线更新：递推最小二乘（RLS）或滑动窗口重训
  - 复杂度：训练 O(n·d²)；预测 O(d)
  - 质量标注：source_hint='imputed_reg'，confidence≈0.6–0.9（随拟合 R²/MAPE 调整）

- 2.4 异常值替换（与缺失同处理）

  - 若值异常则按 FFILL/MEAN/REG 之一替换，保留原值至审计表

伪代码（Python）

```
def impute_series(method, series, gap_indices, ctx):
    if method=='FFILL':
        for t in gap_indices:
            series[t]=series[last_valid_before(t)]
    elif method=='MEAN':
        for t in gap_indices:
            series[t]=mean(window(series, t, W1, W2))
    elif method=='REG':
        for t in gap_indices:
            P, f = ctx['power'][t], ctx['freq'][t]
            series[t] = theta0 + theta1*P + theta2*f + theta3*P*f
    return series
```

______________________________________________________________________

## 3. 方案选择策略（自动择优 + 决策树/评分）

- 3.1 决策树（优先顺序）
  - 若 L ≤ L_ffill 且 gap 前存在有效点 → FFILL
  - 否则 若 L ≤ L_mean 且窗口内有足够邻域值 → MEAN
  - 否则 若存在可靠回归模型（R²≥R²_thr，样本量≥N_thr）→ REG
  - 否则 放弃补齐，记录告警
- 3.2 评分融合（可选）
  - 为每个候选方案计算 score = w1·数据覆盖 + w2·误差评估 + w3·物理一致性
  - 误差评估：交叉验证 MAPE/RMSE；物理一致性：η∈\[0,1\]、Q≥0、H≥0
  - 选择最高分方案；同时将评估指标写入 steps.rules_json
- 3.3 物理/业务约束
  - 补齐后的 Q/H/η 不得违反物理边界；若违反则回退到次优方案或标为“无法补齐”

## 一、目标与范围

> 第二版（详细版，可落地）：针对你提出的 11 点逐条给出可执行方案，并全面对齐 app 目录现状与 Postgres 已有表。计算与优化均以“1 秒一笔”的时间粒度运行与可视化。下文同时整合 jjjj.md（计算方案与单位规范）与 jjj1.md（可视化与 API 契约）的关键内容。

## 总览与约定（对齐 jjjj.md / jjj1.md）

- 单位：压力 MPa；流量 m³/h；功率 kW；频率 Hz；扬程 H 计算时用 Δp(MPa)×1e6/(ρg)。

- 关键变量（metric_key）：main_pipeline\_*、pump\_*、water_temperature 等；优先使用已配置在 dim_metric_config 的 metric_key。

- Trace：所有批次/步骤均带 trace_id/trace_url，供页面右上角跳转。

- rules_json：每步记录“阈值命中明细”，结构 \[{name,expr,left,right,pass}\]。

- 时间粒度：1 秒一笔（ts_bucket 为秒），所有检测、补齐、计算、优化均以秒对齐执行/记录。

- 面向“水泵/泵组”场景，构建“数据补齐 + 计算过程可视化 + 优化闭环可视化”的完整方案。

- 严格对齐现有仓库实现：

  - 数据层：public.staging_raw → public.fact_measurements（app/adapters/db/gateway.py 已落地）
  - 维度：dim_stations、dim_devices、dim_metric_config（网关 SQL 已使用）
  - 兼容模型：operation_data（app/models/operation_data.py）
  - 优化服务：app/services/optimization.py（先保留，新增“可视化留痕/参数日志”）

- 单位要求：压力统一 MPa（不存 Pa），扬程计算在公式中使用 ×1e6 因子；流量 m³/h、功率 kW、频率 Hz。

## 二、总体架构（与现有目录对齐）

- 数据入湖与合并：adapters/db/gateway.py 已提供 staging_raw → fact_measurements 的 COPY + MERGE 能力
- 数据补齐（新增）：app/services/data_completion.py（缺失检测/插补/回填）、app/tasks/jobs（调度）
- 计算过程留痕（新增）：compute_runs、compute_steps、compute_metrics（Postgres 表）
- 优化过程留痕（新增）：optimize_runs、optimize_steps、calibration_log、curve_versions
- 只读 API（新增）：app/api/v1/compute.py、app/api/v1/optimize.py、app/api/v1/curves.py（提供可视化数据）
- Web 可视化：docs/compute_pipeline_h.html、docs/optimize_pipeline_h.html（横向卡片 + 阈值命中明细 + Trace 链接）

## 三、数据库设计（Postgres）

说明：与 jjjj.md / jjj1.md 一致，这里给出最小可建集。压力字段始终 MPa。

1）计算流程留痕

```
create table if not exists compute_runs (
  run_id text primary key,
  trace_id text,
  trace_url text,
  window_start timestamptz,
  window_end   timestamptz,
  site text,
  pump_count int,
  strategy text,            -- 方案：功率×频率/累计量求导/…
  formula_version text,
  data_delay_s double precision,
  missing_rate double precision,
  run_flag boolean,
  steady_flag boolean,
  status text,              -- 正常/警告/错误
  duration_ms int,
  created_at timestamptz default now()
);

create table if not exists compute_steps (
  id bigserial primary key,
  run_id text references compute_runs(run_id) on delete cascade,
  step_key text,            -- ingest/validate/gate/select/qcalc/hcalc/etacalc/persist
  step_name_cn text,
  status text,
  start_ts timestamptz,
  end_ts   timestamptz,
  duration_ms int,
  input_json  jsonb,        -- 输入快照（按 metric_key）
  output_json jsonb,        -- 输出快照（w_i、pump_flow_rate、pump_head、η 等）
  rules_json  jsonb,        -- 阈值命中明细：[{name,expr,left,right,pass}]
  error_msg   text,
  created_at timestamptz default now()
);
create index if not exists idx_compute_steps_run on compute_steps(run_id);
create index if not exists idx_compute_steps_step on compute_steps(step_key);

create table if not exists compute_metrics (
  ts timestamptz,
  pump_id text,
  pump_flow_rate double precision,  -- m³/h
  pump_head      double precision,  -- m
  pump_efficiency double precision, -- %
  pump_speed     double precision,  -- 可存 rpm 或 n_rel
  pump_torque    double precision,  -- 可选 N·m
  run_id text,
  primary key (ts, pump_id)
);
```

2）优化流程留痕

```
create table if not exists optimize_runs (
  run_id text primary key,
  trace_id text,
  trace_url text,
  window_start timestamptz,
  window_end   timestamptz,
  curve_version text,
  status text,
  duration_ms int,
  created_at timestamptz default now()
);

create table if not exists optimize_steps (
  id bigserial primary key,
  run_id text references optimize_runs(run_id) on delete cascade,
  step_key text,            -- gate/resid/update/freeze/log/offline
  step_name_cn text,
  status text,
  start_ts timestamptz,
  end_ts   timestamptz,
  duration_ms int,
  input_json  jsonb,
  output_json jsonb,
  rules_json  jsonb,
  error_msg   text,
  created_at timestamptz default now()
);
create index if not exists idx_opt_steps_run on optimize_steps(run_id);

create table if not exists calibration_log (
  id bigserial primary key,
  run_id text references optimize_runs(run_id) on delete cascade,
  param_name text,          -- α/β/C_Q/b_Q/b_H/b_pout
  old_value double precision,
  new_value double precision,
  learn_rate double precision,
  clip_hit boolean,
  residuals_snapshot jsonb, -- {r_Qbal:..., r_HQ:..., r_QP:...}
  created_at timestamptz default now()
);

create table if not exists curve_versions (
  id bigserial primary key,
  version text,
  curve_type text,          -- HQ/PQ/ηQ
  coeffs jsonb,
  validated_metrics jsonb,  -- {rms_drop_pct:..., constraints_ok:true}
  status text default 'active',
  created_at timestamptz default now(),
  published_at timestamptz
);
```

## 四、数据补齐（Data Completion）设计

目标：对 fact_measurements 的关键指标进行“缺失检测与插补”，保证计算/优化的连续性与质量。

1）缺失检测（按设备/指标/秒级桶）

- 依据 dim_metric_config.metric_key 选取关键指标（如 main_pipeline\_*、pump\_*）。
- 查询窗口：按分钟批次，覆盖最近 N 分钟。
- 判定：同一 device_id/metric_id 在 ts_bucket 存在空缺即为缺失。

2）插补策略（逐层降级）

- 短缺口前向填充（FFILL）：
  - 条件：缺口 ≤ L_ffill 秒（建议 60–180s）
  - 方式：取最近一个有效值；标记 source_hint='imputed_ffill'
- 窗口均值填充（MEAN）：
  - 条件：L_ffill \< 缺口 ≤ L_mean（建议 5–10 分钟）
  - 方式：取窗口均值；source_hint='imputed_mean'
- 模型回归填充（REG）：
  - 条件：存在协变量（如 P、f 与 Q 的关系）且历史样本覆盖充分
  - 方式：Q̂ = F(P,f,cosφ,...) 的滑动回归；source_hint='imputed_reg'
- 放弃与告警：
  - 条件：缺口 > L_max 或数据质量异常占比高
  - 方式：不补齐，仅记录 anomalies 与 steps.status=警告/错误

3）写回策略

- 插补值写入 fact_measurements（ON CONFLICT UPSERT），保留 ts_raw=now()、source_hint 标注。
- 留痕：compute_steps 中记录 input_json（缺失分布）、output_json（填充统计）、rules_json（阈值判定）。

4）示例伪代码（Python/服务层）

```
# app/services/data_completion.py
async def backfill_metrics(window_start, window_end, station_id=None):
    # 1) 拉取窗口内关键指标的现存桶
    # 2) 逐设备/指标检测缺口序列
    # 3) 依策略填充并收集写回行
    # 4) 批量 UPSERT 到 fact_measurements（psycopg.execute_values）
    # 5) 写 compute_steps 留痕；rules_json 记录：缺口长度阈值、FFILL/MEAN/REG 命中情况
    return {"filled": n, "ffill": a, "mean": b, "reg": c, "skipped": d}
```

## 五、计算过程（Compute Pipeline）设计

1）步骤（每分钟批）

- ingest 原始数据（输入：main_pipeline\_*、pump\_*、water_temperature）
- validate 校验与单位（压力=MPa；负值/跳变=0）
- gate 运行/稳态判定（run_flag、steady_flag；f_thr、P_thr、|dQ/dt| 等）
- select 方案选择（首选功率×频率分摊；记录 α、β、f_thr、P_thr、C_Q、b_Q）
- qcalc 泵流量计算：w_i=(P_i^α f_i^β)/Σ → 归一 → Q_i = C_Q(Q_total·w_i)+b_Q
- hcalc 扬程计算：H≈((p_out−p_in)×1e6)/(ρg)，p_out≈main_pipeline_outlet_pressure
- etacalc 效率计算：η=(ρg(Q/3600)H)/(P×1000)
- persist 结果入库：compute_metrics

2）阈值命中明细（rules_json 统一结构）

```
[
  {"name":"频率阈值","expr":"f_i ≥ f_thr (f_thr=4Hz)","left":45.0,"right":4.0,"pass":true},
  {"name":"功率阈值","expr":"P_i ≥ P_thr (P_thr=5%·P_ref)","left":82.1,"right":5.0,"pass":true},
  {"name":"权重归一","expr":"Σw_i = 1","left":1.000,"right":1.000,"pass":true}
]
```

3）与现有网关/报表函数的结合

- 读数（强烈推荐）：优先使用 public.get_device_metrics_by_time_range / public.get_station_devices_metrics_by_time_range（数据库端 JSONB 整形 + limit 下推）；当跨越窗口较大或需要聚合对比时，再使用 reporting.get_metrics_auto_multi
- 写数：使用 psycopg UPSERT（与 adapters/db/gateway 的风格保持一致）

## 六、优化过程（Optimize Pipeline）设计

1）在线步骤（1–5 分钟批）

- gate 门控（物理边界/MAD/稳态）
- resid 残差（r_Qbal、r_HQ、r_QP）
- update 参数递推（C_Q/b_Q 用 RLS；α/β 数值梯度；b_H/b_pout 中位数方向，全部带限幅）
- freeze 限幅/冻结/降级（异常比例高时）
- log 记录日志（calibration_log 写入 old/new、clip_hit、残差快照）
- offline 曲线闭环占位（每日/每周拟合 H–Q/P–Q/η–Q，曲线版本 curve_versions）

2）与 app/services/optimization.py 的关系

- 保持现有 optimize 入口不变；新增“参数更新与曲线版本”的服务协作（读/写上述表）
- 逐步用真实曲线替代“启发式频率”估算逻辑

## 七、只读 API（供可视化）

1）计算过程（数据源说明：底层已采用 get\_\*\_by_time_range 或 reporting.get_metrics_auto_multi，按窗口长度自适应；统一返回包裹不变）

- GET /api/compute/runs（列表）
- GET /api/compute/runs/{run_id}（元数据：trace/url、窗口、站点）
- GET /api/compute/runs/{run_id}/steps（横向卡片数据源：input/output/rules）
- GET /api/compute/runs/{run_id}/metrics（按泵指标，支持 agg=raw|minute）

2）优化过程

- GET /api/opt/runs、/api/opt/runs/{run_id}
- GET /api/opt/runs/{run_id}/steps
- GET /api/opt/runs/{run_id}/calibration-log
- GET /api/curves/versions 与 /api/curves/versions/{version}

3）返回包裹（统一）

```
{"code":0,"message":"ok","trace_id":"...","data":{...}}
```

## 八、Web 页面（横向流程卡片）

- docs/compute_pipeline_h.html：
  - 顶部：运行ID、Trace 链接
  - 横向卡片：中文标题、状态、耗时、上下文、输入/输出、阈值命中明细（可折叠）
  - 数据源：/api/compute/runs/{run_id}、/steps、/metrics
- docs/optimize_pipeline_h.html：
  - 顶部：运行ID、Trace 链接
  - 卡片：门控/残差/更新/限幅/记录/离线
  - 数据源：/api/opt/runs/{run_id}、/steps、/calibration-log

## 九、任务拆解与排期（两周样例）

- 第 1–2 天：
  - 执行/校正本章的 DDL；新增索引
  - data_completion 服务骨架与最小补齐（FFILL），落 compute_steps 留痕
- 第 3–4 天：
  - 计算流程八步跑通（qcalc/hcalc/etacalc），写 compute_metrics
  - 可视化 API（compute 系列）
- 第 5–6 天：
  - 优化流程门控/残差/参数递推（RLS + 限幅），写 optimize\_\* 与 calibration_log
  - 可视化 API（opt 系列）
- 第 7–8 天：
  - docs 下两个页面接 API，横向卡片渲染 + 阈值折叠
  - 联调 + 基本 E2E 验收（本地）
- 第 9–10 天：
  - 离线曲线拟合 + 版本发布（curve_versions），与优化流程闭环
  - 监控/日志/追踪完善，文档收尾

## 十、验收与监控

- 功能：
  - 95% 以上步骤写入 compute_steps/optimize_steps，rules_json 完整
  - 计算指标 compute_metrics 可被可视化读取并渲染
- 性能：
  - 单批次 60s 内完成；页面 2s 内首屏
- 质量：
  - 压力单位 MPa 全链路一致；异常/降级有明确留痕

## 十一、风险与回退

- 插补过度风险：限制缺口阈值，插补写入 source_hint 标注，可按 hint 过滤
- 模型漂移：参数限幅与冻结策略；异常比例高时自动降级/停止更新
- 数据量增长：分区与索引策略，聚合走 reporting.get_metrics_auto_multi

______________________________________________________________________

附：与现有代码的对齐点

- 网关：继续使用 app/adapters/db/gateway.get_conn、COPY/MERGE、reporting 函数
- 模型：兼容 operation_data，同时以 fact_measurements 为主
- 服务：data_completion 新增补齐逻辑；optimization 服务增强“参数与曲线”的读写
- API：新增到 app/api/v1 下，返回结构与本方案一致（供 docs 页面直连）

______________________________________________________________________

## 4. 补齐过程的指标入库规范（中间量/质量/置信度）

- 中间量（建议写入 completion_steps.output_json）：
  - gap_stats：缺口长度 L、缺口段起止、窗口覆盖率、可用前值/邻域样本量
  - method_candidates：{FFILL:{score,...}, MEAN:{score,...}, REG:{score,R2,MAPE,...}}
  - selected_method：最终方案与原因（命中的规则/评分）
- 质量评分与置信度：
  - quality_score∈\[0,100\]（综合评分）；confidence∈\[0,1\]（主要给前端展示）
  - 计算建议：confidence= clamp(基础分×覆盖率×(1-归一化gap长度)×物理一致性)
- 审计字段：
  - 若替换异常值：在 completion_audit 记录 before_value/after_value/why/method
  - 若仅补缺（原本无值）：audit 可选写“插入原因与方法”

## 5. 补齐结果入库机制（写入 fact_measurements）

- 写入策略：
  - 缺失补齐：INSERT ... ON CONFLICT (station_id,device_id,metric_id,ts_bucket)
    DO UPDATE SET value=EXCLUDED.value, source_hint='imputed\_\*', ts_raw=now()
  - 异常替换：建议先写 completion_audit，再 UPDATE fact_measurements 设置 value=新值、source_hint='imputed\_\*\_override'
- 版本控制：
  - 在 completion_runs 保存 imputation_version；同时把 run_id/imputation_version 冗余进 fact_measurements.source_hint 中（如 JSON: {"hint":"imputed_ffill","run":"cmp-...","v":"1"}）
- 示例 SQL（UPSERT）：

```
INSERT INTO public.fact_measurements (station_id,device_id,metric_id,ts_raw,ts_bucket,value,source_hint)
VALUES (%(sid)s,%(did)s,%(mid)s,now(),%(ts)s,%(val)s,%(hint)s)
ON CONFLICT (station_id,device_id,metric_id,ts_bucket)
DO UPDATE SET value=EXCLUDED.value, source_hint=EXCLUDED.source_hint, ts_raw=EXCLUDED.ts_raw;
```

## 6. 可视化支撑表（补齐专用）

为避免与 compute\_\* 混淆，单独引入 completion\_\* 表（也可共用 compute\_\*，此处推荐拆分）。

```
create table if not exists completion_runs (
  run_id text primary key,
  trace_id text, trace_url text,
  window_start timestamptz, window_end timestamptz,
  station_id int null, device_ids int[] null, metric_ids int[] null,
  status text, duration_ms int,
  imputation_version text,
  created_at timestamptz default now()
);

create table if not exists completion_steps (
  id bigserial primary key,
  run_id text references completion_runs(run_id) on delete cascade,
  step_key text,               -- detect/select/impute/upsert/summary
  step_name_cn text,
  status text,
  start_ts timestamptz, end_ts timestamptz, duration_ms int,
  input_json jsonb, output_json jsonb, rules_json jsonb, error_msg text,
  created_at timestamptz default now()
);
create index if not exists idx_completion_steps_run on completion_steps(run_id);

create table if not exists completion_audit (
  id bigserial primary key,
  run_id text references completion_runs(run_id) on delete cascade,
  station_id int, device_id int, metric_id int, ts_bucket timestamptz,
  action text,                  -- insert_missing | override_outlier
  before_value double precision null,
  after_value  double precision not null,
  method text,                  -- FFILL/MEAN/REG
  confidence double precision,  -- 0..1
  reason text,                  -- 异常类型/选择说明
  created_at timestamptz default now()
);
```

______________________________________________________________________

## 7. 优化流程详解（数据→算法→参数更新→落库/修改）

- 数据获取：
  - 来自 fact_measurements（秒级 ts_bucket），或使用 adapters/db/gateway 的 reporting.get_metrics_auto_multi 聚合
  - 选择 steady_flag=1 的样本（稳态定义参见 jjjj.md）
- 算法执行：
  - 残差计算：r_Qbal=Q_total−ΣQ_i；r_HQ=H−Ĥ(Q)；r_QP=P_in−P̂(Q)
  - 在线更新：
    - C_Q、b_Q：RLS（递推最小二乘）
    - α、β：数值梯度微调（小步长、带 clip）
    - b_H、b_pout：中位数方向更新（带 clip）
  - 离线闭环（每日/每周）：拟合 H–Q/P–Q/η–Q，发布新 curve_versions
- 参数修改（如何“修改数据”）：
  - 不直接改历史 fact_measurements；修改的是“计算所用参数/曲线版本”，影响后续秒级计算
  - 将参数更新写入 pump_calibration（或 dim 侧表），计算流程在 select/qcalc/hcalc 时读取最新参数
  - 推荐工况（频率/台数）写入 optimization_recommendations，供值班/自动执行参考
- 表结构（新增/复用）：

```
create table if not exists pump_calibration (
  id bigserial primary key,
  station_id int, pump_id int,
  alpha double precision, beta double precision, C_Q double precision, b_Q double precision,
  b_H double precision, b_pout double precision, f_ref double precision,
  updated_at timestamptz default now(), run_id text
);

create table if not exists optimization_recommendations (
  id bigserial primary key,
  run_id text references optimize_runs(run_id) on delete cascade,
  station_id int, pump_id int,
  recommended_freq double precision, expected_power double precision, expected_flow double precision,
  reason text, created_at timestamptz default now()
);
```

______________________________________________________________________

## 8. 优化可视化表（全流程）

- 已有：optimize_runs、optimize_steps、calibration_log、curve_versions
- 新增建议：optimization_recommendations（上节）
- 可视化要点：
  - steps.rules_json 展示门控/限幅/残差阈值；calibration_log 展示 old→new 与 clip_hit
  - curve_versions 展示新旧曲线对比指标（RMS 下降%、边界满足率）

______________________________________________________________________

## 9. API 接口清单（REST，按模块分组）

- Completion（补齐）
  - GET /api/completion/runs?start&end&status&station_id
  - GET /api/completion/runs/{run_id}
  - GET /api/completion/runs/{run_id}/steps
  - GET /api/completion/runs/{run_id}/audit
- Compute（计算）
  - GET /api/compute/runs、/api/compute/runs/{run_id}
  - GET /api/compute/runs/{run_id}/steps
  - GET /api/compute/runs/{run_id}/metrics?pump_id&agg=raw|minute
- Optimize（优化）
  - GET /api/opt/runs、/api/opt/runs/{run_id}
  - GET /api/opt/runs/{run_id}/steps
  - GET /api/opt/runs/{run_id}/calibration-log
  - GET /api/curves/versions、/api/curves/versions/{version}
  - GET /api/opt/runs/{run_id}/recommendations
- 统一返回：{"code":0,"message":"ok","trace_id":"...","data":{...}}；错误码：400/401/403/404/409/429/500/503
- 示例 SQL 已在 jjj1.md/本文提供

______________________________________________________________________

## 10. 秒级处理（1 秒一笔）实现

- 时间对齐：
  - 生成秒序列 generate_series(T0,T1,'1 second')，与 fact_measurements 左连接；下游全以 ts_bucket 为 1s（查询/前端回放场景，优先用 public.get_device_metrics_by_time_range 或 public.get_station_devices_metrics_by_time_range，避免 API 层二次拼 JSON）
- 调度策略：
  - 以“60 秒微批”驱动，但内部按秒遍历处理（每批处理上一分钟的 60 个秒点）
  - 对于实时更严格的场景，可改为 5–10 秒微批（内部仍逐秒）
- 性能与可用性：
  - 批量 UPSERT：psycopg.execute_values 分批写入（如每 200–500 行一次）
  - 索引：fact_measurements(primary key: station_id,device_id,metric_id,ts_bucket)；steps 表按 run_id 索引
  - 幂等：run_id 采用 window_end 的 ISO 与任务序列号，重复运行不产生副作用
  - 监控：steps.duration_ms、affected_rows、异常比例

______________________________________________________________________

## 11. 内容整合（jjjj.md / jjj1.md 核心纳入）

- 公式与单位（来自 jjjj.md）：
  - H≈((p_out − p_in)×1e6)/(ρ·g)；η=(ρ·g·(Q/3600)·H)/(P×1000)
  - 分摊首选：w_i=(P_i^α·f_i^β)/Σ → Q_i=C_Q·(Q_total·w_i)+b_Q；阈值：f_thr、P_thr；参数范围：α、β∈\[0.8,1.2\]；C_Q∈\[0.9,1.1\]
- 可视化与 API（来自 jjj1.md）：
  - runs/steps 双表结构；rules_json 用于“阈值命中明细”；Trace 链接/ID
  - 只读 API 契约：/api/compute/*、/api/opt/*、/api/curves/*（本文新增 /api/completion/*）

______________________________________________________________________

## 代码示例（对接现有 app 结构）

- worker：app/tasks/jobs/completion_job.py（伪代码）

```
from app.adapters.db.gateway import get_conn
from datetime import datetime, timedelta

async def completion_job(settings, station_id:int|None=None):
    end = datetime.utcnow().replace(microsecond=0)
    start = end - timedelta(seconds=60)
    run_id = f"cpl-{end.isoformat()}"
    # 写 completion_runs
    # detect 缺失
    with get_conn(settings) as conn:
        # 1) 查询缺失集合 G
        # 2) 为每个 gap 选择方法并计算值
        # 3) 批量 UPSERT 到 fact_measurements
        # 4) 写 completion_steps 与 completion_audit
    return run_id
```

- API：app/api/v1/completion.py（伪代码）

```
@router.get('/api/completion/runs/{run_id}/steps')
async def list_steps(run_id: str):
    rows = db.fetch_all("select step_key,step_name_cn,status,duration_ms,input_json,output_json,rules_json from completion_steps where run_id=%s order by id", (run_id,))
    return ok({"items": rows})
```

______________________________________________________________________

## 任务拆解（更新版，含模块归属）

- D1–D2 数据库：创建 completion\_\* / compute\_\* / optimize\_\* / calibration / recommendations 表与索引
- D3–D4 补齐：completion_job 最小可用（FFILL→MEAN），写 completion_runs/steps/audit 与 fact_measurements
- D5–D6 计算：select/qcalc/hcalc/etacalc 跑通，compute_runs/steps/metrics 入库
- D7–D8 优化：online gate/resid/update/freeze/log；calibration_log 与 pump_calibration 更新；recommendations 计算
- D9 前端：docs/compute_pipeline_h.html / docs/optimize_pipeline_h.html 对接 API；新增 docs/ 页面用于 completion 可视化（可选）
- D10–D12 加强：REG 模型补齐（RLS/滑窗回归）、曲线闭环、API 过滤/分页/fields 裁剪
- D13–D14 测试与验收：公式/阈值单测、API 集成、E2E 联调、性能冒烟
