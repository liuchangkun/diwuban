# 测试指南（里程碑2：埋点验证）

本指南说明如何通过 run_all 快速验证导入进度与合并埋点，以及如何提取统计信息。

## 1. 运行 run_all

- 示例命令（根据你的 CLI 实现调整）：
  - python -m app.cli run-all --config configs/dev --mapping configs/dev/mapping.json --window-start 2025-08-18T00:00:00Z --window-end 2025-08-18T06:00:00Z
  - 输出目录：logs/runs/\<日期>/\<时间-pid>/

## 2. 验证 ingest.load.\* 进度

- 文本模式（app.log）：
  - Select-String -Path logs/runs/*/*/app.log -Pattern "ingest.load"
- JSON 模式（app.ndjson）：
  - 使用 jq：
    - jq -r 'select(.event=="ingest.load.progress") | {rows_read:.rows_read,bytes:.bytes,batch_cost_ms:.batch_cost_ms}' logs/runs/*/*/app.ndjson

## 3. 验证 align.merge.window 与 SQL 执行

- 合并窗口：
  - Select-String -Path logs/runs/*/*/app.log -Pattern "align.merge.window"
  - JSON 下可直接查看 app.ndjson 的 align.merge.window（字段见《日志规范》示例）
- SQL 日志（慢 SQL Top 来源）：
  - 默认 Top-5，可在 configs/logging.yaml → sql.top_n_slow 调整
  - jq -r 'select(.event=="db.exec.succeeded") | {window_start,window_end,sql_cost_ms,affected_rows}' logs/runs/*/*/sql.ndjson | sort -t: -k2 -nr | head -n 5

## 4. 验证 task.summary 汇总

- app.ndjson 中应看到 event=task.summary，包含：
  - rows_total, rows_merged, rows_per_sec, duration_ms, backpressure_count, slow_sql_top
- 直接查看 summary.json：
  - cat logs/runs/*/*/summary.json

## 5. 配置采样参数

- 在 configs/logging.yaml 中使用：
  - sampling:
    - loop_log_every_n: 10000  # 每 N 行输出一次进度日志（最小 1）
  - 建议 min_interval_sec 取 1s 作为日志频率下限（当前内置），避免海量输出

## 6. 读取 diagnostics（示例）

- 从 summary.json 读取关键诊断：
  - jq '.diagnostics | {p95:.p95_batch_ms,avg:.avg_fail_rate,samples:.samples_count}' logs/runs/*/*/summary.json
- 从 app.ndjson 的 task.summary 事件读取（同字段）：
  - jq -r 'select(.event=="task.summary") | .diagnostics' logs/runs/*/*/app.ndjson
- 若需更细统计，可查看 perf.ndjson 的批次与背压事件：
  - jq -r 'select(.event=="ingest.copy.batch") | .batch_cost_ms' logs/runs/*/*/perf.ndjson | sort -n | tail -n 10

提示：若未看到行进度，检查 loop_log_every_n 是否过大、数据量是否较小、或当前为文本格式下的行筛选命令。

# 测试指南（里程碑对齐版）

## 最小窗口端到端验证（text/by_module + sources 快照）

- 命令：
  - python -m app.cli.main run-all configs/data_mapping.v2.json --window-start 2025-02-28T02:00:00Z --window-end 2025-02-28T03:00:00Z --log-run --log-dir logs/runs/verify_e2e --log-format text --log-routing by_module --log-level INFO
- 期望：
  - 控制台出现 prepare_dim upsert、ingest.copy.batch、merge started/succeeded
  - 生成 logs/modules/sql.log 与 logs/modules/root.log，含 db.exec.\* 与 align.merge.window
  - 生成 env.json：包含 args_summary、config_snapshot、sources、ts、run_id、run_dir

## 单元与静态检查

- pytest -q 或具体模块测试（若存在）
- pre-commit run --all-files 保持全绿

## 常见问题排查

- db.exec.failed：查看 sql.log 的 error/explain；如需，临时切换 logging.sql.explain=always
- merge 卡顿：查看 root.log 的 align.merge.window 与 backpressure.enter/exit 时序
- 导入刷屏：后续将对 ingest.copy.batch 增加采样与节流（参见日志规范）

## 失败案例诊断示例

- db.exec.failed 示例（sql.log）：
  - ERROR ts=2025-08-19T04:33:01Z logger=sql event=db.exec.failed sql_op=MERGE target_table=public.fact_measurements sql_cost_ms=1203 error="relation "dim_devices" does not exist"
  - explain=Merge Append  -> ... （截断）
- 排查步骤：
  1. 确认 prepare_dim 是否成功（root.log 是否有“维表/映射已准备”）
  1. 检查 mapping/stations/devices/metrics 是否完整；是否使用了 v2 标准 schema
  1. 若为时间解析问题：检查 DataTime 格式与站点 tz；必要时在合并前修正

# 测试指南

> 状态板（2025-08-18）：导入链路与 CLI 已更新（方案B/中文帮助）；check-mapping 支持 --out/--show-all；db-ping --verbose；标准 schema 使用 configs/data_mapping.v2.json。导入默认 auto（阈值 total_mb=50/per_file_mb=10/max_file_count=20）；日志默认 json（可切 text）、支持按模块路由；启动输出参数与配置快照（默认不脱敏）。run-all E2E 测试待修 prepare-dim 的 dim_metric_config 返回列后继续执行。会话快照：docs/PLAYBOOKS/SESSION_SNAPSHOT_2025-08-18.md。

> 更新（2025-08-19）：E2E 与快照验证

- E2E：`python -m app.cli.main run-all ... --log-run --log-dir logs/runs/e2e_test`
- 验证：检查 env.json（args_summary/config_snapshot/sources）与 summary.json（timing/backpressure/tz_fallback）
- 覆盖：使用 --log-format/--log-routing，确认 sources.logging.format/routing=CLI

> 调度与刷新：统一使用 APScheduler（不使用 Windows 计划任务）。

- 环境与准备
  - 数据库：PostgreSQL 16；TEST_DB_DSN 示例：postgresql://user:pass@localhost:5432/dbname
  - 数据准备：api.upsert_measurements_json 写入少量样本；测试后 delete_measurements_by_filter 清理
- 测试类型
  - 只读查询（reporting.\* 日/小时/多站）
  - 明细 CRUD（api.\*）
  - 刷新与调度：REFRESH MV + APScheduler 作业试运行
  - 观测与基线：pg_stat_statements 快照 + 命中率审计
- 基本流程
  1. 写入样本（JSON 批量）
  1. 刷新 MV（或等待 APScheduler）
  1. 查询验证（日/小时聚合 + 明细）
  1. 更新/删除验证
  1. 观测与命中率
- 对齐回归
  - tests/integration/test_time_alignment_and_conflict.py：整秒对齐 + 同秒 UPSERT 合并
  - 自检：ts_bucket 非整秒行数应为 0
