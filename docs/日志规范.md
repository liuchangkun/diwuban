# 日志规范（项目版）
> 状态说明（预对齐，基于已落地代码与数据库）
> - 字段口径：align.merge.window 当前产出使用 rows_input（代码现状）；历史示例中的 rows_in 将在文档后续同步修正
> - 文本模式与按模块路由：by_module 已提供最小可用路由与 Text 模板，字段族将按里程碑2逐项补齐
> - 运行产物：logs/runs/YYYYMMDD/<job_id>/ 下 app.ndjson/sql.ndjson/perf.ndjson/summary.json 已落地
> - 报表产物：reports/data_quality_report.<run_id>.json 将随 S1 Quick Wins 落地，并输出 data_report.generated 事件
> - 启动快照：app.ndjson 首行 args_summary + config_snapshot（含来源标注）将在里程碑1落地；env.json 已包含 run_id/run_dir/config_snapshot


> 状态板（2025-08-18）：perf.ndjson 已增加 p95_window；sql.ndjson 已包含 window_start/window_end；CLI 方案B 支持文件日志初始化；db-ping --verbose 打印连接信息；check-mapping 支持 --out/--show-all 导出与聚类。导入模式默认 auto（阈值 total_mb=50/per_file_mb=10/max_file_count=20，满足倾向 direct，否则 staging）；日志默认 json，可在 configs/logging.yaml 设置 format=text，并可 routing=by_module 按模块分类输出；启动输出 args_summary 与 config_snapshot（默认不脱敏，redaction.enable=false）。端到端 run-all 正在修复 prepare-dim 中 dim_metric_config 返回列名问题。

本规范定义应用层日志的结构、字段与行为，作为“唯一的日志规范”。运维落地与目录结构见《日志运维.md》。

## 1. 目标与原则

- 结构化：NDJSON（每行一个 JSON），UTF-8，UTC 时间
- 可观测：可关联（trace_id/job_id/batch_id）、可统计（rows、耗时）、可审计（字段齐备）
- 低开销：采样/限流、队列异步、摘要化 SQL
- 安全合规：脱敏、长度截断、最小可见

## 2. 事件命名与域

- 格式：`<domain>.<action>[.detail]`
- 域：ingest/align/db/mv/audit/task/guardrail/backpressure/quality/cli

## 3. 字段规范（核心字典）

- 通用：ts/level/event/logger/module/func/line/file/pid/thread
- 追踪：trace_id/job_id/batch_id
- 业务：station_id/\_name、device_id/\_name、metric_id/\_key
- 文件：file_path/file_name/file_hash/file_offset/bytes_read
- 数据量：rows_total/rows_read/rows_loaded/rows_deduped/rows_merged/rows_failed
- 窗口：window_start/window_end
- 数据库：sql_op/sql_cost_ms/affected_rows/target_table
- 重试：attempt/max_attempts/backoff_ms
- 异常：exc_type/exc_message/stack

## 4. 配置与初始化（仅 YAML；configs/logging.yaml 模板）

```yaml
# 日志配置（默认 JSON，可切换 TEXT；支持按模块输出文件；默认不脱敏）
level: INFO
format: json             # json|text
routing: by_run          # by_run|by_module（按模块写 logs/modules/<module>.log）
console: true
file:
  enabled: true
  base_dir: logs
  rotate: daily          # daily|size
  max_bytes: 10485760    # size 模式有效
  backup_count: 10
  retention_days: 14
sampling:
  loop_log_every_n: 1000
context:
  include_fields: [trace_id, job_id, batch_id, station_id, device_id, file_path]
  include_sql_cost: true
  include_stack: true
redaction:
  enable: false          # 默认不脱敏（按用户要求），可改为 true 启用
sql:
  text: full             # summary|normalized|full（full 输出完整 SQL 文本）
  explain: on_error      # on_error|sampled|always
performance:
  queue_handler: true
  flush_on_exit: true
```

## 5. 上下文注入与异步日志

- contextvars + LoggerAdapter 注入 trace_id/job_id
- QueueHandler/QueueListener 异步写盘（退出前 stop()）

## 6. 采样、限流与长度

- debug_sample_rate（仅 DEBUG 生效）
- loop_log_every_n：高频循环进度日志节流
- 单行最大 8KB（超限截断并加 `truncated=true`）

## 7.1 事件与路由（集中常量 + 建议）

- 事件常量（集中定义于 app/utils/logging_ext.py）：
  - EVENT_INGEST_LOAD_BEGIN / EVENT_INGEST_LOAD_PROGRESS / EVENT_INGEST_LOAD_END
  - EVENT_INGEST_COPY_BATCH（高频）
  - EVENT_BACKPRESSURE_ENTER / EVENT_BACKPRESSURE_EXIT
  - EVENT_INGEST_COPY_FAILED
  - EVENT_ALIGN_MERGE_WINDOW
  - EVENT_TASK_SUMMARY

- 路由建议：
  - root：ingest.load.*、ingest.copy.failed、task.summary、align.merge.window
  - perf：ingest.copy.batch、backpressure.*

## 7.2 采样策略（logging.sampling）

- default_rate：默认采样率，范围 0~1
- high_frequency_events：为高频事件设置专属采样率（覆盖 default_rate）
  - 示例：{"ingest.copy.batch": 0.1}
- 实际接入：
  - ingest.copy.batch 按事件级采样
  - ingest.load.progress 由 SamplingGate 控制（every_n + min_interval_sec）


## 7. 错误、重试与背压

- 错误字段：exc_type/exc_message/stack/hint
- 可重试（连接/超时/deadlock/40001）：指数退避+抖动，记录 attempt/backoff_ms
- 背压：当 p95/失败率/锁等待超阈，输出 backpressure.enter/exit 与 guardrail.stop

## 8. 关键节点（最少集）

- ingest.load.begin/progress/end
- align.merge.window/conflict
- mv.refresh.begin/end
- audit.mv
- task.summary（程序退出前输出一次总览）

## 9. SQL 执行日志（状态/语句/计划）

- 状态：sql_state(sql started/succeeded/failed/retried)/sql_try/sql_op/target_table/affected_rows/sql_cost_ms
- 语句：logging.sql.text (none|summary|normalized|full_debug，默认 summary)
  - sql_hash 指纹；sql_text 仅在 normalized/full_debug 输出，截断 2KB，`truncated=true`
  - sql_params_logged=false（默认）；开启时也需脱敏 redaction.patterns
- 计划：explain 摘要（on_error|sampled|always，默认 on_error）
- 错误：pgcode/pgerror/hint/detail/constraint

## 10. 领域增强字段（业务/性能/文件/线程）

- 业务：biz_domain/biz_action/scenario、conflict_count/dedupe_ratio/merge_strategy/source_priority
- 性能：batch_cost_ms/merge_cost_ms/rows_per_sec/p95_batch_ms/lock_waits/adjustment
- 文件：file_size/encoding/compress、ts_min/ts_max、chunk_idx/chunks_total、read_cost_ms/read_bytes_per_sec
- 线程：thread_id/thread_name/worker_index/pool、task_id/station_group/window_key、instance_id

## 11. 测试、验收与安全

- 单测：caplog 验证字段/采样/截断/脱敏；开关项覆盖
- 集成：并发 COPY + 合并下日志吞吐与丢失率（队列溢出检测）
- E2E：run-all 后检查 task.summary 与 audit.mv
- 安全：严禁明文凭据/PII；仅记录摘要，不落完整 SQL/参数

> 运维细则（目录结构、轮转保留、检索与排障）见《日志运维.md》。

## 附A. 上下文自动补全（建议）

- 入口：CLI 生成 trace_id/job_id，并通过 contextvars 传递
- 文件/批次：file_path/file_size/bytes_read、chunk_idx/chunks_total、rows\_\*、batch_cost_ms/rows_per_sec
- 业务三元：station_id/device_id/metric_id（在合并阶段补齐），对齐窗口 window_start/window_end

## 附B. 事件命名扩展（建议）

- ingest.path.resolve：路径迁移/适配证据（base_dir + 受限 globFallback）

### 事件示例：align.merge.window（完整 JSON 示例）

以下示例为 JSON 格式日志（app.ndjson），字段按当前实现输出：

```
{"ts":"2025-08-20T06:05:02Z","level":"INFO","logger":"root","event":"align.merge.window","message":"合并完成","window_start":"2025-08-18T00:00:00Z","window_end":"2025-08-18T06:00:00Z","segmented":true,"granularity":"1h","affected_rows":12345,"rows_in":12500,"rows_deduped":155,"rows_merged":12345,"dedup_ratio":0.0124,"sql_cost_ms":842}
```

说明：

- segmented/granularity 来自 settings.merge.segmented
- affected_rows/rows_in/rows_deduped/rows_merged/dedup_ratio/sql_cost_ms 为合并统计与耗时指标
- window\_\* 为 UTC 窗口边界（字符串形式）

### task.summary（包含 diagnostics 示例）

- summary.json 示例：

```
{
  "rows_total": 100000,
  "rows_merged": 99876,
  "failures": 0,
  "backpressure_count": 2,
  "duration_ms": 300500,
  "rows_per_sec": 332.39,
  "slow_sql_top": [{"sql":"merge fact_measurements 2025-...","cost_ms":842,"affected_rows":12345}],
  "diagnostics": {
    "p50_batch_ms": 80,
    "p90_batch_ms": 120,
    "p95_batch_ms": 150,
    "p99_batch_ms": 260,
    "max_batch_ms": 420,
    "min_batch_ms": 60,
    "avg_fail_rate": 0.012,
    "p95_fail_rate": 0.023,
    "max_fail_rate": 0.05,
    "samples_count": 236,
    "backpressure_enter": 2,
    "backpressure_exit": 2
  },
  "merge": {"rows_merged": 99876, "rows_in": 100200, "rows_deduped": 324, "affected_rows": 99876, "dedup_ratio": 0.0032, "sql_cost_ms": 842},
  "copy": {"rows_read": 100200, "rows_loaded": 99876, ...}
}
```

- app.ndjson 中的 task.summary 事件包含同结构的 diagnostics 字段，便于“一处读取”。

- ingest.columns.validated：固定列名（TagName/DataTime/DataValue）校验通过

- backpressure.enter / backpressure.exit / guardrail.stop：自适应与门禁

- db.exec.started / db.exec.succeeded / db.exec.failed / db.exec.retried：SQL 状态与摘要

### 背压日志示例（JSON，建议）

```json
{"event":"backpressure.enter","p95_batch_ms":2300,"fail_rate":0.012,"action":"shrink_batch","from_batch":1000000,"to_batch":500000}
{"event":"backpressure.exit","p95_batch_ms":1800,"fail_rate":0.003,"action":"recover","new_workers":6}
```

- 说明：enter 记录触发阈值与动作；exit 记录恢复后的关键参数（如回升并发）

## 文本模式与按模块路由（里程碑2 最小实现）

- 切换方式：
  - logging.format=json|text（默认 json）
  - logging.routing=by_run|by_module（默认 by_run）

- backpressure.enter
  - 字段：p95_batch_ms, p95_window, batch_cost_ms, rows_per_sec, fail_rate, adjustment
- backpressure.exit
  - 字段：p95_batch_ms, p95_window, batch_cost_ms, rows_per_sec, fail_rate

- by_run：仍按运行目录 logs/runs/YYYYMMDD/\<job_id>/ 落盘，多流文件扩展名：.ndjson|.log
- by_module：按 logger 名输出到 logs/modules/<logger>.log（例如 sql.log、perf.log、root.log）
- Text 格式示例：
  - INFO ts=2025-08-19T03:12:05Z logger=sql event=db.exec.succeeded sql_op=COPY rows=20480 msg=copy done
- 推荐字段（最小集）：level, ts, logger, event, window_start, window_end, rows, rows_merged, sql_op, msg

### 事件字段表（最小集）

- db.exec.started
  - 字段：sql_op, target_table, window_start, window_end, window_size_seconds, iso_week_utc
- db.exec.succeeded
  - 字段：sql_op, target_table, affected_rows, sql_cost_ms, window_start, window_end
- db.exec.failed
  - 字段：sql_op, target_table, sql_cost_ms, error, explain(可选)
- ingest.load.begin
  - 字段：file_path, rows_total?
- ingest.load.progress（采样节流）
  - 字段：rows_read, bytes, rows_per_sec?, batch_cost_ms?
- ingest.load.end
  - 字段：rows_loaded, cost_ms?
- align.merge.window（里程碑2扩展）
  - 字段：window_start, window_end, segmented, granularity, rows_in?, rows_deduped?, rows_merged?, dedup_ratio?, sql_cost_ms?, affected_rows?
- ingest.copy.batch（预留，后续扩展）
  - 字段：rows, bytes, batch_cost_ms

### by_module 输出说明

- sql 模块：db.exec.\* 事件；文本模式下便于阅读（行内字段）
- root 模块：task.begin/task.end、align.merge.window、ingest.copy.batch 等
- 输出路径：logs/modules/<logger>.log

### 样例片段（文本模式）

- root.log（导入进度采样）

  - INFO ts=2025-08-20T06:00:01Z logger=root event=ingest.load.progress rows_read=100000 bytes=104857600 rows_per_sec=28000 batch_cost_ms=350

- root.log（导入结束小结）

  - INFO ts=2025-08-20T06:05:01Z logger=root event=ingest.load.end rows_loaded=99876 cost_ms=300000

- root.log（任务汇总）

  - INFO ts=2025-08-20T06:05:02Z logger=root event=task.summary rows_total=100000 rows_merged=99876 backpressure_count=2 rows_per_sec=27000 duration_ms=300500

- sql.log（MERGE 成功）

### 配置采样参数（ingest.load.progress）

- 配置文件路径：configs/logging.yaml → sampling.loop_log_every_n（整数，最小 1）

- 建议：

  - 小数据集：1000~5000
  - 中/大型数据集：10000~50000
  - 并设置最小时间间隔 min_interval_sec≈1s（当前实现内置），避免日志风暴

- 说明：rows_per_sec 基于“文件级开始时间”计算，若数据量极小可能为 None 或波动较大，属正常现象

  - INFO ts=2025-08-19T04:31:12Z logger=sql event=db.exec.succeeded sql_op=MERGE target_table=public.fact_measurements affected_rows=12345 sql_cost_ms=842

- root.log（合并窗口完成）

  - INFO ts=2025-08-19T04:31:12Z logger=root event=align.merge.window window_start=2025-02-28T02:00:00Z window_end=2025-02-28T03:00:00Z segmented=True granularity=1h
