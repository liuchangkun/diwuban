# 日志规范（项目版）

> 状态说明（预对齐，基于已落地代码与数据库）
>
> - 字段口径：align.merge.window 当前产出使用 rows_input（代码现状）；历史示例中的 rows_in 将在文档后续同步修正
> - 文本模式与按模块路由：by_module 已提供最小可用路由与 Text 模板，字段族将按里程碑2逐项补齐
> - 运行产物：logs/runs/YYYYMMDD/\<job_id>/ 下 app.ndjson/sql.ndjson/perf.ndjson/summary.json 已落地
> - 报表产物：reports/data_quality_report.\<run_id>.json 将随 S1 Quick Wins 落地，并输出 data_report.generated 事件
> - 启动快照：app.ndjson 首行 args_summary + config_snapshot（含来源标注）将在里程碑1落地；env.json 已包含 run_id/run_dir/config_snapshot

> 状态板（2025-08-18）：perf.ndjson 已增加 p95_window；sql.ndjson 已包含 window_start/window_end；CLI 方案B 支持文件日志初始化；db-ping --verbose 打印连接信息；check-mapping 支持 --out/--show-all 导出与聚类。导入模式默认 auto（阈值 total_mb=50/per_file_mb=10/max_file_count=20，满足倾向 direct，否则 staging）；日志默认 json，可在 configs/logging.yaml 设置 format=text，并可 routing=by_module 按模块分类输出；启动输出 args_summary 与 config_snapshot（默认不脱敏，redaction.enable=false）。端到端 run-all 正在修复 prepare-dim 中 dim_metric_config 返回列名问题。

本规范定义应用层日志的结构、字段与行为，作为"唯一的日志规范"。运维落地与目录结构见《日志运维.md》。

## 1. 目标与原则

- 结构化：NDJSON（每行一个 JSON），UTF-8，UTC 时间
- 可观测：可关联（trace_id/job_id/batch_id）、可统计（rows、耗时）、可审计（字段齐备）
- 低开销：采样/限流、队列异步、摘要化 SQL
- 安全合规：脱敏、长度截断、最小可见

## 2. 事件命名与域

- 格式：`<domain>.<action>[.detail]`
- 域：ingest/align/db/mv/audit/task/guardrail/backpressure/quality/cli/pool

## 3. 字段规范（核心字典）

- 通用：ts/level/event/logger/module/func/line/file/pid/thread
- 追踪：trace_id/job_id/batch_id
- 业务：station_id/\_name、device_id/\_name、metric_id/\_key
- 文件：file_path/file_name/file_hash/file_offset/bytes_read
- 数据量：rows_total/rows_read/rows_loaded/rows_deduped/rows_merged/rows_failed
- 窗口：window_start/window_end
- 数据库：sql_op/sql_cost_ms/affected_rows/target_table
- 重试：attempt/max_attempts/backoff_ms
- 异常：exc_type/exc_message/stack
- 连接池：total_connections/active_connections/idle_connections/total_requests/failed_requests/average_wait_time/peak_connections

## 4. 配置与初始化（仅 YAML；configs/logging.yaml 模板）

```yaml
# 日志配置（默认 JSON，可切换 TEXT；支持按模块输出文件；默认不脱敏）
level: INFO
format: json             # json|text
routing: by_run          # by_run|by_module（按模块写 logs/modules/<module>.log）
console: true
file:
  enabled: true
  base_dir: logs
  rotate: daily          # daily|size
  max_bytes: 10485760    # size 模式有效
  backup_count: 10
  retention_days: 14
sampling:
  loop_log_every_n: 1000
context:
  include_fields: [trace_id, job_id, batch_id, station_id, device_id, file_path]
  include_sql_cost: true
  include_stack: true
redaction:
  enable: false          # 默认不脱敏（按用户要求），可改为 true 启用
sql:
  text: full             # summary|normalized|full（full 输出完整 SQL 文本）
  explain: on_error      # on_error|sampled|always
performance:
  queue_handler: true
  flush_on_exit: true
```

## 5. 上下文注入与异步日志

- contextvars + LoggerAdapter 注入 trace_id/job_id
- QueueHandler/QueueListener 异步写盘（退出前 stop()）

## 6. 采样、限流与长度

- debug_sample_rate（仅 DEBUG 生效）
- loop_log_every_n：高频循环进度日志节流
- 单行最大 8KB（超限截断并加 `truncated=true`）

## 7.1 事件与路由（集中常量 + 建议）

- 事件常量（集中定义于 app/utils/logging_ext.py）：

  - EVENT_INGEST_LOAD_BEGIN / EVENT_INGEST_LOAD_PROGRESS / EVENT_INGEST_LOAD_END
  - EVENT_INGEST_COPY_BATCH（高频）
  - EVENT_BACKPRESSURE_ENTER / EVENT_BACKPRESSURE_EXIT
  - EVENT_INGEST_COPY_FAILED
  - EVENT_ALIGN_MERGE_WINDOW
  - EVENT_TASK_SUMMARY
  - EVENT_POOL_INITIALIZED / EVENT_POOL_CONNECTION_CREATED / EVENT_POOL_CONNECTION_ACQUIRED
  - EVENT_POOL_CONNECTION_CREATE_FAILED / EVENT_POOL_CLOSED

- 路由建议：

  - root：ingest.load.\*、ingest.copy.failed、task.summary、align.merge.window、pool.\*
  - perf：ingest.copy.batch、backpressure.\*
  - db：pool.\*

## 7.2 采样策略（logging.sampling）

- default_rate：默认采样率，范围 0~1
- high_frequency_events：为高频事件设置专属采样率（覆盖 default_rate）
  - 示例：{"ingest.copy.batch": 0.1}
- 实际接入：
  - ingest.copy.batch 按事件级采样
  - ingest.load.progress 由 SamplingGate 控制（every_n + min_interval_sec）

## 7. 错误、重试与背压

- 错误字段：exc_type/exc_message/stack/hint
- 可重试（连接/超时/deadlock/40001）：指数退避+抖动，记录 attempt/backoff_ms
- 背压：当 p95/失败率/锁等待超阈，输出 backpressure.enter/exit 与 guardrail.stop

## 8. 关键节点（最少集）

- ingest.load.begin/progress/end
- align.merge.window/conflict
- mv.refresh.begin/end
- audit.mv
- task.summary（程序退出前输出一次总览）
- pool.initialized/created/acquired/closed

## 9. SQL 执行日志（状态/语句/计划）

- 状态：sql_state(sql started/succeeded/failed/retried)/sql_try/sql_op/target_table/affected_rows/sql_cost_ms
- 语句：logging.sql.text (none|summary|normalized|full_debug，默认 summary)
  - sql_hash 指纹；sql_text 仅在 normalized/full_debug 输出，截断 2KB，`truncated=true`
  - sql_params_logged=false（默认）；开启时也需脱敏 redaction.patterns
- 计划：explain 摘要（on_error|sampled|always，默认 on_error）
- 错误：pgcode/pgerror/hint/detail/constraint

## 10. 领域增强字段（业务/性能/文件/线程）

- 业务：biz_domain/biz_action/scenario、conflict_count/dedupe_ratio/merge_strategy/source_priority
- 性能：batch_cost_ms/merge_cost_ms/rows_per_sec/p95_batch_ms/lock_waits/adjustment
- 文件：file_size/encoding/compress、ts_min/ts_max、chunk_idx/chunks_total、read_cost_ms/read_bytes_per_sec
- 线程：thread_id/thread_name/worker_index/pool、task_id/station_group/window_key、instance_id

## 11. 测试、验收与安全

- 单测：caplog 验证字段/采样/截断/脱敏；开关项覆盖
- 集成：并发 COPY + 合并下日志吞吐与丢失率（队列溢出检测）
- E2E：run-all 后检查 task.summary 与 audit.mv
- 安全：严禁明文凭据/PII；仅记录摘要，不落完整 SQL/参数

## 12. 数据库连接池日志事件

数据库连接池相关操作会生成以下日志事件：

### pool.initialized

- **描述**：连接池初始化完成
- **字段**：min_size, max_size, host, database
- **级别**：INFO

### pool.connection.created

- **描述**：创建新连接
- **字段**：total_connections
- **级别**：DEBUG

### pool.connection.acquired

- **描述**：获取连接成功
- **字段**：wait_time_ms, active_connections
- **级别**：DEBUG

### pool.connection.create_failed

- **描述**：创建连接失败
- **字段**：error, dsn_preview, index, min_size
- **级别**：WARNING

### pool.closed

- **描述**：连接池关闭
- **字段**：连接池统计信息（total_connections, active_connections, idle_connections, total_requests, failed_requests, average_wait_time, peak_connections, uptime_seconds）
- **级别**：INFO

> 运维细则（目录结构、轮转保留、检索与排障）见《日志运维.md》。

## 附A. 上下文自动补全（建议）

- 入口：CLI 生成 trace_id/job_id，并通过 contextvars 传递
- 文件/批次：file_path/file_size/bytes_read、chunk_idx/chunks_total、rows\_\*、batch_cost_ms/rows_per_sec
- 业务三元：station_id/device_id/metric_id（在合并阶段补齐），对齐窗口 window_start/window_end

## 附B. 事件命名扩展（建议）

- ingest.path.resolve：路径迁移/适配证据（base_dir + 受限 globFallback）

### 事件示例：align.merge.window（完整 JSON 示例）

以下示例为 JSON 格式日志（app.ndjson），字段按当前实现输出：

```
{"ts":"2025-08-20T06:05:02Z","level":"INFO","logger":"root","event":"align.merge.window","message":"合并完成","window_start":"2025-08-18T00:00:00Z","window_end":"2025-08-18T06:00:00Z","segmented":true,"granularity":"1h","affected_rows":12345,"rows_in":12500,"rows_deduped":155,"rows_merged":12345,"dedup_ratio":0.0124,"sql_cost_ms":842}
```

说明：

- segmented/granularity 来自 settings.merge.segmented
- affected_rows/rows_in/rows_deduped/rows_merged/dedup_ratio/sql_cost_ms 为合并统计与耗时指标
- window\_\* 为 UTC 窗口边界（字符串形式）

### 事件示例：pool.initialized（完整 JSON 示例）

```
{"ts":"2025-08-20T06:05:02Z","level":"INFO","logger":"root","event":"pool.initialized","message":"连接池初始化完成","min_size":1,"max_size":10,"host":"localhost","database":"pump_station_optimization"}
```

### 事件示例：pool.connection.acquired（完整 JSON 示例）

```
{"ts":"2025-08-20T06:05:02Z","level":"DEBUG","logger":"root","event":"pool.connection.acquired","message":"获取连接成功","wait_time_ms":5.2,"active_connections":3}
```

### task.summary（包含 diagnostics 示例）

- summary.json 示例：

```
{
  "rows_total": 100000,
  "rows_merged": 99876,
  "failures": 0,
  "backpressure_count": 2,
  "duration_ms": 300500,
  "rows_per_sec": 332.39,
  "slow_sql_top": [{"sql":"merge fact_measurements 2025-...","cost_ms":842,"affected_rows":12345}],
  "diagnostics": {
    "p50_batch_ms": 80,
    "p90_batch_ms": 120,
    "p95_batch_ms": 150,
    "p99_batch_ms": 260,
    "max_batch_ms": 420,
    "min_batch_ms": 60,
    "avg_fail_rate": 0.012,
    "p95_fail_rate": 0.023,
    "max_fail_rate": 0.05,
    "samples_count": 236,
    "backpressure_enter": 2,
    "backpressure_exit": 2
  },
  "merge": {"rows_merged": 99876, "rows_in": 100200, "rows_deduped": 324, "affected_rows": 99876, "dedup_ratio": 0.0032, "sql_cost_ms": 842},
  "copy": {"rows_read": 100200, "rows_loaded": 99876, ...}
}
```
