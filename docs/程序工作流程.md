# 程序工作流程（重排版）
> 状态说明（预对齐，基于已落地代码与数据库）
> - 运行产物：env.json 与 summary.json 已由 run-all 落地（env 合并 run_id/run_dir/config_snapshot）
> - 配置外置与来源标注：三份 YAML 模板与 sources 标注合并将在里程碑1落地；当前 loader 可读取 configs/*
> - 日志模式：json/by_run 稳定；text/by_module 已提供最小可用路由，字段模板将在里程碑2按“最小集”补齐

> 状态说明（预对齐，基于已落地代码与数据库）
> - env.json 与 summary.json：run-all 已在收尾生成 summary.json，并合并/回填 env.json（run_id/run_dir/config_snapshot）
> - 配置外置与来源标注：三份 YAML 模板与 sources 标注合并将在里程碑1落地；当前 loader 可读取 configs/*
> - 日志模式切换：json/by_run 稳定；text/by_module 提供最小可用路由，字段模板将在里程碑2补齐


> 状态板（2025-08-18）：CLI 方案B（--log-run/--log-dir）；check-mapping 支持 --out/--show-all 聚类；db-ping --verbose；已使用标准 schema（config/data_mapping.v2.json）。导入模式默认 auto（阈值 total_mb=50/per_file_mb=10/max_file_count=20，满足则直写 direct，否则 staging）；日志默认 json，可在 configs/logging.yaml 设置 format=text；支持 routing=by_module 按模块分类输出；配置拆分为 configs/{logging,ingest,database}.yaml（均含中文注释）；启动输出参数与配置快照（不脱敏）。run-all 正在修复 prepare-dim 中 dim_metric_config 返回列名不匹配问题。重启后恢复：docs/PLAYBOOKS/SESSION_SNAPSHOT_2025-08-18.md。
> 状态板（2025-08-20）：已放弃 dev-suite MCP（相关脚本/Docker/VSCode 配置已删除，PLAYBOOKS 留痕）；PR 模板新增“【必选】MCP 默认工具确认”小节；其余现状与本页一致。

> 本文为“CSV 高性能导入（方案A）”落地指南与验收标准。遵循 PROJECT_RULES.md 与 docs/ 文档体系。
> 环境限制：当前开发环境中禁止对任何表执行写操作（结构/数据），允许改动函数/视图/触发器等对象。涉及写表的导入/合并流程应在专用测试库执行；在开发库中仅进行 dry-run/只读验证。

> 提示（MCP 建议）：实施前请先使用 MCP 工具进行“任务分解/受影响范围自检”，并在实施后用 MCP 进行最小验证与文档/PLAYBOOKS 同步。参见：docs/智能助手行为控制.md#使用-mcp-工具强制规则。

## 1. 目标与范围（强制）

- 唯一事实源：config/data_mapping.json（禁止从文件名/路径推断维度/指标）
- CSV 固定列：TagName（变量名称）、DataTime（数据时间）、DataValue（数据值）
- 对齐与合并：UTC 秒级对齐（ts_bucket），PRIMARY KEY(station_id,device_id,metric_id,ts_bucket) UPSERT

## 2. 涉及对象与契约（强制）

- 维表/映射：dim_stations、dim_devices、dim_metric_config、dim_mapping_items
- 事实：fact_measurements（见《表结构与数据库》）

## 3. 程序目录与责任边界（强制）

- 采用方案A分层：app/core, app/adapters, app/services, app/cli（详见《编码规范》§35）
- 跨层经网关/适配器；copy 只 COPY，不做业务判断；merge 只做集合式合并与统计

## 4. CSV 列定义与校验（强制）

- 列名固定：TagName/DataTime/DataValue（大小写兼容）
- 解析失败：行写入 staging_rejects（error_msg、rejected_at），统计 bad_rows/decoder_errors

## 5. 文件路径定位策略（强制）

- 规则：data_mapping.json 记录相对 data/ 的路径；程序支持 base_dir（configs/ingest.yaml）
- 迁移适配（可选）：仅在 base_dir 内进行受限 globFallback；记录 event=ingest.path.resolve → summary.json 汇总

## 6. 高性能导入（方案A）流程（强制）

- 模式选择：ingest.mode 支持 auto|direct|staging（默认 auto）。当总量/单文件/文件数满足阈值（total_mb=50、per_file_mb=10、max_file_count=20）时优先 direct 直写；否则 staging。

1. prepare-dim：由 mapping 生成/更新维表与映射
1. direct（小量快速）：多线程读取→tz→UTC→秒对齐→safe_upsert_measurement(\_local) UPSERT
1. staging（大吞吐）：并发 COPY CSV → UNLOGGED staging_raw（流式，低内存）
1. 集合式合并（staging 路径）：JOIN 维度/映射 → DataTime+tz → ts_utc → ts_bucket → 去重 → INSERT…ON CONFLICT
1. 刷新 MV：小时/天；审计命中率与对齐自检

## 7. 并发与背压自适应（强制）

- 默认：workers=6；commit_interval 建议 1,000,000 行/段
- 窗口：按 UTC ISO 周界（周一 00:00:00 UTC）对齐，窗口 \[start, end)
- 背压阈值：P95>2s 或失败率>1% → 先缩批 50%，再降并发；恢复后渐进回升
- 事件：backpressure.enter/exit、guardrail.stop（见《日志规范》）

## 8. 配置与参数（强制）

- configs/ingest.yaml：base_dir, workers, commit_interval, window
- configs/logging.yaml：logging.sql.text/explain, sampling.loop_log_every_n, redaction.enable, retention_days
- 覆盖顺序：CLI > ENV > YAML > 默认；启动打印“脱敏快照”

## 9. 验收标准与自检（强制）

### 配置片段示例（ingest 与 logging）

```yaml
# configs/ingest.yaml（示例）
ingest:
  base_dir: "data"
  workers: 6
  commit_interval: 1000000
merge:
  window:
    size: "7d"   # 或使用 start/end：
    # start: "2025-08-11T00:00:00Z"
    # end:   "2025-08-18T00:00:00Z"
```

```yaml
# configs/logging.yaml（示例）
level: INFO
format: json
performance:
  queue_handler: true
logging:
  sql:
    text: summary      # summary|normalized|full_debug
    explain: on_error  # on_error|sampled|always
sampling:
  loop_log_every_n: 1000
redaction:
  enable: true
retention_days: 14
```

### 运行产物（里程碑0 基线）

- env.json：包含 args_summary（命令与关键参数）与 config_snapshot（完整 Settings，不脱敏）、ts、run_id、run_dir；用于后续排障与复现

- summary.json：包含 copy/merge 用时、backpressure enter/exit、tz_fallback_count；后续版本将补充合并影响行数/冲突比等；用于质量与性能基线

- 功能：not_aligned=0；UPSERT 合并验证；MV 刷新命中

### 配置外置与来源标注（里程碑1 最小实现）

- 配置拆分：configs/{logging.yaml, ingest.yaml, database.yaml}（中文注释）

- 优先级：CLI > ENV > YAML > 默认；base_dir 固定 data（不可覆盖）

- 启动快照：env.json 中包含 args_summary、config_snapshot 以及 sources（字段来源：DEFAULT|YAML|ENV|CLI）

- 示例（节选）：

  - sources.logging.format=CLI、sources.logging.routing=CLI（当通过 --log-format/--log-routing 覆盖时）

- CLI 覆盖键（里程碑1 扩展）

  - --log-format json|text（sources.logging.format=CLI）
  - --log-routing by_run|by_module（sources.logging.routing=CLI）
  - --log-level DEBUG|INFO|WARNING|ERROR（sources.logging.level=CLI）
  - --db-dsn-read / --db-dsn-write（sources.db.dsn_read/dsn_write=CLI）
  - --ingest-workers / --ingest-commit-interval（sources.ingest.workers/commit_interval=CLI）

- 日志：runs/YYYYMMDD/\<job_id>/ 下 app/error/sql/perf/summary/env 多流齐备，字段与开关合规

- 性能：吞吐/延迟/失败率/锁等待达标（可本地化目标）

### 里程碑2 最小实现（状态）

- 已完成：logging.format=text、logging.routing=by_module、db.exec.\* 埋点（prepare_dim/merge）
- 验证参考：docs/测试指南.md 最小窗口端到端验证步骤

## 10. 风险、回滚与审计（建议）

- 回滚：清理 staging；按窗口删除回滚；降级 SQL 文本输出
- 审计：PLAYBOOKS 登记变更与验证；summary.json 汇总关键证据

______________________________________________________________________

# 程序工作流程

> 目标：严格依据 config/data_mapping.json 的配置，生成并维护维表数据与映射快照，为后续事实数据入库（fact_measurements）提供前置条件与约束。严禁从 CSV 文件名/路径反推站点/设备/指标信息。

## 一、配置来源（唯一事实源）

- 配置文件：config/data_mapping.v2.json
  - 顶层键：泵站名称（例如："二期供水泵房"、"二期取水泵房"）
  - 二级键：设备名称（例如："二期供水泵房1#泵"、"二期供水泵房总管"、"总管" 等）
  - 设备属性：
    - type：设备类型（如 pump、Main_pipeline），数组形式，取第一个为主值
    - pump_type：泵的类型（如 variable_frequency、soft_start）；非泵/总管类设备填 null
    - 指标键（metric_key）：如 pump_frequency、pump_voltage_a、pump_voltage_b、pump_current_c、pump_active_power、pump_kwh、pump_power_factor、main_pipeline_outlet_pressure、cumulative_flow 等；其值为来源文件路径数组（仅作为来源提示 source_hint，不参与维度定义）

说明：维表与配置表信息严格以 data_mapping.json 的“站点名/设备名/type/pump_type/metric_key”为准，不允许从 CSV 文件名与路径反推出站点/设备/指标语义。

## 二、涉及的数据库对象（摘要）

见 docs/表结构与数据库.md（以下为与本流程直接相关的表）：

- public.dim_stations（泵站维表）：id, name, extra(jsonb 推荐包含 tz)
- public.dim_devices（设备维表）：id, station_id(FK), name(同站内唯一), type, pump_type, extra
- public.dim_metric_config（指标配置）：id, metric_key(唯一), unit, unit_display, decimals_policy, fixed_decimals, value_type, valid_min, valid_max
- public.dim_mapping_items（映射快照）：id, mapping_hash, station_name, device_name, metric_key, source_hint
- public.fact_measurements（时序事实，分区父表结构）：id, station_id, device_id, metric_id, ts_raw, ts_bucket(秒对齐), value, source_hint, inserted_at

约束提醒：

- fact_measurements 主键：(station_id, device_id, metric_id, ts_bucket)；ts_bucket 必须整秒对齐（CHECK）。
- 写入建议使用 DB 函数：safe_upsert_measurement（UTC）/safe_upsert_measurement_local（本地时间+站点时区）。

## 三、生成/维护规则

1. 站点维表 dim_stations

- 规则：对 data_mapping.json 顶层每个站点名，若不存在则创建一条记录；name=站点名
- extra：建议包含 {"tz": "Asia/Shanghai"} 等时区信息（若配置无 tz，请在落地前补充）

2. 设备维表 dim_devices

- 规则：对每个站点下的每个设备名，若不存在则创建一条记录；
  - station_id：必须引用对应 dim_stations.id（外键语义）
  - name：= 设备名（同一 station_id 内唯一）
  - type：来自 data_mapping.json 的 type\[0\]
  - pump_type：来自 pump_type\[0\]；若 type != "pump"（如 Main_pipeline），则设为 null
- 注意：dim_devices.station_id 必须与 dim_stations.id 关联，确保设备归属泵站明确

3. 指标配置 dim_metric_config

- 规则：收集所有设备声明过的 metric_key（去重），为缺失项补充配置行；
  - metric_key：如 frequency、voltage_a、current_a、power、kwh、power_factor、pressure、flow_rate、cumulative_flow
  - unit / unit_display：按常用物理量给出默认值（可后续调整）：
    - frequency: Hz
    - voltage_a/voltage_b/voltage_c: V
    - current_a/current_b/current_c: A
    - power: kW（如原始为 W，请在导入时统一换算或将 unit 设置为 W）
    - kwh: kWh
    - power_factor: 1（无量纲，可置空 unit 或使用 ""）
    - pressure: MPa（或 kPa，依数据源单位选择其一并保持一致）
    - flow_rate: m3/h（或 L/s，依数据源单位选择其一并保持一致）
    - cumulative_flow: m3
  - decimals_policy：默认 as_is；fixed_decimals/value_type/valid_min/valid_max 视数据质量策略后续迭代

4. 映射快照 dim_mapping_items

- 规则：为每个 (站点名, 设备名, metric_key) 生成一条映射记录
  - mapping_hash：可用 hash(站点名 + "|" + 设备名 + "|" + metric_key)
  - source_hint：固定为 "data_mapping.json"（不写入任何 CSV 文件名/路径）
- 用途：形成稳定、可审计的“配置→维度→指标”映射快照

5. 事实表 fact_measurements（入库约束与建议）

- 入库前提：对应的 station_id/device_id/metric_id 必须已存在并正确关联
- 时间约束：ts_bucket 必须为整秒（date_trunc('second', ts_utc)），建议统一 UTC 存储
- 写入方式：优先通过 safe_upsert_measurement / safe_upsert_measurement_local，保证主键冲突时按策略合并
- source_hint：可写入 "ingest"/"convert" 等来源标签；不依赖文件名

## 四、流程步骤（建议实施顺序）

1. 解析 data_mapping.json
   - 遍历顶层站点名、二级设备名、读取 type/pump_type/metric_key 列表
1. 同步 dim_stations
   - 若不存在则 INSERT；建议补充 extra.tz
1. 同步 dim_devices
   - 依据站点与设备名 upsert；写入 type、pump_type（非泵设 null）
1. 同步 dim_metric_config
   - 依据全量 metric_key 集合 upsert；按上表填充 unit/decimals_policy 等默认值
1. 生成 dim_mapping_items 快照
   - 对每个 (站点, 设备, metric_key) 生成/更新一条记录；source_hint 固定为 "data_mapping.json"
     6.（可选）导入数据与验证
   - 按接口将数据写入 fact_measurements（与本流程解耦）；
   - 执行一致性检查：所有 fact 行的外键三元组 (station_id, device_id, metric_id) 必须在各维表中有效存在

## 五、数据加载与时间对齐（整合《泵站时间对齐实现》）

- 前提：dim_stations、dim_devices、dim_metric_config、dim_mapping_items 已根据 data_mapping.json 生成并校验无误
- CSV 加载：开始加载 CSV 数据，按站点驱动对齐；严禁从文件名/路径反推维度与指标
- 对齐规则（来自《泵站时间对齐实现》）：
  - 统一 UTC：写入时间统一转换为 UTC
  - 秒级对齐：ts_bucket = date_trunc('second', ts_utc)
  - 主键： (station_id, device_id, metric_id, ts_bucket)
  - 冲突合并：ON CONFLICT(...) DO UPDATE，按策略合并 value/source_hint
  - 时区优先级：入参 tz > dim_stations.extra->>'tz' > 默认 UTC
  - CHECK 兜底：CHECK(date_trunc('second', ts_bucket) = ts_bucket)
- 推荐写入函数：
  - public.safe_upsert_measurement(station_id, device_id, metric_id, ts_utc, value, source_hint)
  - public.safe_upsert_measurement_local(station_id, device_id, metric_id, ts_local, value, source_hint)
- 典型流程（可视作简化版）：
  1. 解析 CSV 记录，定位对应的 station_id/device_id/metric_id（三者必须已存在）
  1. 若记录时间含 tz，则转 UTC；否则查 dim_stations.extra->>'tz' 转 UTC
  1. 取整秒 ts_bucket 并调用 safe_upsert\_\* 完成写入与合并
- 参考：详见 docs/泵站时间对齐实现.md（原理、示例与自检 SQL）

## 五、校验与注意事项

- 禁止从 CSV 文件名/路径推断维度与指标：仅以 data_mapping.json 的结构信息为准

## 六、干跑校验与自动生成 SQL（实践指南）

- 干跑（不写库）：

  - 目的：在写库前检查 mapping 的站点/设备/metric 概览与规则符合性
  - 运行：python scripts/dev/dry_run_mapping_validation.py
  - 输出：数量汇总与前若干条映射样例；提示 type/pump_type 等规则

- 自动生成维表/映射 SQL（不写库）：

  - 运行：python scripts/dev/generate_seed_from_mapping.py
  - 产物：scripts/dev/seed_from_mapping.sql（执行 psql -f）
  - 说明：只做 upsert，不覆盖已有配置；单位默认值可后续在 dim_metric_config 调整

- CSV 中 DataVersion、DataQuality 字段忽略，不参与维度/指标映射

- 单位一致性：若数据源单位与 dim_metric_config 默认不一致，请统一换算后入库（或调整 dim_metric_config.unit 并全程保持一致）

- 时区与对齐：按项目总纲，写入统一为 UTC，ts_bucket 秒级对齐；本地时间写入需携带站点时区（见 safe_upsert_measurement_local）

- 幂等与可追溯：建议使用 UPSERT 与映射快照，配合 PLAYBOOKS 记录变更

## 六、扩展与后续

## 七、规范与日志（强约束链接）

- 编码规范（唯一权威）：见 docs/编码规范.md

- 日志规范（唯一权威）：见 docs/日志规范.md

- 日志运维（唯一权威）：见 docs/日志运维.md

- 若后续为设备补充额定参数，请使用 device_rated_params（如 rated_flow、rated_head 等）

- 若需为汇总层（mv_measurements_hourly/daily）提供指标覆盖，请确保 metric_key 与单位与事实层保持一致

______________________________________________________________________

附：常见 metric_key 与含义（可按需扩展）

- pump_voltage_c：泵C相电压
- pump_cumulative_flow：泵累计流量
- pump_efficiency：泵效率
- pump_frequency：泵变频器频率
- main_pipeline_Inlet_pressure：总管进口压力
- main_pipeline_flow_rate：总管瞬时流量
- pump_active_power：泵有功功率
 
