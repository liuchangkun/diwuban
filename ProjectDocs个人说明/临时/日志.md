# 日志功能规范（项目版）

本文档在“日志功能规范（全面版）/logging-guide.md、10-日志功能规范.md”的基础上，结合本项目现状（PostgreSQL、按泵站时区对齐、并发 COPY + 库端合并、MV 刷新与命中审计）进行裁剪与落地，作为 app/ 程序的唯一日志规范。

## 1. 目标与原则

- 目标：提供上下文完整、可观测、可审计、低开销的日志体系，支持大规模 CSV 导入与生产运维。
- 原则：结构化（默认 JSON）/可配置/最少开销/可溯源/合规脱敏。
- 等级：DEBUG/INFO/WARN/ERROR/CRITICAL；生产默认 INFO。

## 2. 事件命名规范

- 统一格式：`<domain>.<action>[.detail]`
- 域建议：ingest/align/db/mv/audit/task/guardrail/backpressure/quality/cli
- 常用事件：
  - ingest.load.begin / ingest.load.end / ingest.load.progress
  - align.merge.begin / align.merge.batch / align.merge.window / align.merge.end / align.conflict
  - db.retry / db.error / db.summary
  - mv.refresh.begin / mv.refresh.end
  - audit.mv / audit.alignment
  - backpressure.enter / backpressure.exit
  - guardrail.stop / guardrail.resume
  - task.summary

## 3. 结构化字段规范

- 通用字段（必须）：`ts`(ISO8601)、`level`、`event`、`message`(可选)、`logger/module/func/line/file/pid/thread`
- 关联上下文（建议统一注入）：
  - 追踪：`trace_id`、`job_id`、`batch_id`
  - 业务：`station_id`、`station_name`、`device_id`、`device_name`、`metric_id`、`metric_key`
  - 文件：`file_path`、`file_name`、`file_hash`、`file_offset`、`bytes_read`
  - 数据量：`rows_total`、`rows_read`、`rows_loaded`、`rows_deduped`、`rows_merged`、`rows_failed`
  - 时间窗口：`window_start`、`window_end`
  - 数据库：`sql_op`(LOAD/INSERT/UPDATE/SELECT)、`sql_cost_ms`、`affected_rows`、`target_table`
  - 重试：`attempt`、`max_attempts`、`backoff_ms`
  - 异常：`exc_type`、`exc_message`、`stack`
- 脱敏：账号/密码/令牌/连接串/PII 一律打码。日志中仅记录 DB 主机别名/库名，不记录明文凭据。

## 4. 配置与初始化

- 配置文件：`configs/logging.yaml`（可选）；ENV/CLI 可覆盖：`LOG_LEVEL`、`LOG_FORMAT`(json|text)、`LOG_FILE_PATH`、`--log-json/--no-log-json`、`--log-file`、`--no-console`。
- 推荐使用 `logging` + `LoggerAdapter`；生产默认启用 `QueueHandler/QueueListener` 异步写盘，异常路径可回退同步。
- JSON 编码器：统一使用紧凑分隔（`,:`），限制单条日志大小（默认 8KB），超限截断并添加 `truncated=true`。

## 5. 上下文注入与传递

- 入口（CLI/任务）生成 `trace_id`、`job_id`；在子任务/线程复用（contextvars）。
- 使用 `LoggerAdapter` 在 `extra` 中注入公共上下文字段；局部补充（如 file_path、window_start）。

## 6. 采样、限流与轮转

- 采样：`debug_sample_rate` 控制 DEBUG 比例（默认 0.0）；批处理路径使用 `loop_log_every_n`（默认 1000）输出进度。
- 限流：限制单条日志大小；热路径合并摘要日志（如每批次输出一次聚合计数与耗时）。
- 轮转：按天/按大小滚动文件（默认 10MB * 10 份，或按天保留 14 天）。容器环境优先 stdout/stderr。

## 7. 错误、重试与背压

- 错误记录：`event` 指向领域动作；附 `exc_type/exc_message/stack`；`hint` 给出修复建议（如“检查 CSV 列名/时间格式”）。
- 可重试错误（PostgreSQL 常见）：连接中断、超时、`deadlock_detected`、`serialization_failure(40001)` → 指数退避 + 抖动，记录 `attempt/max_attempts/backoff_ms/sql_op`。
- 背压门禁：当 `失败率/批次 P95/锁等待` 超阈 → 降并发/缩批；恢复后回升；分别记录 `backpressure.enter/exit`。
- 停止门禁：连续窗口不达标，停止某站点导入并记录 `guardrail.stop`。

## 8. 关键节点日志规范（建议最少集）

- ingest.load.begin：`file_path/rows_total?`（未知可不填）
- ingest.load.progress：每 N 行或每文件分段输出 `rows_read/bytes_read`（采样）
- ingest.load.end：`rows_loaded/cost_ms`
- align.merge.window：每个时间窗口的输入/输出/去重/合并统计 + `sql_cost_ms/affected_rows`
- align.conflict：同秒冲突/合并数（抽样即可）
- mv.refresh.begin / mv.refresh.end：刷新对象与耗时
- audit.mv：读数（hourly_hits/daily_hits/fact_hits/total）
- task.summary：总览（文件数/行数/耗时/失败/重试/背压决策），程序退出前输出一次

## 9. 与程序阶段对应关系

- prepare-dim：统计新增/忽略的 dim\_\*、映射条目数（INFO）
- create-staging：创建/存在即跳过（INFO）；DDL 失败（ERROR）
- ingest:copy：每文件 begin/progress/end；故障退避（WARN/ERROR）
- merge:fact：按窗口 begin/batch/window/end；去重与冲突统计；故障退避（WARN/ERROR）
- refresh:mv：begin/end + 成功/失败
- audit:mv：读数输出（INFO）

## 10. 示例（JSON 行）

```json
{"ts":"2025-08-18T02:00:03Z","level":"INFO","event":"align.merge.window","trace_id":"t-1","job_id":"j-1","window_start":"2025-08-11","window_end":"2025-08-18","rows_merged":49876,"sql_cost_ms":320,"affected_rows":49876}
```

## 11. 验收与测试

- 单测：字段完整性/脱敏规则/配置覆盖；`caplog` 捕获验证。
- 集成：高并发 COPY + 合并下的日志吞吐与轮转；异常路径包含 stack 与上下文。
- E2E：run-all 跑通后检查 `task.summary` 与核心指标一致；抽查 `audit.mv` 与 MV 行数。

## 12. 安全与合规

- 禁止记录敏感信息；统一通过配置 `redaction.patterns` 执行脱敏（如密码/令牌/连接串）。
- 仅在必要时记录 SQL 摘要：操作类别/表/影响行数/耗时，不记录完整 SQL 与参数。

## 13. 与项目文档的关系

- 本规范与《程序工作流程.md》《数据库函数参考.md》一致；作为 app/ 程序日志唯一参考。
- 如需对接 ELK/ClickHouse/Promtail 等，请保持 JSON 字段稳定，新增字段向后兼容。

## 14. 配置模板（configs/logging.yaml）

```yaml
level: INFO            # DEBUG/INFO/WARN/ERROR/CRITICAL
format: json           # json|text
console: true
file:
  enabled: true
  path: logs/app.log
  rotate: daily        # daily|size
  max_bytes: 10485760  # 10MB，仅在 rotate=size 时生效
  backup_count: 10
  retention_days: 14
sampling:
  debug_sample_rate: 0.0
  loop_log_every_n: 1000
context:
  include_fields: [trace_id, job_id, batch_id, station_id, device_id, file_path]
  include_sql_cost: true
  include_stack: true
redaction:
  enable: true
  patterns:
    - '(?i)(password|passwd|pwd|secret|token)=[^&\s]+'
  replacement: '***'
performance:
  queue_handler: true  # 启用异步队列日志
  flush_on_exit: true
```

## 15. 初始化示例（Python）

```python
import logging, json, yaml
from logging.config import dictConfig
from pathlib import Path

def init_logging(cfg_path: Path, overrides: dict | None = None) -> None:
    cfg = yaml.safe_load(cfg_path.read_text(encoding="utf-8")) if cfg_path.exists() else {}
    overrides = overrides or {}
    # ENV/CLI 覆盖（示例）
    for k, v in overrides.items():
        if v is not None:
            # 简单合并，复杂结构可递归 merge
            cfg[k] = v
    dictConfig(_to_dict_config(cfg))

def _to_dict_config(cfg: dict) -> dict:
    # 省略实际完整实现：根据 cfg 组装 dictConfig 字典（handlers/formatters/filters/root）
    ...
```

## 16. 上下文注入与传递

```python
import logging, contextvars
trace_id_var = contextvars.ContextVar("trace_id", default=None)

def set_trace_id(tid: str):
    trace_id_var.set(tid)

def get_trace_id() -> str | None:
    return trace_id_var.get()

class CtxAdapter(logging.LoggerAdapter):
    def process(self, msg, kwargs):
        extra = {"trace_id": get_trace_id()} | (kwargs.get("extra") or {})
        kwargs["extra"] = extra
        return msg, kwargs

log = CtxAdapter(logging.getLogger(__name__), {})
```

## 17. 异步队列日志（QueueHandler/QueueListener）

```python
import logging, logging.handlers
from queue import Queue
queue = Queue(maxsize=10000)
handler = logging.handlers.QueueHandler(queue)
listener = logging.handlers.QueueListener(queue, logging.StreamHandler())
root = logging.getLogger()
root.setLevel(logging.INFO)
root.addHandler(handler)
listener.start()
# 退出时 listener.stop()，确保刷盘
```

## 18. 采样/限流 Filter 示例

```python
import logging, random
class SamplingFilter(logging.Filter):
    def __init__(self, debug_rate: float = 0.0, every_n: int = 1000) -> None:
        super().__init__()
        self.debug_rate = debug_rate
        self.every_n = every_n
        self._c = 0
    def filter(self, rec: logging.LogRecord) -> bool:
        if rec.levelno == logging.DEBUG:
            return random.random() < self.debug_rate
        self._c += 1
        if self.every_n and (self._c % self.every_n == 0):
            return True
        return True
```

## 19. SQL 摘要日志规范

- 仅记录操作类别/对象/影响行数/耗时，不输出完整 SQL 及参数。
- 字段建议：`sql_op`（LOAD/INSERT/UPDATE/SELECT）、`target_table`、`tables`、`sql_cost_ms`、`affected_rows`。
- 多表 JOIN 可记录 `tables=[a,b]`。

## 20. 背压门禁参数（建议默认）

- 吞吐目标：≥ 50,000 行/秒；未达标 → 降并发或缩小批次
- P95 批次耗时：≤ 2000ms；超阈 → 拆批/降并发 50%
- 失败率：≤ 1%（停止阈 2%）；超阈 → backpressure.enter/必要时 guardrail.stop
- 锁等待：接近 0；升高 → 先减小提交行数，再降并发

## 21. 标准化错误输出（CLI 友好）

```json
{"error_code":"INVALID_INPUT","message":"配置校验失败","hint":"修复缺失字段","context":{"file":"configs/app.yaml"}}
```

## 22. 测试与基准建议

- 单测：caplog 验证字段与采样；脱敏规则命中。
- 集成：并发 COPY + 合并下日志吞吐、轮转与丢失率（Queue 溢出检测）。
- 压测：不同 workers/批次下的 `rows_*` 与 `batch_cost_ms/merge_cost_ms`。

## 23. 运维与落盘策略

- 容器：优先 stdout/stderr，由采集端收集；本地/Server 可启用文件轮转。
- 变更审计：记录日志配置的关键变更（级别/采样/限流/队列开关）。
- 退出顺序：先 stop QueueListener，再退出进程，失败回退 stderr 最小字段集。

## 24. 业务功能日志字段（领域增强）

- 适用：导入/对齐/合并/特征计算/报表出数/校验/告警
- 字段建议：
  - 业务：`biz_domain`(ingest|align|feature|report|quality|alert)、`biz_action`、`scenario`
  - 对齐/合并：`conflict_count`、`dedupe_ratio`、`merge_strategy`（latest|max|avg）、`source_priority`
  - 质量：`anomaly_type`、`threshold`、`actual`、`policy_id`、`policy_version`
  - 报表：`report_name`、`time_gran`(hour|day) 、`rows_output`、`mv_hit`(true|false)

## 25. 性能指标与吞吐字段（端到端）

- 批处理与窗口：`batch_cost_ms`、`merge_cost_ms`、`rows_per_sec`、`rows_deduped`、`rows_merged`
- 资源快照（可选）：`cpu_pct`、`rss_mb`、`queue_depth`（日志队列/任务队列）
- 门禁窗口：`p95_batch_ms`、`fail_rate`、`lock_waits`、`adjustment`（降并发/缩批）

## 26. 模型训练/评估日志（如后续接入 ML）

- 训练作业：`ml_job_id`、`ml_stage`(train|eval|tune|deploy)、`dataset_id`、`data_version`、`feature_version`
- 超参：`optimizer`、`lr`、`batch_size`、`epochs`、`seed`
- 进度：`epoch`、`step`、`steps_total`、`loss`、`metric_acc`、`metric_mae`（按需）
- 校验/对比：`baseline_job_id`、`delta_metric`、`early_stop`、`checkpoint`
- 部署：`model_version`、`canary_percent`、`rollback`（bool）

## 27. 文件加载日志（扫描/解压/读取）

- 文件：`file_path`、`file_name`、`file_size`、`compress`(none|gz|zip) 、`encoding`
- 读取：`bytes_read`、`lines_read`、`ts_min`、`ts_max`、`chunk_idx`、`chunks_total`
- 错误：`decode_errors`、`bad_rows`、`skip_policy`
- 吞吐：`read_cost_ms`、`read_bytes_per_sec`

## 28. SQL 执行日志增强（状态/语句/计划）

- 状态：`sql_state`(started|succeeded|failed|retried)、`sql_try`、`sql_op`、`target_table`、`affected_rows`、`sql_cost_ms`、`wait_event`（可选）
- 语句：
  - `sql_mode`(summary|normalized|full_debug) —— 由配置控制，默认 summary
  - `sql_hash` —— 语句指纹（MD5/xxhash），便于聚合分析
  - `sql_text` —— 仅在 normalized/full_debug 输出；参数脱敏、执行长度与大小上限（默认 2KB），超限 `truncated=true`
  - `sql_params_logged`(bool) —— 默认 false；开启时仅输出非敏感值；受 redaction 保护
- 计划（可选）：`explain_format=json` 的关键字段摘要，如 `plan_node`、`total_cost`、`rows`
- 错误：`pgcode`、`pgerror`、`hint`、`constraint`、`detail`（失败时）

## 29. 线程/并发上下文

- 线程：`thread_id`、`thread_name`、`worker_index`、`pool`（连接池/线程池名称）
- 任务：`task_id`（协程/任务 ID）、`station_group`（站点并发分组）、`window_key`（周/日窗口）
- 进程：`pid`（已有）、`instance_id`（多实例部署区分）

## 30. SQL 记录策略与安全开关（配置项）

- `logging.sql.text`: none|summary|normalized|full_debug（默认 summary）
- `logging.sql.max_len`: 2048（超过截断并打 `truncated=true`）
- `logging.sql.params`: false（仅在 debug/排障临时开启，受脱敏规则保护）
- `logging.sql.explain`: off|on_error|sampled|always（默认 on_error）
- `logging.redaction.enable`: true；`patterns` 与 `replacement` 详见第 14 节模板

## 31. 示例（SQL 成功/失败/采样计划）

```json
{"event":"db.exec","sql_state":"succeeded","sql_op":"INSERT","target_table":"fact_measurements","affected_rows":49876,"sql_cost_ms":320,"sql_mode":"summary","sql_hash":"ab12..."}
{"event":"db.exec","sql_state":"failed","sql_op":"INSERT","target_table":"fact_measurements","pgcode":"40001","hint":"重试","attempt":2,"backoff_ms":400}
{"event":"db.exec","sql_state":"succeeded","sql_op":"SELECT","sql_mode":"normalized","sql_text":"select id from d where name=$1","sql_hash":"9f00...","explain":{ "plan_node":"Index Scan","total_cost":8.17,"rows":1 }}
```

## 32. 业务/性能/文件/线程综合示例

```json
{"event":"ingest.load.progress","station_name":"二期供水泵房","file_path":"data/pump1.csv.gz","bytes_read":104857600,"lines_read":1000000,"chunk_idx":5,"chunks_total":20,"read_bytes_per_sec":1200000,"thread_name":"ingest-3","worker_index":3}
{"event":"align.merge.window","station_id":1,"window_start":"2025-08-11","window_end":"2025-08-18","rows_deduped":50000,"rows_merged":49876,"batch_cost_ms":1800,"rows_per_sec":27700,"p95_batch_ms":1900,"lock_waits":0}
```

## 33. 与程序实现的映射建议

- app 层：
  - 文件加载模块记录 27 节字段；并以 `loop_log_every_n` 节流
  - 合并模块在窗口级输出 25/28 节关键指标；失败时输出 7/28 节错误字段
  - SQL 网关统一打点（开始/成功/失败），遵循 28/30 节的开关与脱敏
  - 日志适配器统一注入 29 节的线程/任务上下文
- 配置层：在 `configs/logging.yaml` 增加 30 节的开关，CLI/ENV 可覆盖
- 测试与验收：单测覆盖开关生效、脱敏正确、大小截断、计划采样；E2E 验证 `task.summary` 与统计一致
