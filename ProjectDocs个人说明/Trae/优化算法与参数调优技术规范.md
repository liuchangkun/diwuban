# 优化算法与参数调优技术规范

> 目标：将原有技术规范中"优化算法与参数调优"及"泵组优化算法规范"的内容抽离为独立文档，统一描述优化问题建模、算法选择、参数调优与工程化落地，减少主文档行数并提升可维护性。

## 如何使用本规范

### 🎯 新入职算法工程师快速启动

1. **熟悉优化问题建模**：阅读第2章，理解决策变量、目标函数、约束定义方式
1. **选择合适算法**：根据问题特征（单/多目标、连续/离散）选择第3-4章对应算法
1. **实现泵组优化**：参考第5章的实际应用场景与算法集成方案
1. **参数调优实践**：按第6章流程进行参数搜索与性能评估

### 📋 日常开发检查清单

- [ ] 优化问题是否按第2章接口约定实现（objective/constraints/bounds）
- [ ] 算法选择是否考虑问题规模与收敛要求
- [ ] 参数调优是否遵循第6章的系统化流程
- [ ] 结果评估是否包含第7章要求的可视化与统计分析
- [ ] 配置管理是否按第8章规范化（可复现、版本控制）

### 🔍 常见问题快速导航

- **多目标权衡决策** → 第4章 NSGA-II 与帕累托前沿分析
- **算法收敛性问题** → 第6章停止准则与早停策略
- **参数敏感性分析** → 第7章敏感性评估方法
- **工程化部署配置** → 第8章配置模型与日志规范

______________________________________________________________________

## 1. 适用范围与术语

- 适用范围：水泵/泵站运行策略优化、曲线拟合参数反求、系统能效优化与多目标权衡。
- 术语约定：
  - 决策变量 x：连续或离散参数，含运行点、启停组合、频率/阀位等。
  - 目标函数 f(x)：单目标或多目标（能耗、效率、磨损、稳定性）。
  - 约束 g(x) ≤ 0, h(x) = 0：流量/压力/容量/运行边界/检修窗口等。

## 2. 优化问题建模

- 决策空间：由 OptimizationBounds 定义上下界与维度；离散变量建议编码为整数并在算子中做型值修复。
- 目标定义：支持最小化/最大化；多目标时输出向量并采用帕累托支配关系。
- 约束处理：
  - 软约束：罚函数/可行性优先排序。
  - 硬约束：解修复、边界投影、可行性保持算子。
- 接口约定：
  - objective(x: ndarray) -> float | dict\[str, float\]
  - constraints(x: ndarray) -> dict\[str, bool\]
  - bounds: OptimizationBounds(lower: list\[float\], upper: list\[float\])

## 3. 单目标全局优化算法

- 遗传算法（GeneticAlgorithmOptimizer）
  - 关键阶段：种群初始化→适应度评估→选择（锦标赛/轮盘赌）→交叉（单点/均匀/SBX）→变异（多项式/高斯）→边界修复。
  - 可调参：population_size, generations, crossover_rate, mutation_rate, elitism。
  - 收敛监控：最优值曲线、种群多样性、早停（阈值/耐心）。
- 粒子群优化（ParticleSwarmOptimizer）
  - 参数：w, c1, c2，速度上限 v_max，位置边界投影。
  - 策略：线性递减惯性权重/自适应权重，局部/全局邻域拓扑。
- 贝叶斯优化（BayesianOptimizer）
  - 核心：高斯过程回归器 + 采集函数（EI/PI/UCB）。
  - 技巧：标准化输入/输出、重复启动 n_restarts、采集函数最大化使用边界与随机重启。

## 4. 多目标优化（NSGA-II）

- 流程：非支配排序→拥挤距离→锦标赛选择→SBX交叉→多项式变异→环境选择。
- 指标：
  - 帕累托前沿近似质量与分布均匀性。
  - 超体积（Hypervolume，≤3 目标时简化计算）。
- 实践建议：保持足够种群规模与代数，必要时启发式重启以避免早熟收敛。

## 5. 泵组优化算法规范

- 优化目标：
  - 能耗最小化：min Σ P_i(t)
  - 效率最大化：max Σ η_i(t)·Q_i(t)
  - 磨损最小化：min Σ wear_rate_i(t)
  - 稳定性最大化：min Σ vibration_i(t)
- 算法集成：
  - 经典：Nelder–Mead、梯度、BFGS/Newton（可用于连续可导子问题的精修）。
  - 启发式：GA/PSO/差分进化/模拟退火/蚁群（适合非凸、离散混合）。
  - 强化学习：PPO/DDPG 等在泵站环境上进行策略学习，用于在线/近实时决策。
- 约束处理与解修复：
  - 流量需求、压力要求、泵型/台数容量、运行上下限、检修计划。
  - 统一的 ConstraintHandler：validate_solution → repair_solution。

## 6. 参数调优与停止准则

- 调参流程：
  1. 确定搜索空间（对数/线性尺度）；
  1. 粗粒度网格/随机搜索预筛；
  1. 贝叶斯优化精修（以验证指标为目标）；
  1. 交叉验证与鲁棒性评估（多随机种子）。
- 停止准则：
  - 迭代上限、无改进轮数、目标阈值达成、预算（时间/评估次数）。
- 复现性：固定随机种子、记录配置快照与数据版本。

## 7. 结果评估与可视化

- 单目标：最优值曲线、参数收敛轨迹、敏感性分析（偏导/扰动）。
- 多目标：帕累托前沿散点、超体积随代数变化、目标间权衡曲线。
- 运行统计：
  - 评估次数、迭代耗时、失败/修复比率、可行解比例。

## 8. 工程化与配置

- 配置模型（示例字段）：
  - GA：population_size, generations, crossover_rate, mutation_rate, elitism。
  - PSO：swarm_size, inertia_w, c1, c2, v_max。
  - BO：kernel, acquisition_function, initial_points, n_restarts_optimizer。
  - NSGA-II：population_size, generations, crossover_rate, mutation_rate。
- 统一日志：记录算法、参数、约束、结果与耗时（中文日志）。
- 失败恢复：定期快照（checkpoint），支持从最近世代/迭代续跑。

## 9. 附录：接口与数据结构约定（示意）

```python
# 决策空间边界
@dataclass
class OptimizationBounds:
    lower: list[float]
    upper: list[float]

# 目标函数约定（单目标）
# def objective(x: np.ndarray) -> float: ...

# 目标函数约定（多目标）
# def objectives(x: np.ndarray) -> dict[str, float]:
#     return {"energy": energy_cost, "efficiency": -eff, "wear": wear, "stability": vib}

# 约束协议
# def constraints(x: np.ndarray) -> dict[str, bool]:
#     return {"flow_demand": True, "pressure_requirement": True}
```

## 10. 完整可执行算法示例

### 10.1 遗传算法实现

```python
"""
遗传算法优化器
支持连续变量优化，包含选择、交叉、变异等基本操作
"""
import numpy as np
import logging
from typing import Dict, Any, Optional, Callable, List, Tuple
from dataclasses import dataclass
import matplotlib.pyplot as plt
from concurrent.futures import ThreadPoolExecutor
import time

# 日志初始化（示例代码使用者可按需调整）
logger = logging.getLogger(__name__)

@dataclass
class GAConfig:
    """遗传算法配置参数"""
    population_size: int = 50
    generations: int = 100
    crossover_rate: float = 0.8
    mutation_rate: float = 0.1
    elitism: int = 2  # 精英个体数量
    tournament_size: int = 3
    early_stopping_patience: int = 20
    early_stopping_threshold: float = 1e-6
    random_seed: Optional[int] = None
    n_jobs: int = 1  # 并行评估任务数

class GeneticAlgorithmOptimizer:
    """
    遗传算法优化器

    用于求解连续变量优化问题，支持单目标最小化
    """

    def __init__(self, config: GAConfig):
        """
        初始化遗传算法优化器

        参数:
            config: 算法配置参数
        """
        self.config = config
        self.best_fitness_history: List[float] = []
        self.diversity_history: List[float] = []
        self.generation = 0

        if config.random_seed is not None:
            np.random.seed(config.random_seed)

    def initialize_population(self, bounds: 'OptimizationBounds') -> np.ndarray:
        """
        初始化种群

        参数:
            bounds: 决策变量边界

        返回:
            初始种群矩阵 (population_size, n_variables)
        """
        n_vars = len(bounds.lower)
        population = np.random.uniform(
            low=bounds.lower,
            high=bounds.upper,
            size=(self.config.population_size, n_vars)
        )

        logger.info(f"初始化种群完成，种群大小: {self.config.population_size}, 变量维度: {n_vars}")
        return population

    def evaluate_population(self, population: np.ndarray, objective_func: Callable[[np.ndarray], float]) -> np.ndarray:
        """
        评估种群适应度

        参数:
            population: 种群矩阵
            objective_func: 目标函数

        返回:
            适应度数组
        """
        if self.config.n_jobs == 1:
            # 串行评估
            fitness = np.array([objective_func(individual) for individual in population])
        else:
            # 并行评估
            with ThreadPoolExecutor(max_workers=self.config.n_jobs) as executor:
                fitness = np.array(list(executor.map(objective_func, population)))

        return fitness

    def tournament_selection(self, population: np.ndarray, fitness: np.ndarray) -> np.ndarray:
        """
        锦标赛选择

        参数:
            population: 种群矩阵
            fitness: 适应度数组

        返回:
            选择的父代个体
        """
        n_individuals = len(population)
        selected_indices = []

        for _ in range(n_individuals):
            # 随机选择参与锦标赛的个体
            tournament_indices = np.random.choice(
                n_individuals,
                size=self.config.tournament_size,
                replace=False
            )

            # 选择锦标赛中适应度最好的个体
            best_idx = tournament_indices[np.argmin(fitness[tournament_indices])]
            selected_indices.append(best_idx)

        return population[selected_indices]

    def sbx_crossover(self, parent1: np.ndarray, parent2: np.ndarray, bounds: 'OptimizationBounds', eta: float = 20.0) -> Tuple[np.ndarray, np.ndarray]:
        """
        模拟二进制交叉 (SBX)

        参数:
            parent1, parent2: 父代个体
            bounds: 变量边界
            eta: 分布指数

        返回:
            两个子代个体
        """
        if np.random.random() > self.config.crossover_rate:
            return parent1.copy(), parent2.copy()

        child1, child2 = parent1.copy(), parent2.copy()

        for i in range(len(parent1)):
            if np.random.random() <= 0.5:
                if abs(parent1[i] - parent2[i]) > 1e-14:
                    if parent1[i] < parent2[i]:
                        y1, y2 = parent1[i], parent2[i]
                    else:
                        y1, y2 = parent2[i], parent1[i]

                    yl, yu = bounds.lower[i], bounds.upper[i]

                    # 计算beta值
                    beta1 = 1.0 + (2.0 * (y1 - yl) / (y2 - y1))
                    beta2 = 1.0 + (2.0 * (yu - y2) / (y2 - y1))

                    alpha1 = 2.0 - beta1**(-(eta + 1.0))
                    alpha2 = 2.0 - beta2**(-(eta + 1.0))

                    u1, u2 = np.random.random(), np.random.random()

                    if u1 <= (1.0 / alpha1):
                        betaq1 = (u1 * alpha1)**(1.0 / (eta + 1.0))
                    else:
                        betaq1 = (1.0 / (2.0 - u1 * alpha1))**(1.0 / (eta + 1.0))

                    if u2 <= (1.0 / alpha2):
                        betaq2 = (u2 * alpha2)**(1.0 / (eta + 1.0))
                    else:
                        betaq2 = (1.0 / (2.0 - u2 * alpha2))**(1.0 / (eta + 1.0))

                    child1[i] = 0.5 * ((y1 + y2) - betaq1 * (y2 - y1))
                    child2[i] = 0.5 * ((y1 + y2) + betaq2 * (y2 - y1))

        # 边界修复
        child1 = np.clip(child1, bounds.lower, bounds.upper)
        child2 = np.clip(child2, bounds.lower, bounds.upper)

        return child1, child2

    def polynomial_mutation(self, individual: np.ndarray, bounds: 'OptimizationBounds', eta: float = 20.0) -> np.ndarray:
        """
        多项式变异

        参数:
            individual: 个体
            bounds: 变量边界
            eta: 分布指数

        返回:
            变异后的个体
        """
        mutated = individual.copy()

        for i in range(len(individual)):
            if np.random.random() <= self.config.mutation_rate:
                y = individual[i]
                yl, yu = bounds.lower[i], bounds.upper[i]

                delta1 = (y - yl) / (yu - yl)
                delta2 = (yu - y) / (yu - yl)

                u = np.random.random()

                if u <= 0.5:
                    xy = 1.0 - delta1
                    val = 2.0 * u + (1.0 - 2.0 * u) * (xy**(eta + 1.0))
                    deltaq = val**(1.0 / (eta + 1.0)) - 1.0
                else:
                    xy = 1.0 - delta2
                    val = 2.0 * (1.0 - u) + 2.0 * (u - 0.5) * (xy**(eta + 1.0))
                    deltaq = 1.0 - val**(1.0 / (eta + 1.0))

                mutated[i] = y + deltaq * (yu - yl)

                # 边界修复
                mutated[i] = np.clip(mutated[i], yl, yu)

        return mutated

    def calculate_diversity(self, population: np.ndarray) -> float:
        """
        计算种群多样性（平均欧几里得距离）

        参数:
            population: 种群矩阵

        返回:
            种群多样性指标
        """
        n_individuals = len(population)
        total_distance = 0.0
        count = 0

        for i in range(n_individuals):
            for j in range(i + 1, n_individuals):
                distance = np.linalg.norm(population[i] - population[j])
                total_distance += distance
                count += 1

        return total_distance / count if count > 0 else 0.0

    def optimize(
        self,
        objective_func: Callable[[np.ndarray], float],
        bounds: 'OptimizationBounds'
    ) -> Dict[str, Any]:
        """
        执行遗传算法优化

        参数:
            objective_func: 目标函数（最小化）
            bounds: 决策变量边界

        返回:
            优化结果字典
        """
        start_time = time.time()
        logger.info(f"开始遗传算法优化，种群大小: {self.config.population_size}, 最大代数: {self.config.generations}")

        # 初始化种群
        population = self.initialize_population(bounds)

        # 评估初始种群
        fitness = self.evaluate_population(population, objective_func)

        # 记录历史
        self.best_fitness_history = []
        self.diversity_history = []

        best_individual = population[np.argmin(fitness)].copy()
        best_fitness = np.min(fitness)
        stagnation_count = 0

        for generation in range(self.config.generations):
            self.generation = generation

            # 记录历史
            self.best_fitness_history.append(best_fitness)
            diversity = self.calculate_diversity(population)
            self.diversity_history.append(diversity)

            logger.info(f"第 {generation + 1} 代：最优适应度 = {best_fitness:.6f}, 种群多样性 = {diversity:.6f}")

            # 早停检查
            if generation > 0:
                improvement = self.best_fitness_history[-2] - self.best_fitness_history[-1]
                if improvement < self.config.early_stopping_threshold:
                    stagnation_count += 1
                else:
                    stagnation_count = 0

                if stagnation_count >= self.config.early_stopping_patience:
                    logger.info(f"触发早停机制，连续 {stagnation_count} 代无明显改进")
                    break

            # 选择
            selected_population = self.tournament_selection(population, fitness)

            # 交叉和变异生成新种群
            new_population = []

            for i in range(0, self.config.population_size, 2):
                parent1 = selected_population[i]
                parent2 = selected_population[(i + 1) % self.config.population_size]

                # 交叉
                child1, child2 = self.sbx_crossover(parent1, parent2, bounds)

                # 变异
                child1 = self.polynomial_mutation(child1, bounds)
                child2 = self.polynomial_mutation(child2, bounds)

                new_population.extend([child1, child2])

            new_population = np.array(new_population[:self.config.population_size])

            # 评估新种群
            new_fitness = self.evaluate_population(new_population, objective_func)

            # 精英策略：保留最优个体
            combined_population = np.vstack([population, new_population])
            combined_fitness = np.hstack([fitness, new_fitness])

            # 按适应度排序
            sorted_indices = np.argsort(combined_fitness)

            # 选择最优的个体组成下一代
            population = combined_population[sorted_indices[:self.config.population_size]]
            fitness = combined_fitness[sorted_indices[:self.config.population_size]]

            # 更新最优解
            current_best = population[0]
            current_best_fitness = fitness[0]

            if current_best_fitness < best_fitness:
                best_individual = current_best.copy()
                best_fitness = current_best_fitness

        execution_time = time.time() - start_time

        logger.info(f"遗传算法优化完成，最终最优适应度: {best_fitness:.6f}, 耗时: {execution_time:.2f}秒")

        return {
            "best_solution": best_individual,
            "best_fitness": best_fitness,
            "n_generations": generation + 1,
            "execution_time": execution_time,
            "fitness_history": self.best_fitness_history,
            "diversity_history": self.diversity_history,
            "final_population": population,
            "convergence_info": {
                "early_stopped": stagnation_count >= self.config.early_stopping_patience,
                "stagnation_generations": stagnation_count
            }
        }


# 使用示例
def rastrigin_function(x: np.ndarray) -> float:
    """Rastrigin函数（测试用多峰函数）"""
    A = 10
    n = len(x)
    return A * n + sum(xi**2 - A * np.cos(2 * np.pi * xi) for xi in x)


# 最小可运行示例
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

    # 定义优化边界
    bounds = OptimizationBounds(
        lower=[-5.12, -5.12],
        upper=[5.12, 5.12]
    )

    # 配置遗传算法
    config = GAConfig(
        population_size=30,
        generations=50,
        crossover_rate=0.8,
        mutation_rate=0.1,
        elitism=2,
        random_seed=42
    )

    # 运行优化
    optimizer = GeneticAlgorithmOptimizer(config)
    result = optimizer.optimize(rastrigin_function, bounds)

    logger.info(f"最优解: {result['best_solution']}")
    logger.info(f"最优值: {result['best_fitness']:.6f}")
    logger.info(f"收敛代数: {result['n_generations']}")

    # 绘制收敛曲线（可选）
    plt.figure(figsize=(12, 4))

    plt.subplot(1, 2, 1)
    plt.plot(result['fitness_history'])
    plt.title('适应度收敛曲线')
    plt.xlabel('代数')
    plt.ylabel('最优适应度')
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(result['diversity_history'])
    plt.title('种群多样性变化')
    plt.xlabel('代数')
    plt.ylabel('多样性指标')
    plt.grid(True)

    plt.tight_layout()
    plt.show()
```

### 10.2 粒子群优化算法实现

```python
"""
粒子群优化算法
适用于连续变量优化问题，具有良好的收敛特性
"""
import numpy as np
import logging
from typing import Dict, Any, Optional, Callable, List
from dataclasses import dataclass
import time
import matplotlib.pyplot as plt

logger = logging.getLogger(__name__)

@dataclass
class PSOConfig:
    """粒子群优化算法配置"""
    swarm_size: int = 30
    max_iterations: int = 100
    inertia_w: float = 0.9
    inertia_w_min: float = 0.4
    c1: float = 2.0  # 认知权重
    c2: float = 2.0  # 社会权重
    v_max_ratio: float = 0.2  # 最大速度占变量范围的比例
    early_stopping_patience: int = 15
    early_stopping_threshold: float = 1e-6
    adaptive_inertia: bool = True
    random_seed: Optional[int] = None

class ParticleSwarmOptimizer:
    """
    粒子群优化算法

    基于群体智能的优化算法，通过粒子间的信息共享寻找最优解
    """

    def __init__(self, config: PSOConfig):
        """
        初始化粒子群优化器

        参数:
            config: 算法配置参数
        """
        self.config = config
        self.best_fitness_history: List[float] = []
        self.iteration = 0

        if config.random_seed is not None:
            np.random.seed(config.random_seed)

    def initialize_swarm(self, bounds: 'OptimizationBounds') -> Dict[str, np.ndarray]:
        """
        初始化粒子群

        参数:
            bounds: 决策变量边界

        返回:
            包含位置和速度的字典
        """
        n_vars = len(bounds.lower)

        # 初始化位置
        positions = np.random.uniform(
            low=bounds.lower,
            high=bounds.upper,
            size=(self.config.swarm_size, n_vars)
        )

        # 计算最大速度
        v_max = self.config.v_max_ratio * (np.array(bounds.upper) - np.array(bounds.lower))

        # 初始化速度
        velocities = np.random.uniform(
            low=-v_max,
            high=v_max,
            size=(self.config.swarm_size, n_vars)
        )

        logger.info(f"初始化粒子群完成，粒子数: {self.config.swarm_size}, 变量维度: {n_vars}")

        return {
            "positions": positions,
            "velocities": velocities,
            "v_max": v_max
        }

    def update_inertia_weight(self, iteration: int) -> float:
        """
        更新惯性权重（线性递减）

        参数:
            iteration: 当前迭代次数

        返回:
            当前惯性权重
        """
        if self.config.adaptive_inertia:
            return self.config.inertia_w_min + (self.config.inertia_w - self.config.inertia_w_min) * \
                   (self.config.max_iterations - iteration) / self.config.max_iterations
        else:
            return self.config.inertia_w

    def update_velocity(
        self,
        velocities: np.ndarray,
        positions: np.ndarray,
        personal_best: np.ndarray,
        global_best: np.ndarray,
        v_max: np.ndarray,
        w: float
    ) -> np.ndarray:
        """
        更新粒子速度

        参数:
            velocities: 当前速度
            positions: 当前位置
            personal_best: 个体最优位置
            global_best: 全局最优位置
            v_max: 最大速度限制
            w: 惯性权重

        返回:
            更新后的速度
        """
        r1 = np.random.random(velocities.shape)
        r2 = np.random.random(velocities.shape)

        # PSO速度更新公式
        new_velocities = (
            w * velocities +
            self.config.c1 * r1 * (personal_best - positions) +
            self.config.c2 * r2 * (global_best - positions)
        )

        # 速度限制
        new_velocities = np.clip(new_velocities, -v_max, v_max)

        return new_velocities

    def update_position(
        self,
        positions: np.ndarray,
        velocities: np.ndarray,
        bounds: 'OptimizationBounds'
    ) -> np.ndarray:
        """
        更新粒子位置

        参数:
            positions: 当前位置
            velocities: 当前速度
            bounds: 变量边界

        返回:
            更新后的位置
        """
        new_positions = positions + velocities

        # 边界处理
        new_positions = np.clip(new_positions, bounds.lower, bounds.upper)

        return new_positions

    def optimize(
        self,
        objective_func: Callable[[np.ndarray], float],
        bounds: 'OptimizationBounds'
    ) -> Dict[str, Any]:
        """
        执行粒子群优化

        参数:
            objective_func: 目标函数（最小化）
            bounds: 决策变量边界

        返回:
            优化结果字典
        """
        start_time = time.time()
        logger.info(f"开始粒子群优化，粒子数: {self.config.swarm_size}, 最大迭代: {self.config.max_iterations}")

        # 初始化粒子群
        swarm = self.initialize_swarm(bounds)
        positions = swarm["positions"]
        velocities = swarm["velocities"]
        v_max = swarm["v_max"]

        # 评估初始适应度
        fitness = np.array([objective_func(pos) for pos in positions])

        # 初始化个体最优和全局最优
        personal_best_positions = positions.copy()
        personal_best_fitness = fitness.copy()

        global_best_idx = np.argmin(fitness)
        global_best_position = positions[global_best_idx].copy()
        global_best_fitness = fitness[global_best_idx]

        # 记录历史
        self.best_fitness_history = []
        stagnation_count = 0

        for iteration in range(self.config.max_iterations):
            self.iteration = iteration

            # 记录历史
            self.best_fitness_history.append(global_best_fitness)

            logger.info(f"第 {iteration + 1} 次迭代：全局最优适应度 = {global_best_fitness:.6f}")

            # 早停检查
            if iteration > 0:
                improvement = self.best_fitness_history[-2] - self.best_fitness_history[-1]
                if improvement < self.config.early_stopping_threshold:
                    stagnation_count += 1
                else:
                    stagnation_count = 0

                if stagnation_count >= self.config.early_stopping_patience:
                    logger.info(f"触发早停机制，连续 {stagnation_count} 次迭代无明显改进")
                    break

            # 更新惯性权重
            w = self.update_inertia_weight(iteration)

            # 更新速度
            velocities = self.update_velocity(
                velocities, positions, personal_best_positions,
                global_best_position, v_max, w
            )

            # 更新位置
            positions = self.update_position(positions, velocities, bounds)

            # 评估新位置
            fitness = np.array([objective_func(pos) for pos in positions])

            # 更新个体最优
            improved_mask = fitness < personal_best_fitness
            personal_best_positions[improved_mask] = positions[improved_mask]
            personal_best_fitness[improved_mask] = fitness[improved_mask]

            # 更新全局最优
            best_idx = np.argmin(personal_best_fitness)
            if personal_best_fitness[best_idx] < global_best_fitness:
                global_best_position = personal_best_positions[best_idx].copy()
                global_best_fitness = personal_best_fitness[best_idx]

        execution_time = time.time() - start_time

        logger.info(f"粒子群优化完成，最终最优适应度: {global_best_fitness:.6f}, 耗时: {execution_time:.2f}秒")

        return {
            "best_solution": global_best_position,
            "best_fitness": global_best_fitness,
            "n_iterations": iteration + 1,
            "execution_time": execution_time,
            "fitness_history": self.best_fitness_history,
            "final_positions": positions,
            "convergence_info": {
                "early_stopped": stagnation_count >= self.config.early_stopping_patience,
                "stagnation_iterations": stagnation_count
            }
        }


# 最小可运行示例
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

    def sphere_function(x: np.ndarray) -> float:
        """Sphere函数（简单测试函数）"""
        return sum(xi**2 for xi in x)

    # 定义优化边界
    bounds = OptimizationBounds(
        lower=[-10.0, -10.0],
        upper=[10.0, 10.0]
    )

    # 配置粒子群算法
    config = PSOConfig(
        swarm_size=20,
        max_iterations=50,
        inertia_w=0.9,
        inertia_w_min=0.4,
        c1=2.0,
        c2=2.0,
        random_seed=42
    )

    # 运行优化
    optimizer = ParticleSwarmOptimizer(config)
    result = optimizer.optimize(sphere_function, bounds)

    logger.info(f"最优解: {result['best_solution']}")
    logger.info(f"最优值: {result['best_fitness']:.6f}")
    logger.info(f"收敛迭代: {result['n_iterations']}")

    # 绘制收敛曲线（可选）
    plt.figure(figsize=(8, 6))
    plt.plot(result['fitness_history'], marker='o', linewidth=2)
    plt.title('粒子群优化收敛曲线')
    plt.xlabel('迭代次数')
    plt.ylabel('全局最优适应度')
    plt.grid(True, alpha=0.3)
    plt.yscale('log')
    plt.show()
```

### 10.3 水泵系统优化具体应用示例

```python
"""
水泵系统优化具体应用
结合实际工程参数进行多目标优化
"""
import numpy as np
from typing import Dict, Any, Tuple, List
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)

@dataclass
class PumpSystemConfig:
    """水泵系统配置"""
    n_pumps: int = 3  # 泵台数
    rated_flow: float = 100.0  # 额定流量 m³/h
    rated_head: float = 80.0   # 额定扬程 m
    rated_power: float = 22.0  # 额定功率 kW
    efficiency_curve_params: Dict[str, float] | None = None  # 效率曲线参数

    def __post_init__(self):
        if self.efficiency_curve_params is None:
            # 默认效率曲线参数（二次多项式）
            self.efficiency_curve_params = {
                'a': -0.0001,
                'b': 0.015,
                'c': 0.2
            }

class PumpSystemOptimizer:
    """
    水泵系统优化器

    优化目标：
    1. 最小化能耗
    2. 最大化效率
    3. 最小化磨损
    """

    def __init__(self, config: PumpSystemConfig):
        """
        初始化水泵系统优化器

        参数:
            config: 系统配置
        """
        self.config = config

    def calculate_pump_efficiency(self, flow_rate: float) -> float:
        """
        计算水泵效率

        参数:
            flow_rate: 流量 (m³/h)

        返回:
            效率值 (0-1)
        """
        params = self.config.efficiency_curve_params

        # 归一化流量
        normalized_flow = flow_rate / self.config.rated_flow

        # 二次多项式效率曲线
        efficiency = (
            params['a'] * normalized_flow**2 +
            params['b'] * normalized_flow +
            params['c']
        )

        # 限制效率范围
        return float(np.clip(efficiency, 0.1, 0.95))

    def calculate_pump_head(self, flow_rate: float) -> float:
        """
        计算水泵扬程

        参数:
            flow_rate: 流量 (m³/h)

        返回:
            扬程 (m)
        """
        # 简化的扬程-流量特性曲线
        normalized_flow = flow_rate / self.config.rated_flow

        # 二次多项式扬程曲线
        head = self.config.rated_head * (
            1.2 - 0.8 * normalized_flow - 0.4 * normalized_flow**2
        )

        return float(max(head, 0.0))

    def calculate_pump_power(self, flow_rate: float, head: float, efficiency: float) -> float:
        """
        计算水泵功率

        参数:
            flow_rate: 流量 (m³/h)
            head: 扬程 (m)
            efficiency: 效率

        返回:
            功率 (kW)
        """
        # 水的密度 (kg/m³)
        rho_water = 1000.0
        # 重力加速度 (m/s²)
        g = 9.81

        # 流量转换 (m³/h -> m³/s)
        flow_rate_ms = flow_rate / 3600.0

        # 理论功率 (kW)
        theoretical_power = (rho_water * g * flow_rate_ms * head) / 1000.0

        # 考虑效率的实际功率
        if efficiency > 0:
            actual_power = theoretical_power / efficiency
        else:
            actual_power = float('inf')

        return float(actual_power)

    def pump_system_objectives(self, decision_vars: np.ndarray) -> Dict[str, float]:
        """
        水泵系统多目标函数

        参数:
            decision_vars: 决策变量 [pump1_flow, pump2_flow, pump3_flow, pump1_freq, pump2_freq, pump3_freq]

        返回:
            多目标值字典
        """
        n_pumps = self.config.n_pumps

        # 提取决策变量
        flow_rates = decision_vars[:n_pumps]  # 每台泵的流量
        frequencies = decision_vars[n_pumps:]  # 每台泵的频率

        total_power = 0.0
        total_efficiency_flow = 0.0
        total_flow = 0.0
        total_wear = 0.0

        for i in range(n_pumps):
            if flow_rates[i] > 0:  # 泵运行
                # 考虑频率对性能的影响
                freq_ratio = frequencies[i] / 50.0  # 额定频率50Hz

                # 调整流量和扬程
                adjusted_flow = flow_rates[i] * freq_ratio
                adjusted_head = self.calculate_pump_head(adjusted_flow) * (freq_ratio**2)

                # 计算效率和功率
                efficiency = self.calculate_pump_efficiency(adjusted_flow)
                power = self.calculate_pump_power(adjusted_flow, adjusted_head, efficiency)

                # 考虑频率对功率的影响
                power *= freq_ratio**3

                # 累加指标
                total_power += power
                total_efficiency_flow += efficiency * adjusted_flow
                total_flow += adjusted_flow

                # 简化的磨损模型（偏离最优工作点的惩罚）
                optimal_flow_ratio = 0.7  # 最优流量比例
                flow_deviation = abs(adjusted_flow / self.config.rated_flow - optimal_flow_ratio)
                wear_factor = 1.0 + 2.0 * flow_deviation**2
                total_wear += wear_factor

        # 计算目标函数
        # 1. 能耗目标（最小化）
        energy_objective = total_power

        # 2. 效率目标（最大化，转为最小化）
        if total_flow > 0:
            weighted_efficiency = total_efficiency_flow / total_flow
            efficiency_objective = -weighted_efficiency  # 负号表示最大化转最小化
        else:
            efficiency_objective = 1.0  # 惩罚无流量情况

        # 3. 磨损目标（最小化）
        wear_objective = total_wear

        return {
            "energy": float(energy_objective),
            "efficiency": float(efficiency_objective),
            "wear": float(wear_objective),
            "total_flow": float(total_flow),
            "total_power": float(total_power)
        }

    def pump_system_constraints(self, decision_vars: np.ndarray) -> Dict[str, bool]:
        """
        水泵系统约束条件

        参数:
            decision_vars: 决策变量

        返回:
            约束满足情况字典
        """
        n_pumps = self.config.n_pumps
        flow_rates = decision_vars[:n_pumps]
        frequencies = decision_vars[n_pumps:]

        constraints: Dict[str, bool] = {}

        # 1. 流量需求约束
        total_flow = float(sum(flow_rates))
        flow_demand = 200.0  # 目标流量 m³/h
        flow_tolerance = 0.05  # 5% 容差

        constraints["flow_demand"] = abs(total_flow - flow_demand) / flow_demand <= flow_tolerance

        # 2. 压力约束
        min_head_required = 60.0  # 最小扬程要求 m

        for i, flow_rate in enumerate(flow_rates):
            if flow_rate > 0:
                freq_ratio = frequencies[i] / 50.0
                adjusted_flow = flow_rate * freq_ratio
                head = self.calculate_pump_head(adjusted_flow) * (freq_ratio**2)
                constraints[f"pump_{i}_head"] = head >= min_head_required
            else:
                constraints[f"pump_{i}_head"] = True

        # 3. 功率约束
        max_power_per_pump = self.config.rated_power * 1.1  # 允许10%超载

        for i, flow_rate in enumerate(flow_rates):
            if flow_rate > 0:
                freq_ratio = frequencies[i] / 50.0
                adjusted_flow = flow_rate * freq_ratio
                adjusted_head = self.calculate_pump_head(adjusted_flow) * (freq_ratio**2)
                efficiency = self.calculate_pump_efficiency(adjusted_flow)
                power = self.calculate_pump_power(adjusted_flow, adjusted_head, efficiency) * (freq_ratio**3)

                constraints[f"pump_{i}_power"] = power <= max_power_per_pump
            else:
                constraints[f"pump_{i}_power"] = True

        # 4. 运行台数约束（至少一台运行）
        running_pumps = sum(1 for flow in flow_rates if flow > 0)
        constraints["min_running_pumps"] = running_pumps >= 1

        return constraints


# 综合优化示例
def pump_optimization_example():
    """水泵系统优化完整示例"""
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

    # 系统配置
    config = PumpSystemConfig(
        n_pumps=3,
        rated_flow=100.0,
        rated_head=80.0,
        rated_power=22.0
    )

    # 创建优化器
    pump_optimizer = PumpSystemOptimizer(config)

    # 定义优化边界
    # 变量：[pump1_flow, pump2_flow, pump3_flow, pump1_freq, pump2_freq, pump3_freq]
    bounds = OptimizationBounds(
        lower=[0.0, 0.0, 0.0, 30.0, 30.0, 30.0],  # 流量 >= 0, 频率 >= 30Hz
        upper=[120.0, 120.0, 120.0, 50.0, 50.0, 50.0]  # 流量 <= 120 m³/h, 频率 <= 50Hz
    )

    # 定义约束优化目标函数
    def constrained_objective(x: np.ndarray) -> float:
        """带约束的目标函数"""
        objectives = pump_optimizer.pump_system_objectives(x)
        constraints = pump_optimizer.pump_system_constraints(x)

        # 多目标加权组合
        energy_weight = 0.4
        efficiency_weight = 0.3
        wear_weight = 0.3

        objective_value = (
            energy_weight * objectives["energy"] +
            efficiency_weight * objectives["efficiency"] +
            wear_weight * objectives["wear"]
        )

        # 约束违反惩罚
        penalty = 0.0
        for satisfied in constraints.values():
            if not satisfied:
                penalty += 1000.0  # 大惩罚

        return float(objective_value + penalty)

    # 使用遗传算法优化
    ga_config = GAConfig(
        population_size=40,
        generations=80,
        crossover_rate=0.8,
        mutation_rate=0.1,
        random_seed=42
    )

    ga_optimizer = GeneticAlgorithmOptimizer(ga_config)
    result = ga_optimizer.optimize(constrained_objective, bounds)

    # 分析结果
    best_solution = result["best_solution"]
    n_pumps = config.n_pumps

    logger.info("=== 水泵系统优化结果 ===")
    logger.info(f"最优目标值: {result['best_fitness']:.4f}")
    logger.info(f"收敛代数: {result['n_generations']}")
    logger.info(f"计算时间: {result['execution_time']:.2f}秒")

    logger.info("--- 最优运行参数 ---")
    for i in range(n_pumps):
        flow = best_solution[i]
        freq = best_solution[i + n_pumps]
        logger.info(f"水泵 {i+1}: 流量 = {flow:.2f} m³/h, 频率 = {freq:.1f} Hz")

    # 详细性能分析
    objectives = pump_optimizer.pump_system_objectives(best_solution)
    constraints = pump_optimizer.pump_system_constraints(best_solution)

    logger.info("--- 性能指标 ---")
    logger.info(f"总流量: {objectives['total_flow']:.2f} m³/h")
    logger.info(f"总功率: {objectives['total_power']:.2f} kW")
    logger.info(f"系统效率: {-objectives['efficiency']:.3f}")
    logger.info(f"磨损指标: {objectives['wear']:.2f}")

    all_satisfied = all(constraints.values())
    logger.info("--- 约束检查 ---")
    for name, satisfied in constraints.items():
        status = "满足" if satisfied else "违反"
        logger.info(f"{name}: {status}")

    if all_satisfied:
        logger.info("所有约束均满足！")
    else:
        logger.info("存在约束违反，需要调整参数。")

    return result


if __name__ == "__main__":
    pump_optimization_example()
```
