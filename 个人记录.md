人工触发：在对话或提交描述中出现以下关键词时，按流程执行
记录变更、更新 PLAYBOOKS、保存记忆、按照 PLAYBOOKS 流程完成、记忆和文档都更新了吗？、PLAYBOOKS
同义词：记录决策、记录配置变更、记录改进、记录经验教训、记录性能基准

自动记忆（PLAYBOOKS 三步）
触发条件：你的消息中出现关键词（记录变更/更新 PLAYBOOKS/保存记忆/按照 PLAYBOOKS 流程完成/记忆和文档都更新了吗？/PLAYBOOKS 等）
自动动作：
更新 PLAYBOOKS 文档条目
保存关键决策到记忆系统
同步 docs/ 文档索引与“最近变更（自动生成）”
保障机制：memory_index 仅在内容变化时写入，避免无差异改写；中文兼容已增强
自动代码质量检查（严格策略，默认开启）
触发条件：我进行或建议任何代码/配置修改后，以及你发出“确保全绿/跑钩子/跑检查”等指令
自动动作（本地安全执行）：
运行 pre-commit run --all-files（ruff/black/mypy/bandit/mdformat/yaml 等）
如有 mdformat/black 自动格式化，直接纳入本次提交
仅当需要安装新依赖、迁移数据库、长任务等风险动作时，才会先征求你同意
远端保障：CI 已新增“pre-commit 全绿检查 Job”，所有 PR 先过此 Job，报告作为工件上传；build-test 依赖其结果

记忆相关
“更新 PLAYBOOKS：xxx” 或 “记录变更：xxx” → 自动执行三步（文档、记忆、索引）
“记忆和文档都更新了吗？” → 自动检查并补齐
质量检查相关
“确保全绿/跑钩子/跑检查/本地跑一遍” → 我会运行 pre-commit 并汇报摘要和关键日志
“CI 跑一遍并给我报告” → 我会触发推送/PR 并在 CI 完成后返回工件链接（需要你确认 push/PR）

当你发出：记录变更/更新 PLAYBOOKS/保存记忆/按照 PLAYBOOKS 流程完成/记忆和文档都更新了吗？/PLAYBOOKS
我会自动：更新 PLAYBOOKS → 保存关键记忆 → 同步“最近变更”和 INDEX（仅在内容变化时写入）

新会话启动模板（直接粘贴使用）
请按项目规则与文档体系执行：
遵循 PROJECT_RULES.md 与 docs/（SCHEMA_AND_DB.md、DATA_SPEC.md、ALIGNMENT_POLICY.md、PERFORMANCE_OPTIMIZATION.md、DECISIONS.md、LESSONS_LEARNED.md、CONFIGURATION_CHANGES.md 等）
不读取 venv/ 和 data/ 目录
启动前动作：
加载并对齐 PLAYBOOKS 历史：扫描 docs/PLAYBOOKS 下记录，汇总与本任务相关的“决策/经验/优化/配置变更/基准”
给出本任务的风险点清单与应对策略（直接引用相关文档条款）
代码改动约定（必须执行）：
每次改动后：先本地 pre-commit 全量体检（ruff、black、mypy、bandit、mdformat、check-yaml、mixed-line-ending、memory-check、memory-index）
自动执行 PLAYBOOKS 三步（仅在内容变化时写入）：更新记录 → 保存记忆 → 同步“最近变更”和 INDEX
修复后再次运行 pre-commit 确保全绿
CI 约定：
持续保持 pre-commit Job 全绿；PR 下方自动贴出详细 pre-commit 报告（已配置），Actions Summary 显示摘要
授权范围（默认同意）：
允许运行本地只读/安全命令：pre-commit、ruff/black/mypy/bandit、mdformat、pytest -q（不执行迁移、部署、数据写入）
如需安装依赖、改数据库、长任务，会先征求确认
输出要求：
每一步给出“执行了什么/结果如何/下一步”的简明小结
引用文档时点明来源文件与条目标题（便于溯源）

进行具体开发任务时的简短模板
任务目标：一句话说明要改什么
必须遵循的文档点：列 2-3 条（比如字段命名/性能要求/对齐策略）
安全边界：是否允许安装依赖/执行长任务
验收标准：通过哪些钩子/测试/指标
示例

干跑与生成 SQL
python scripts/dev/dry_run_mapping_validation.py
python scripts/dev/generate_seed_from_mapping.py
psql -h localhost -U postgres -d pump_station_optimization -f scripts/dev/seed_from_mapping.sql
最小造数与对齐验证
psql -h localhost -U postgres -d pump_station_optimization -f scripts/dev/seed_minimal_demo.sql
MV 创建与刷新
psql -h localhost -U postgres -d pump_station_optimization -f scripts/mv_blueprints.sql
psql -h localhost -U postgres -d pump_station_optimization -c "REFRESH MATERIALIZED VIEW reporting.mv_measurements_hourly; REFRESH MATERIALIZED VIEW reporting.mv_measurements_daily;"
命中率审计
psql -h localhost -U postgres -d pump_station_optimization -f scripts/mv_hit_audit.sql
psql -h localhost -U postgres -d pump_station_optimization -c "SELECT * FROM monitoring.v_mv_hit_audit;"
一键体检
powershell -NoProfile -ExecutionPolicy Bypass -File .\\scripts\\dev\\pcv.ps1
质量门禁
python scripts/quality_gate.py

______________________________________________________________________

## 导入程序方案A与日志输出结构（决策与实施计划）

- 背景：CSV 超大；需在保证“按泵站时区对齐到 UTC 秒、主键合并、只依赖 data_mapping.json”的前提下，最大化吞吐与稳定性。
- 决策：采用 方案A（并发 COPY → UNLOGGED staging → 库端集合式转换/去重/合并 → 刷新MV/命中审计）。
- 参照文档：docs/规范.md、docs/日志.md、docs/程序工作流程.md。

### 1) 程序架构（app/ 落地）

- 目录：app/ingest/{cli,config,io,copy_workers,merge,logging,utils}
- CLI 子命令：
  - prepare-dim：从 data_mapping.json 生成并执行 dim\_\* 与映射 upsert（复用 generate_seed_from_mapping 逻辑）
  - create-staging：创建 staging_raw（UNLOGGED）与 staging_rejects
  - ingest:copy：并发 COPY CSV → staging_raw（流式、低内存、支持 .gz）
  - merge:fact：库端集合式转换/对齐/去重 → INSERT … ON CONFLICT 合并（按周/日窗口）
  - refresh:mv：刷新 reporting.mv_measurements_hourly/daily
  - audit:mv：读取 monitoring.v_mv_hit_audit
  - run-all：按顺序串起全流程

### 2) 方案A 关键技术点

- COPY 会话：SET synchronous_commit=off; SET client_encoding='UTF8'；必要时调大 work_mem（仅会话）。
- staging_raw：初期无索引（导入快）；合并前可临时加轻索引 (station_name,device_name,metric_key)。
- 合并 SQL：
  - JOIN dim_stations/device/metric，时区从 dim_stations.extra->>'tz'；ts_local → UTC → date_trunc('second') → ts_bucket
  - 窗口去重（同 (sid,did,mid,ts_bucket) 保留最新 ts_utc）
  - INSERT … ON CONFLICT DO UPDATE 合并（与 safe_upsert\_\* 语义一致）
- 分窗执行：按周/日循环合并，降低锁与 WAL 压力；大批后 ANALYZE 目标分区与 MV。

### 3) 并发与内存控制

- 文件级并发：ThreadPoolExecutor，workers=CPU×2 或 4~8（按资源调优）。
- 流式读：逐行/小批写 COPY，常数级内存；单文件可分段 COPY（超大文件）。
- 背压门禁（自适应）：若 P95 批次耗时>2s 或失败率>1% → 降并发/缩批 50%；达标再回升；连续不达标触发 guardrail.stop。

### 4) 日志输出结构（便于联合排障）

- 统一 NDJSON（UTF-8，UTC），trace_id/job_id/batch_id 贯穿。
- 目录（推荐 方案A）：D:/Augment/diwuban/logs/runs/YYYYMMDD/\<job_id>/
  - app.ndjson（INFO+ 全量结构化）
  - error.ndjson（WARN+ 快速定位异常）
  - sql.ndjson（SQL 摘要/采样计划：sql_state/sql_op/affected_rows/sql_cost_ms/sql_mode/sql_hash，可选 sql_text 脱敏+截断）
  - perf.ndjson（吞吐/耗时/背压）
  - summary.json（一次性汇总：总行数、合并数、失败/重试、MV 刷新结果、exit_code）
  - env.json（可选：脱敏配置快照）
- 关键字段：
  - 业务：biz_domain/biz_action/scenario、conflict_count/dedupe_ratio/merge_strategy/source_priority
  - 性能：batch_cost_ms/merge_cost_ms/rows_per_sec/p95_batch_ms/lock_waits/adjustment
  - 文件：file_path/file_size/bytes_read/lines_read/chunk_idx/chunks_total
  - 线程：thread_id/thread_name/worker_index/task_id
  - SQL：sql_state/sql_try/sql_op/target_table/affected_rows/sql_cost_ms/sql_mode/sql_hash/(sql_text?)/pgcode/hint
- 配置开关（logging.yaml）：logging.sql.text（summary|normalized|full_debug，默认 summary）、logging.sql.max_len=2048、logging.sql.explain=on_error、logging.sql.params=false、performance.queue_handler=true、sampling.loop_log_every_n=1000、redaction.enable=true。

### 5) 里程碑与验收

- M1 规范就绪：docs/规范.md、docs/日志.md（已完成增强版）
- M2 SQL/DDL：scripts/sql/staging_raw.sql、merge_staging_to_fact.sql（含 rejects 与去重策略）
- M3 CLI 骨架：app/ingest/\* 完整子命令与 --help；默认 runs 目录与 per-run 多流日志
- M4 并发 COPY 与窗口合并打通：小样本 E2E（not_aligned=0，MV 刷新与命中）
- M5 压测与门禁：吞吐≥50k 行/秒（样机），P95≤2s，失败率≤1%；背压日志生效

### 6) 风险与回滚

- 风险：脏数据/时间解析失败/锁竞争/日志洪泛 → 用 rejects、窗口合并、门禁自适应、采样/限流
- 回滚：清空 staging、按窗口回滚 fact；关闭 normalized SQL 文本；恢复默认并发与批大小

### 7) 待办与约束

- 待办：落地 configs/logging.yaml 模板与 CLI 覆盖；实现 SQL 网关统一打点与脱敏；实现 per-run 目录与 summary.json
- 约束：严禁从 CSV 文件名/路径推断维度/指标；时区仅来自 dim_stations.extra->>'tz'；统一秒级对齐
