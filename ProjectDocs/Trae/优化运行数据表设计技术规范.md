# 优化运行数据表设计技术规范

## 目录
1. [概述](#1-概述)
2. [当前设计问题分析](#2-当前设计问题分析)
3. [优化设计方案](#3-优化设计方案)
4. [时间对齐策略](#4-时间对齐策略)
5. [计算值管理](#5-计算值管理)
6. [存储优化](#6-存储优化)
7. [实现规范](#7-实现规范)
8. [性能测试](#8-性能测试)

---

## 1. 概述

### 1.1 优化目标
- **存储效率**: 减少存储空间占用，提高I/O性能
- **时间对齐**: 实现高效的多参数时间同步查询
- **计算值管理**: 区分原始数据和计算数据，支持数据溯源
- **查询性能**: 优化常用查询场景的响应时间
- **数据完整性**: 保证数据一致性和可靠性

### 1.2 适用范围
- **二期供水泵房**: 6台变频泵 + 总管数据
- **二期取水泵房**: 5台泵 + 总管数据
- **数据类型**: 电气、液压、机械、热力参数
- **时间精度**: 毫秒级时间戳

### 1.3 设计原则
- 读写分离优化
- 冷热数据分层存储
- 计算值可追溯
- 时间对齐高效查询
- 存储空间最小化

---

## 2. 当前设计问题分析

### 2.1 存储效率问题

#### 2.1.1 数据冗余
```sql
-- 当前设计问题：每个参数单独一行，存在大量重复信息
CREATE TABLE operation_data (
    id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
    station_id BIGINT UNSIGNED NOT NULL,  -- 重复存储
    device_id BIGINT UNSIGNED NOT NULL,   -- 重复存储
    tag_name VARCHAR(200) NOT NULL,       -- 冗长字符串
    data_time TIMESTAMP(3) NOT NULL,      -- 重复存储
    data_value DECIMAL(15,6) NOT NULL,
    parameter_type VARCHAR(50) NOT NULL,  -- 重复存储
    unit VARCHAR(20) DEFAULT NULL,        -- 重复存储
    -- 其他字段...
);
```

**问题分析**:
- 同一时刻同一设备的多个参数分散存储
- `station_id`、`device_id`、`data_time`大量重复
- 字符串类型占用空间大
- 索引开销大

#### 2.1.2 时间对齐查询低效
```sql
-- 当前查询：获取设备在某时刻的所有参数
SELECT parameter_type, data_value
FROM operation_data
WHERE device_id = 1 
  AND data_time = '2025-01-01 10:00:00.000'
  AND parameter_type IN ('power', 'frequency', 'voltage_a');
```

**问题**:
- 需要扫描多行数据
- 无法保证所有参数在同一时刻都有数据
- JOIN操作复杂

### 2.2 计算值管理问题

#### 2.2.1 数据来源不明确
- 原始数据和计算数据混合存储
- 无法追溯计算值的来源
- 计算方法变更时历史数据处理困难

#### 2.2.2 版本管理缺失
- 计算算法更新后无法对比效果
- 无法回滚到历史计算结果

---

## 3. 优化设计方案

### 3.1 分层存储架构

#### 3.1.1 原始数据表 (raw_operation_data)
```sql
CREATE TABLE raw_operation_data (
    id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '数据ID',
    device_id BIGINT UNSIGNED NOT NULL COMMENT '设备ID',
    data_time TIMESTAMP(3) NOT NULL COMMENT '数据时间',
    
    -- 电气参数（压缩存储）
    voltage_a DECIMAL(6,2) DEFAULT NULL COMMENT 'A相电压(V)',
    voltage_b DECIMAL(6,2) DEFAULT NULL COMMENT 'B相电压(V)',
    voltage_c DECIMAL(6,2) DEFAULT NULL COMMENT 'C相电压(V)',
    current_a DECIMAL(7,3) DEFAULT NULL COMMENT 'A相电流(A)',
    current_b DECIMAL(7,3) DEFAULT NULL COMMENT 'B相电流(A)',
    current_c DECIMAL(7,3) DEFAULT NULL COMMENT 'C相电流(A)',
    active_power DECIMAL(8,3) DEFAULT NULL COMMENT '有功功率(kW)',
    reactive_power DECIMAL(8,3) DEFAULT NULL COMMENT '无功功率(kVar)',
    power_factor DECIMAL(4,3) DEFAULT NULL COMMENT '功率因数',
    frequency DECIMAL(5,2) DEFAULT NULL COMMENT '频率(Hz)',
    kwh DECIMAL(12,3) DEFAULT NULL COMMENT '电度(kWh)',
    
    -- 液压参数
    pressure DECIMAL(6,2) DEFAULT NULL COMMENT '压力(MPa)',
    flow_rate DECIMAL(8,2) DEFAULT NULL COMMENT '流量(m³/h)',
    cumulative_flow DECIMAL(12,3) DEFAULT NULL COMMENT '累计流量(m³)',
    
    -- 机械参数
    vibration_a DECIMAL(6,3) DEFAULT NULL COMMENT 'A点振动(mm/s)',
    vibration_b DECIMAL(6,3) DEFAULT NULL COMMENT 'B点振动(mm/s)',
    
    -- 温度参数（使用SMALLINT节省空间，存储温度*10）
    temp_ch1 SMALLINT DEFAULT NULL COMMENT '温度通道1(°C*10)',
    temp_ch2 SMALLINT DEFAULT NULL COMMENT '温度通道2(°C*10)',
    temp_ch3 SMALLINT DEFAULT NULL COMMENT '温度通道3(°C*10)',
    temp_ch4 SMALLINT DEFAULT NULL COMMENT '温度通道4(°C*10)',
    temp_ch5 SMALLINT DEFAULT NULL COMMENT '温度通道5(°C*10)',
    temp_ch6 SMALLINT DEFAULT NULL COMMENT '温度通道6(°C*10)',
    temp_ch7 SMALLINT DEFAULT NULL COMMENT '温度通道7(°C*10)',
    temp_ch8 SMALLINT DEFAULT NULL COMMENT '温度通道8(°C*10)',
    
    -- 数据质量标记
    quality_flags BIGINT UNSIGNED DEFAULT 0 COMMENT '质量标记位图',
    data_source TINYINT UNSIGNED DEFAULT 1 COMMENT '数据源(1:CSV,2:实时)',
    
    created_at TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3) COMMENT '创建时间',
    
    PRIMARY KEY (id),
    UNIQUE KEY uk_raw_data_device_time (device_id, data_time),
    INDEX idx_raw_data_time (data_time),
    INDEX idx_raw_data_device_time_range (device_id, data_time),
    
    CONSTRAINT fk_raw_data_device_id FOREIGN KEY (device_id) REFERENCES devices(id) ON DELETE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='原始运行数据表'
PARTITION BY RANGE (UNIX_TIMESTAMP(data_time)) (
    PARTITION p202501 VALUES LESS THAN (UNIX_TIMESTAMP('2025-02-01 00:00:00')),
    PARTITION p202502 VALUES LESS THAN (UNIX_TIMESTAMP('2025-03-01 00:00:00')),
    PARTITION p202503 VALUES LESS THAN (UNIX_TIMESTAMP('2025-04-01 00:00:00')),
    PARTITION p202504 VALUES LESS THAN (UNIX_TIMESTAMP('2025-05-01 00:00:00')),
    PARTITION p202505 VALUES LESS THAN (UNIX_TIMESTAMP('2025-06-01 00:00:00')),
    PARTITION p202506 VALUES LESS THAN (UNIX_TIMESTAMP('2025-07-01 00:00:00')),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);
```

#### 3.1.2 计算数据表 (calculated_operation_data)
```sql
CREATE TABLE calculated_operation_data (
    id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '计算数据ID',
    device_id BIGINT UNSIGNED NOT NULL COMMENT '设备ID',
    data_time TIMESTAMP(3) NOT NULL COMMENT '数据时间',
    calculation_version VARCHAR(20) NOT NULL DEFAULT 'v1.0' COMMENT '计算版本',
    
    -- 计算得出的性能参数
    efficiency DECIMAL(6,4) DEFAULT NULL COMMENT '效率',
    head DECIMAL(7,2) DEFAULT NULL COMMENT '扬程(m)',
    npsh DECIMAL(6,2) DEFAULT NULL COMMENT 'NPSH(m)',
    specific_speed DECIMAL(8,2) DEFAULT NULL COMMENT '比转速',
    
    -- 能耗分析参数
    specific_energy DECIMAL(8,4) DEFAULT NULL COMMENT '单位能耗(kWh/m³)',
    energy_efficiency_ratio DECIMAL(6,4) DEFAULT NULL COMMENT '能效比',
    
    -- 运行状态参数
    load_factor DECIMAL(5,4) DEFAULT NULL COMMENT '负荷率',
    operating_point_score DECIMAL(5,4) DEFAULT NULL COMMENT '工况点评分',
    
    -- 计算来源追溯
    source_data_ids JSON DEFAULT NULL COMMENT '源数据ID列表',
    calculation_method VARCHAR(50) NOT NULL COMMENT '计算方法',
    calculation_params JSON DEFAULT NULL COMMENT '计算参数',
    
    -- 质量评估
    confidence_score DECIMAL(4,3) DEFAULT NULL COMMENT '置信度',
    validation_status ENUM('pending', 'validated', 'rejected') DEFAULT 'pending' COMMENT '验证状态',
    
    created_at TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3) COMMENT '创建时间',
    
    PRIMARY KEY (id),
    UNIQUE KEY uk_calc_data_device_time_version (device_id, data_time, calculation_version),
    INDEX idx_calc_data_device_time (device_id, data_time),
    INDEX idx_calc_data_method (calculation_method),
    INDEX idx_calc_data_version (calculation_version),
    INDEX idx_calc_data_confidence (confidence_score),
    
    CONSTRAINT fk_calc_data_device_id FOREIGN KEY (device_id) REFERENCES devices(id) ON DELETE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='计算运行数据表'
PARTITION BY RANGE (UNIX_TIMESTAMP(data_time)) (
    PARTITION p202501 VALUES LESS THAN (UNIX_TIMESTAMP('2025-02-01 00:00:00')),
    PARTITION p202502 VALUES LESS THAN (UNIX_TIMESTAMP('2025-03-01 00:00:00')),
    PARTITION p202503 VALUES LESS THAN (UNIX_TIMESTAMP('2025-04-01 00:00:00')),
    PARTITION p202504 VALUES LESS THAN (UNIX_TIMESTAMP('2025-05-01 00:00:00')),
    PARTITION p202505 VALUES LESS THAN (UNIX_TIMESTAMP('2025-06-01 00:00:00')),
    PARTITION p202506 VALUES LESS THAN (UNIX_TIMESTAMP('2025-07-01 00:00:00')),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);
```

#### 3.1.3 参数字典表 (parameter_dictionary)
```sql
CREATE TABLE parameter_dictionary (
    id SMALLINT UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '参数ID',
    parameter_code VARCHAR(20) NOT NULL COMMENT '参数代码',
    parameter_name VARCHAR(50) NOT NULL COMMENT '参数名称',
    parameter_type ENUM('electrical', 'hydraulic', 'mechanical', 'thermal') NOT NULL COMMENT '参数类型',
    unit VARCHAR(10) NOT NULL COMMENT '单位',
    data_type ENUM('raw', 'calculated') NOT NULL COMMENT '数据类型',
    precision_digits TINYINT UNSIGNED DEFAULT 3 COMMENT '精度位数',
    valid_range_min DECIMAL(15,6) DEFAULT NULL COMMENT '有效范围最小值',
    valid_range_max DECIMAL(15,6) DEFAULT NULL COMMENT '有效范围最大值',
    description TEXT DEFAULT NULL COMMENT '参数描述',
    
    created_at TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3) COMMENT '创建时间',
    updated_at TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3) ON UPDATE CURRENT_TIMESTAMP(3) COMMENT '更新时间',
    
    PRIMARY KEY (id),
    UNIQUE KEY uk_param_code (parameter_code),
    INDEX idx_param_type (parameter_type),
    INDEX idx_param_data_type (data_type)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='参数字典表';
```

### 3.2 质量标记位图设计

#### 3.2.1 质量标记位定义
```python
class DataQualityFlags:
    """
    数据质量标记位图定义
    使用64位整数的不同位表示各种质量状态
    """
    
    # 基础质量标记 (位0-15)
    GOOD = 0                    # 位0: 数据良好
    MISSING = 1 << 0           # 位0: 数据缺失
    INTERPOLATED = 1 << 1      # 位1: 插值数据
    EXTRAPOLATED = 1 << 2      # 位2: 外推数据
    ESTIMATED = 1 << 3         # 位3: 估算数据
    
    # 异常检测标记 (位16-31)
    OUTLIER_STATISTICAL = 1 << 16  # 位16: 统计异常值
    OUTLIER_PHYSICAL = 1 << 17     # 位17: 物理异常值
    RANGE_VIOLATION = 1 << 18      # 位18: 超出有效范围
    RATE_VIOLATION = 1 << 19       # 位19: 变化率异常
    
    # 传感器状态标记 (位32-47)
    SENSOR_FAULT = 1 << 32         # 位32: 传感器故障
    CALIBRATION_DUE = 1 << 33      # 位33: 需要校准
    MAINTENANCE_MODE = 1 << 34     # 位34: 维护模式
    
    # 计算状态标记 (位48-63)
    CALC_PENDING = 1 << 48         # 位48: 待计算
    CALC_FAILED = 1 << 49          # 位49: 计算失败
    CALC_LOW_CONFIDENCE = 1 << 50  # 位50: 低置信度
    
    @staticmethod
    def has_flag(quality_flags: int, flag: int) -> bool:
        """检查是否包含指定标记"""
        return (quality_flags & flag) != 0
    
    @staticmethod
    def add_flag(quality_flags: int, flag: int) -> int:
        """添加质量标记"""
        return quality_flags | flag
    
    @staticmethod
    def remove_flag(quality_flags: int, flag: int) -> int:
        """移除质量标记"""
        return quality_flags & ~flag
```

---

## 4. 时间对齐策略

### 4.1 时间网格化设计

#### 4.1.1 标准时间网格
```python
class TimeGridManager:
    """
    时间网格管理器
    将不规则时间戳对齐到标准网格
    """
    
    def __init__(self, grid_interval_seconds: int = 1):
        """
        初始化时间网格
        
        Args:
            grid_interval_seconds: 网格间隔（秒）
        """
        self.grid_interval = grid_interval_seconds
    
    def align_to_grid(self, timestamp: datetime) -> datetime:
        """
        将时间戳对齐到最近的网格点
        
        Args:
            timestamp: 原始时间戳
            
        Returns:
            对齐后的时间戳
        """
        # 计算从epoch开始的秒数
        epoch_seconds = timestamp.timestamp()
        
        # 对齐到网格
        aligned_seconds = round(epoch_seconds / self.grid_interval) * self.grid_interval
        
        # 转换回datetime
        return datetime.fromtimestamp(aligned_seconds, tz=timestamp.tzinfo)
    
    def generate_time_range(self, start_time: datetime, end_time: datetime) -> list[datetime]:
        """
        生成时间范围内的所有网格点
        
        Args:
            start_time: 开始时间
            end_time: 结束时间
            
        Returns:
            网格时间点列表
        """
        aligned_start = self.align_to_grid(start_time)
        aligned_end = self.align_to_grid(end_time)
        
        time_points = []
        current_time = aligned_start
        
        while current_time <= aligned_end:
            time_points.append(current_time)
            current_time += timedelta(seconds=self.grid_interval)
        
        return time_points
```

#### 4.1.2 时间对齐视图
```sql
CREATE VIEW v_aligned_operation_data AS
SELECT 
    r.device_id,
    r.data_time,
    
    -- 原始数据
    r.voltage_a, r.voltage_b, r.voltage_c,
    r.current_a, r.current_b, r.current_c,
    r.active_power, r.reactive_power, r.power_factor,
    r.frequency, r.kwh,
    r.pressure, r.flow_rate, r.cumulative_flow,
    r.vibration_a, r.vibration_b,
    r.temp_ch1/10.0 AS temp_ch1, r.temp_ch2/10.0 AS temp_ch2,
    r.temp_ch3/10.0 AS temp_ch3, r.temp_ch4/10.0 AS temp_ch4,
    r.temp_ch5/10.0 AS temp_ch5, r.temp_ch6/10.0 AS temp_ch6,
    r.temp_ch7/10.0 AS temp_ch7, r.temp_ch8/10.0 AS temp_ch8,
    
    -- 计算数据（取最新版本）
    c.efficiency, c.head, c.npsh, c.specific_speed,
    c.specific_energy, c.energy_efficiency_ratio,
    c.load_factor, c.operating_point_score,
    
    -- 质量信息
    r.quality_flags,
    c.confidence_score,
    c.calculation_version
    
FROM raw_operation_data r
LEFT JOIN (
    SELECT 
        device_id, data_time,
        efficiency, head, npsh, specific_speed,
        specific_energy, energy_efficiency_ratio,
        load_factor, operating_point_score,
        confidence_score, calculation_version,
        ROW_NUMBER() OVER (PARTITION BY device_id, data_time ORDER BY calculation_version DESC) as rn
    FROM calculated_operation_data
    WHERE validation_status = 'validated'
) c ON r.device_id = c.device_id AND r.data_time = c.data_time AND c.rn = 1;
```

### 4.2 批量时间对齐查询

#### 4.2.1 多设备同步查询
```sql
-- 获取多个设备在指定时间范围内的对齐数据
SELECT 
    time_grid.grid_time,
    d1.device_id AS device1_id,
    d1.active_power AS device1_power,
    d1.efficiency AS device1_efficiency,
    d2.device_id AS device2_id,
    d2.active_power AS device2_power,
    d2.efficiency AS device2_efficiency
FROM (
    -- 生成时间网格
    SELECT DATE_ADD('2025-01-01 10:00:00', INTERVAL seq.n SECOND) AS grid_time
    FROM (
        SELECT a.N + b.N * 10 + c.N * 100 + d.N * 1000 AS n
        FROM (SELECT 0 AS N UNION SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4 UNION SELECT 5 UNION SELECT 6 UNION SELECT 7 UNION SELECT 8 UNION SELECT 9) a
        CROSS JOIN (SELECT 0 AS N UNION SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4 UNION SELECT 5 UNION SELECT 6 UNION SELECT 7 UNION SELECT 8 UNION SELECT 9) b
        CROSS JOIN (SELECT 0 AS N UNION SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4 UNION SELECT 5 UNION SELECT 6 UNION SELECT 7 UNION SELECT 8 UNION SELECT 9) c
        CROSS JOIN (SELECT 0 AS N UNION SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4 UNION SELECT 5 UNION SELECT 6 UNION SELECT 7 UNION SELECT 8 UNION SELECT 9) d
    ) seq
    WHERE DATE_ADD('2025-01-01 10:00:00', INTERVAL seq.n SECOND) <= '2025-01-01 11:00:00'
) time_grid
LEFT JOIN v_aligned_operation_data d1 ON time_grid.grid_time = d1.data_time AND d1.device_id = 1
LEFT JOIN v_aligned_operation_data d2 ON time_grid.grid_time = d2.data_time AND d2.device_id = 2
ORDER BY time_grid.grid_time;
```

---

## 5. 计算值管理

### 5.1 计算版本控制

#### 5.1.1 计算版本管理器
```python
class CalculationVersionManager:
    """
    计算版本管理器
    管理不同版本的计算算法和结果
    """
    
    def __init__(self, db_connection):
        self.db = db_connection
        self.current_versions = self._load_current_versions()
    
    def register_calculation_method(self, method_name: str, version: str, 
                                  algorithm_config: dict) -> bool:
        """
        注册新的计算方法版本
        
        Args:
            method_name: 计算方法名称
            version: 版本号
            algorithm_config: 算法配置
            
        Returns:
            注册是否成功
        """
        try:
            query = """
            INSERT INTO calculation_methods (method_name, version, algorithm_config, is_active)
            VALUES (%s, %s, %s, %s)
            """
            self.db.execute(query, (method_name, version, json.dumps(algorithm_config), True))
            
            # 更新当前版本
            self.current_versions[method_name] = version
            return True
        except Exception as e:
            logger.error(f"注册计算方法失败: {e}")
            return False
    
    def calculate_derived_parameters(self, device_id: int, data_time: datetime,
                                   raw_data: dict, method_version: str = None) -> dict:
        """
        计算派生参数
        
        Args:
            device_id: 设备ID
            data_time: 数据时间
            raw_data: 原始数据
            method_version: 指定计算方法版本
            
        Returns:
            计算结果
        """
        if method_version is None:
            method_version = self.current_versions.get('efficiency_calculation', 'v1.0')
        
        # 获取计算方法配置
        algorithm_config = self._get_algorithm_config('efficiency_calculation', method_version)
        
        # 执行计算
        calculated_data = {
            'efficiency': self._calculate_efficiency(raw_data, algorithm_config),
            'head': self._calculate_head(raw_data, algorithm_config),
            'npsh': self._calculate_npsh(raw_data, algorithm_config),
            'specific_energy': self._calculate_specific_energy(raw_data, algorithm_config)
        }
        
        # 保存计算结果
        self._save_calculated_data(device_id, data_time, calculated_data, 
                                 method_version, raw_data)
        
        return calculated_data
    
    def _calculate_efficiency(self, raw_data: dict, config: dict) -> float:
        """
        计算泵效率
        
        Args:
            raw_data: 原始数据
            config: 算法配置
            
        Returns:
            效率值
        """
        # 水力功率 = ρ × g × Q × H / 1000
        # 其中：ρ=1000kg/m³, g=9.81m/s², Q为流量(m³/s), H为扬程(m)
        
        flow_rate = raw_data.get('flow_rate', 0) / 3600  # m³/h转m³/s
        head = raw_data.get('head', 0)  # 扬程(m)
        active_power = raw_data.get('active_power', 0) * 1000  # kW转W
        
        if active_power <= 0 or flow_rate <= 0:
            return None
        
        # 水力功率(W)
        hydraulic_power = 1000 * 9.81 * flow_rate * head
        
        # 效率
        efficiency = hydraulic_power / active_power
        
        # 限制在合理范围内
        return max(0.0, min(1.0, efficiency))
```

#### 5.1.2 计算方法配置表
```sql
CREATE TABLE calculation_methods (
    id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '方法ID',
    method_name VARCHAR(50) NOT NULL COMMENT '方法名称',
    version VARCHAR(20) NOT NULL COMMENT '版本号',
    algorithm_config JSON NOT NULL COMMENT '算法配置',
    
    -- 版本信息
    is_active BOOLEAN NOT NULL DEFAULT TRUE COMMENT '是否激活',
    is_default BOOLEAN NOT NULL DEFAULT FALSE COMMENT '是否默认版本',
    
    -- 性能指标
    accuracy_score DECIMAL(6,5) DEFAULT NULL COMMENT '准确度分数',
    performance_score DECIMAL(6,5) DEFAULT NULL COMMENT '性能分数',
    
    -- 适用范围
    applicable_device_types JSON DEFAULT NULL COMMENT '适用设备类型',
    parameter_requirements JSON DEFAULT NULL COMMENT '参数要求',
    
    -- 变更信息
    change_description TEXT DEFAULT NULL COMMENT '变更说明',
    previous_version VARCHAR(20) DEFAULT NULL COMMENT '前一版本',
    
    created_at TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3) COMMENT '创建时间',
    updated_at TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3) ON UPDATE CURRENT_TIMESTAMP(3) COMMENT '更新时间',
    created_by VARCHAR(50) DEFAULT NULL COMMENT '创建人',
    
    PRIMARY KEY (id),
    UNIQUE KEY uk_method_version (method_name, version),
    INDEX idx_method_name (method_name),
    INDEX idx_method_active (is_active),
    INDEX idx_method_default (is_default)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='计算方法配置表';
```

### 5.2 数据溯源管理

#### 5.2.1 数据血缘关系表
```sql
CREATE TABLE data_lineage (
    id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '血缘关系ID',
    target_table VARCHAR(50) NOT NULL COMMENT '目标表名',
    target_id BIGINT UNSIGNED NOT NULL COMMENT '目标记录ID',
    source_table VARCHAR(50) NOT NULL COMMENT '源表名',
    source_id BIGINT UNSIGNED NOT NULL COMMENT '源记录ID',
    
    -- 关系信息
    relationship_type ENUM('derived', 'aggregated', 'interpolated', 'corrected') NOT NULL COMMENT '关系类型',
    transformation_method VARCHAR(50) NOT NULL COMMENT '转换方法',
    transformation_params JSON DEFAULT NULL COMMENT '转换参数',
    
    -- 质量信息
    confidence_score DECIMAL(4,3) DEFAULT NULL COMMENT '置信度',
    quality_impact DECIMAL(4,3) DEFAULT NULL COMMENT '质量影响度',
    
    created_at TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3) COMMENT '创建时间',
    
    PRIMARY KEY (id),
    INDEX idx_lineage_target (target_table, target_id),
    INDEX idx_lineage_source (source_table, source_id),
    INDEX idx_lineage_method (transformation_method),
    INDEX idx_lineage_type (relationship_type)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='数据血缘关系表';
```

---

## 6. 存储优化

### 6.1 数据压缩策略

#### 6.1.1 列式存储优化
```python
class DataCompressionManager:
    """
    数据压缩管理器
    优化存储空间和I/O性能
    """
    
    @staticmethod
    def compress_temperature_data(temp_celsius: float) -> int:
        """
        压缩温度数据：将浮点温度转换为整数存储
        
        Args:
            temp_celsius: 摄氏温度
            
        Returns:
            压缩后的整数值（温度*10）
        """
        if temp_celsius is None:
            return None
        return int(round(temp_celsius * 10))
    
    @staticmethod
    def decompress_temperature_data(temp_compressed: int) -> float:
        """
        解压缩温度数据
        
        Args:
            temp_compressed: 压缩的温度值
            
        Returns:
            实际温度值
        """
        if temp_compressed is None:
            return None
        return temp_compressed / 10.0
    
    @staticmethod
    def optimize_decimal_precision(value: float, precision: int = 3) -> Decimal:
        """
        优化小数精度，减少存储空间
        
        Args:
            value: 原始值
            precision: 保留精度
            
        Returns:
            优化后的Decimal值
        """
        if value is None:
            return None
        
        # 根据数值大小动态调整精度
        if abs(value) >= 1000:
            precision = max(1, precision - 1)
        elif abs(value) < 1:
            precision = min(6, precision + 1)
        
        return Decimal(str(round(value, precision)))
```

#### 6.1.2 分区策略优化
```sql
-- 创建分区维护存储过程
DELIMITER //

CREATE PROCEDURE sp_maintain_data_partitions()
BEGIN
    DECLARE v_current_date DATE DEFAULT CURDATE();
    DECLARE v_next_month DATE DEFAULT DATE_ADD(v_current_date, INTERVAL 1 MONTH);
    DECLARE v_partition_name VARCHAR(20);
    DECLARE v_partition_value VARCHAR(30);
    
    -- 生成下个月的分区名和值
    SET v_partition_name = CONCAT('p', DATE_FORMAT(v_next_month, '%Y%m'));
    SET v_partition_value = CONCAT('UNIX_TIMESTAMP(\'', DATE_FORMAT(DATE_ADD(v_next_month, INTERVAL 1 MONTH), '%Y-%m-01 00:00:00'), '\')');
    
    -- 为原始数据表添加分区
    SET @sql = CONCAT('ALTER TABLE raw_operation_data ADD PARTITION (PARTITION ', v_partition_name, ' VALUES LESS THAN (', v_partition_value, '))');
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- 为计算数据表添加分区
    SET @sql = CONCAT('ALTER TABLE calculated_operation_data ADD PARTITION (PARTITION ', v_partition_name, ' VALUES LESS THAN (', v_partition_value, '))');
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    -- 删除6个月前的旧分区（可选）
    -- 这里可以添加删除旧分区的逻辑
    
END //

DELIMITER ;
```

### 6.2 索引优化策略

#### 6.2.1 复合索引设计
```sql
-- 针对常用查询模式的复合索引

-- 1. 设备+时间范围查询索引
CREATE INDEX idx_raw_data_device_time_covering 
ON raw_operation_data (device_id, data_time, active_power, frequency, flow_rate, pressure);

-- 2. 多设备同步查询索引
CREATE INDEX idx_raw_data_time_device_covering 
ON raw_operation_data (data_time, device_id, active_power, efficiency);

-- 3. 质量标记查询索引
CREATE INDEX idx_raw_data_quality_flags 
ON raw_operation_data (quality_flags, device_id, data_time);

-- 4. 计算版本查询索引
CREATE INDEX idx_calc_data_version_covering 
ON calculated_operation_data (calculation_version, device_id, data_time, efficiency, confidence_score);
```

#### 6.2.2 索引使用监控
```sql
-- 创建索引使用情况监控视图
CREATE VIEW v_index_usage_stats AS
SELECT 
    t.TABLE_SCHEMA,
    t.TABLE_NAME,
    t.INDEX_NAME,
    t.CARDINALITY,
    t.SUB_PART,
    t.PACKED,
    t.NULLABLE,
    t.INDEX_TYPE,
    s.COUNT_FETCH,
    s.COUNT_INSERT,
    s.COUNT_UPDATE,
    s.COUNT_DELETE,
    s.SUM_TIMER_FETCH,
    s.SUM_TIMER_INSERT,
    s.SUM_TIMER_UPDATE,
    s.SUM_TIMER_DELETE
FROM information_schema.STATISTICS t
LEFT JOIN performance_schema.table_io_waits_summary_by_index_usage s 
    ON t.TABLE_SCHEMA = s.OBJECT_SCHEMA 
    AND t.TABLE_NAME = s.OBJECT_NAME 
    AND t.INDEX_NAME = s.INDEX_NAME
WHERE t.TABLE_SCHEMA = 'pump_station_optimization'
    AND t.TABLE_NAME IN ('raw_operation_data', 'calculated_operation_data')
ORDER BY s.COUNT_FETCH DESC;
```

---

## 7. 实现规范

### 7.1 数据访问层设计

#### 7.1.1 优化的数据访问类
```python
class OptimizedOperationDataDAO:
    """
    优化的运行数据访问对象
    提供高效的数据读写接口
    """
    
    def __init__(self, db_connection_pool):
        self.db_pool = db_connection_pool
        self.time_grid_manager = TimeGridManager()
        self.compression_manager = DataCompressionManager()
    
    def batch_insert_raw_data(self, device_id: int, data_records: list[dict]) -> dict:
        """
        批量插入原始数据
        
        Args:
            device_id: 设备ID
            data_records: 数据记录列表
            
        Returns:
            插入结果统计
        """
        with self.db_pool.get_connection() as conn:
            cursor = conn.cursor()
            
            # 准备批量插入SQL
            insert_sql = """
            INSERT INTO raw_operation_data (
                device_id, data_time, voltage_a, voltage_b, voltage_c,
                current_a, current_b, current_c, active_power, reactive_power,
                power_factor, frequency, kwh, pressure, flow_rate,
                cumulative_flow, vibration_a, vibration_b,
                temp_ch1, temp_ch2, temp_ch3, temp_ch4,
                temp_ch5, temp_ch6, temp_ch7, temp_ch8,
                quality_flags, data_source
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE
                voltage_a = VALUES(voltage_a),
                voltage_b = VALUES(voltage_b),
                voltage_c = VALUES(voltage_c),
                current_a = VALUES(current_a),
                current_b = VALUES(current_b),
                current_c = VALUES(current_c),
                active_power = VALUES(active_power),
                reactive_power = VALUES(reactive_power),
                power_factor = VALUES(power_factor),
                frequency = VALUES(frequency),
                kwh = VALUES(kwh),
                pressure = VALUES(pressure),
                flow_rate = VALUES(flow_rate),
                cumulative_flow = VALUES(cumulative_flow),
                vibration_a = VALUES(vibration_a),
                vibration_b = VALUES(vibration_b),
                temp_ch1 = VALUES(temp_ch1),
                temp_ch2 = VALUES(temp_ch2),
                temp_ch3 = VALUES(temp_ch3),
                temp_ch4 = VALUES(temp_ch4),
                temp_ch5 = VALUES(temp_ch5),
                temp_ch6 = VALUES(temp_ch6),
                temp_ch7 = VALUES(temp_ch7),
                temp_ch8 = VALUES(temp_ch8),
                quality_flags = VALUES(quality_flags)
            """
            
            # 准备数据
            insert_data = []
            for record in data_records:
                # 时间对齐
                aligned_time = self.time_grid_manager.align_to_grid(record['data_time'])
                
                # 数据压缩
                compressed_data = (
                    device_id,
                    aligned_time,
                    record.get('voltage_a'),
                    record.get('voltage_b'),
                    record.get('voltage_c'),
                    record.get('current_a'),
                    record.get('current_b'),
                    record.get('current_c'),
                    record.get('active_power'),
                    record.get('reactive_power'),
                    record.get('power_factor'),
                    record.get('frequency'),
                    record.get('kwh'),
                    record.get('pressure'),
                    record.get('flow_rate'),
                    record.get('cumulative_flow'),
                    record.get('vibration_a'),
                    record.get('vibration_b'),
                    self.compression_manager.compress_temperature_data(record.get('temp_ch1')),
                    self.compression_manager.compress_temperature_data(record.get('temp_ch2')),
                    self.compression_manager.compress_temperature_data(record.get('temp_ch3')),
                    self.compression_manager.compress_temperature_data(record.get('temp_ch4')),
                    self.compression_manager.compress_temperature_data(record.get('temp_ch5')),
                    self.compression_manager.compress_temperature_data(record.get('temp_ch6')),
                    self.compression_manager.compress_temperature_data(record.get('temp_ch7')),
                    self.compression_manager.compress_temperature_data(record.get('temp_ch8')),
                    record.get('quality_flags', 0),
                    record.get('data_source', 1)
                )
                insert_data.append(compressed_data)
            
            # 执行批量插入
            cursor.executemany(insert_sql, insert_data)
            conn.commit()
            
            return {
                'inserted_count': cursor.rowcount,
                'device_id': device_id,
                'time_range': {
                    'start': min(record['data_time'] for record in data_records),
                    'end': max(record['data_time'] for record in data_records)
                }
            }
    
    def get_aligned_multi_device_data(self, device_ids: list[int], 
                                    start_time: datetime, end_time: datetime,
                                    parameters: list[str] = None) -> pd.DataFrame:
        """
        获取多设备时间对齐数据
        
        Args:
            device_ids: 设备ID列表
            start_time: 开始时间
            end_time: 结束时间
            parameters: 需要的参数列表
            
        Returns:
            对齐的数据DataFrame
        """
        if parameters is None:
            parameters = ['active_power', 'frequency', 'flow_rate', 'pressure', 'efficiency']
        
        # 构建动态SQL
        select_columns = ['time_grid.grid_time']
        join_clauses = []
        
        for i, device_id in enumerate(device_ids):
            alias = f'd{i+1}'
            for param in parameters:
                select_columns.append(f'{alias}.{param} AS device{device_id}_{param}')
            
            join_clauses.append(f"""
            LEFT JOIN v_aligned_operation_data {alias} 
                ON time_grid.grid_time = {alias}.data_time 
                AND {alias}.device_id = {device_id}
            """)
        
        # 生成时间网格
        time_points = self.time_grid_manager.generate_time_range(start_time, end_time)
        time_grid_values = "', '".join([t.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3] for t in time_points])
        
        query = f"""
        WITH time_grid AS (
            SELECT grid_time FROM (
                VALUES {', '.join([f"('{t.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]}')" for t in time_points])}
            ) AS t(grid_time)
        )
        SELECT {', '.join(select_columns)}
        FROM time_grid
        {' '.join(join_clauses)}
        ORDER BY time_grid.grid_time
        """
        
        with self.db_pool.get_connection() as conn:
            return pd.read_sql(query, conn)
```

### 7.2 性能监控

#### 7.2.1 查询性能监控
```python
class PerformanceMonitor:
    """
    性能监控器
    监控数据库查询性能和存储效率
    """
    
    def __init__(self, db_connection):
        self.db = db_connection
        self.metrics = {}
    
    def monitor_query_performance(self, query_name: str, query_sql: str, 
                                params: tuple = None) -> dict:
        """
        监控查询性能
        
        Args:
            query_name: 查询名称
            query_sql: SQL语句
            params: 查询参数
            
        Returns:
            性能指标
        """
        start_time = time.time()
        
        with self.db.cursor() as cursor:
            # 执行查询
            if params:
                cursor.execute(query_sql, params)
            else:
                cursor.execute(query_sql)
            
            results = cursor.fetchall()
            
            # 获取查询计划
            explain_sql = f"EXPLAIN FORMAT=JSON {query_sql}"
            cursor.execute(explain_sql, params)
            explain_result = cursor.fetchone()
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        # 分析性能指标
        performance_metrics = {
            'query_name': query_name,
            'execution_time_seconds': execution_time,
            'rows_returned': len(results),
            'rows_per_second': len(results) / execution_time if execution_time > 0 else 0,
            'explain_plan': json.loads(explain_result[0]) if explain_result else None,
            'timestamp': datetime.now()
        }
        
        # 记录性能指标
        self.metrics[query_name] = performance_metrics
        
        # 记录到日志
        logger.info(f"查询性能监控 - {query_name}: {execution_time:.3f}秒, {len(results)}行")
        
        return performance_metrics
    
    def get_storage_statistics(self) -> dict:
        """
        获取存储统计信息
        
        Returns:
            存储统计数据
        """
        storage_stats = {}
        
        # 表大小统计
        table_size_query = """
        SELECT 
            TABLE_NAME,
            ROUND(((DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024), 2) AS table_size_mb,
            ROUND((DATA_LENGTH / 1024 / 1024), 2) AS data_size_mb,
            ROUND((INDEX_LENGTH / 1024 / 1024), 2) AS index_size_mb,
            TABLE_ROWS
        FROM information_schema.TABLES 
        WHERE TABLE_SCHEMA = 'pump_station_optimization'
            AND TABLE_NAME IN ('raw_operation_data', 'calculated_operation_data')
        """
        
        with self.db.cursor() as cursor:
            cursor.execute(table_size_query)
            table_stats = cursor.fetchall()
            
            for row in table_stats:
                storage_stats[row[0]] = {
                    'total_size_mb': row[1],
                    'data_size_mb': row[2],
                    'index_size_mb': row[3],
                    'row_count': row[4]
                }
        
        return storage_stats
```

---

## 8. 性能测试

### 8.1 基准测试

#### 8.1.1 插入性能测试
```python
import logging
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def test_batch_insert_performance():
    """
    测试批量插入性能
    """
    dao = OptimizedOperationDataDAO(db_pool)
    
    # 生成测试数据
    test_data = []
    base_time = datetime.now()
    
    for i in range(10000):  # 1万条记录
        record = {
            'data_time': base_time + timedelta(seconds=i),
            'voltage_a': 380.0 + random.uniform(-10, 10),
            'voltage_b': 380.0 + random.uniform(-10, 10),
            'voltage_c': 380.0 + random.uniform(-10, 10),
            'current_a': 45.0 + random.uniform(-5, 5),
            'current_b': 45.0 + random.uniform(-5, 5),
            'current_c': 45.0 + random.uniform(-5, 5),
            'active_power': 30.0 + random.uniform(-5, 5),
            'frequency': 50.0 + random.uniform(-2, 2),
            'flow_rate': 100.0 + random.uniform(-10, 10),
            'pressure': 0.5 + random.uniform(-0.1, 0.1),
            'temp_ch1': 25.0 + random.uniform(-5, 5),
            'quality_flags': 0
        }
        test_data.append(record)
    
    # 执行性能测试
    start_time = time.time()
    result = dao.batch_insert_raw_data(device_id=1, data_records=test_data)
    end_time = time.time()
    
    # 计算性能指标
    execution_time = end_time - start_time
    records_per_second = len(test_data) / execution_time
    
    logger.info("批量插入性能测试结果:")
    logger.info(f"  记录数: {len(test_data)}")
    logger.info(f"  执行时间: {execution_time:.3f}秒")
    logger.info(f"  插入速率: {records_per_second:.0f}条/秒")
    logger.info(f"  插入结果: {result}")
    
    assert records_per_second > 1000, "插入性能不达标"

def test_query_performance():
    """
    测试查询性能
    """
    dao = OptimizedOperationDataDAO(db_pool)
    monitor = PerformanceMonitor(db_pool.get_connection())
    
    # 测试多设备同步查询
    start_time = datetime.now() - timedelta(hours=1)
    end_time = datetime.now()
    device_ids = [1, 2, 3]
    
    # 执行查询性能测试
    query_start = time.time()
    result_df = dao.get_aligned_multi_device_data(
        device_ids=device_ids,
        start_time=start_time,
        end_time=end_time,
        parameters=['active_power', 'frequency', 'efficiency']
    )
    query_end = time.time()
    
    # 计算性能指标
    query_time = query_end - query_start
    rows_returned = len(result_df)
    rows_per_second = rows_returned / query_time if query_time > 0 else 0
    
    logger.info("多设备同步查询性能测试结果:")
    logger.info(f"  设备数: {len(device_ids)}")
    logger.info("  时间范围: 1小时")
    logger.info(f"  返回行数: {rows_returned}")
    logger.info(f"  查询时间: {query_time:.3f}秒")
    logger.info(f"  查询速率: {rows_per_second:.0f}行/秒")
    
    assert query_time < 5.0, "查询性能不达标"
    assert rows_per_second > 500, "查询速率不达标"
```

### 8.2 性能基准

#### 8.2.1 性能目标
- **批量插入**: ≥ 5000条/秒
- **单设备查询**: ≤ 100ms（1小时数据）
- **多设备同步查询**: ≤ 500ms（3设备，1小时数据）
- **存储空间**: 比原设计节省 ≥ 30%
- **索引效率**: 查询命中率 ≥ 95%

#### 8.2.2 监控指标
- **存储增长率**: ≤ 100MB/天/设备
- **查询响应时间**: P95 ≤ 200ms
- **数据完整性**: ≥ 99.9%
- **计算准确性**: 误差 ≤ 2%

---

## 总结

本优化设计通过以下关键改进，显著提升了运行数据表的性能和可维护性：

1. **分层存储架构**: 分离原始数据和计算数据，提高查询效率
2. **列式存储优化**: 减少数据冗余，压缩存储空间
3. **时间网格化**: 实现高效的多设备时间对齐查询
4. **计算版本控制**: 支持算法迭代和结果追溯
5. **质量标记位图**: 高效的数据质量管理
6. **智能索引设计**: 针对常用查询模式优化
7. **分区策略**: 提高大数据量下的查询性能
8. **性能监控**: 持续优化和问题发现

这些优化措施将为智慧水务系统提供高效、可靠、可扩展的数据存储和管理能力。