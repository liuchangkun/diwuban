# æ°´æ³µæ€§èƒ½åˆ†æä¸ä¼˜åŒ–ç³»ç»ŸæŠ€æœ¯è§„èŒƒ

> æœ¬è§„èŒƒå®šä¹‰äº†æ°´æ³µæ€§èƒ½åˆ†æä¸ä¼˜åŒ–ç³»ç»Ÿçš„æŠ€æœ¯æ¶æ„ã€æ•°æ®å¤„ç†æµç¨‹ã€æ›²çº¿æ‹Ÿåˆç®—æ³•ã€ä¼˜åŒ–æ–¹æ³•ä»¥åŠç›‘æ§ä¸è¯„ä¼°ä½“ç³»ã€‚

## ğŸ”§ å¦‚ä½•ä½¿ç”¨æœ¬è§„èŒƒæ¨åŠ¨å¼€å‘/æµ‹è¯•/ä¼˜åŒ–
- å¼€å‘å…¥å£ï¼šæŒ‰â€œç³»ç»Ÿæ¶æ„æ–‡æ¡£â€ä¸­çš„ç›®å½•å®ç°æ¨¡å— â†’ [ç³»ç»Ÿæ¶æ„](system_architecture.md#21-é¡¹ç›®ç›®å½•ç»“æ„)
- æ•°æ®è§„èŒƒï¼šæ•°æ®æ¸…æ´—/æ ‡å‡†åŒ–ç»†åˆ™ â†’ [æ•°æ®å¤„ç†è§„èŒƒ](data_processing_specifications.md)
- æ‹Ÿåˆä¸ä¼˜åŒ–ï¼šæœ¬æ–‡ä»¶ç¬¬4ç« ä¸ç¬¬5ç« çš„ç®—æ³•å®ç°æŒ‡å¼• + [ä¼˜åŒ–ç®—æ³•è§„èŒƒ](optimization_algorithms_specifications.md)
- è´¨é‡é—¨æ§›ä¸æµ‹è¯•ï¼šæ•´ä½“æµ‹è¯•æ¡†æ¶ä¸é—¨æ§› â†’ [æµ‹è¯•ä¸è´¨é‡ä¿è¯è§„èŒƒ](testing_quality_assurance_specifications.md)
- å·¥ç¨‹å‚æ•°å…¬å¼ï¼šæ°´æ³µä¸“ç”¨å·¥ç¨‹å…¬å¼ä¸è¾¹ç•Œ â†’ [æ°´æ³µå·¥ç¨‹å‚æ•°è®¡ç®—è§„èŒƒ](pump_engineering_parameter_calculation_specifications.md)
- å®æ—¶é“¾è·¯ï¼šå®æ—¶é‡‡é›†/ç›‘æ§/å‘Šè­¦ â†’ [å®æ—¶å¤„ç†è§„èŒƒ](real_time_processing_specifications.md)

## 1. ç³»ç»Ÿæ¦‚è¿°

### 1.1 é¡¹ç›®èƒŒæ™¯
- **ç›®æ ‡**ï¼šæ„å»ºæ™ºèƒ½åŒ–æ°´æ³µæ€§èƒ½åˆ†æä¸ä¼˜åŒ–ç³»ç»Ÿ
- **èŒƒå›´**ï¼šæ¶µç›–æ€§èƒ½æ›²çº¿æ‹Ÿåˆã€å®æ—¶ç›‘æ§ã€æ•ˆç‡ä¼˜åŒ–ã€é¢„æµ‹æ€§ç»´æŠ¤
- **æ•°æ®æº**ï¼šCSVæ–‡ä»¶æ ¼å¼çš„è¿è¡Œæ•°æ®
- **æŠ€æœ¯æ ˆ**ï¼šPython 3.13.6 + pandas + numpy + scikit-learn

### 1.2 æ ¸å¿ƒåŠŸèƒ½
- æ°´æ³µæ€§èƒ½æ›²çº¿è‡ªåŠ¨æ‹Ÿåˆä¸å»ºæ¨¡
- å®æ—¶è¿è¡ŒçŠ¶æ€ç›‘æ§ä¸å¼‚å¸¸æ£€æµ‹
- å¤šç›®æ ‡ä¼˜åŒ–ç®—æ³•ä¸å‚æ•°è°ƒä¼˜
- é¢„æµ‹æ€§ç»´æŠ¤ä¸æ•…éšœè¯Šæ–­
- æ•°æ®å¯è§†åŒ–ä¸æŠ¥å‘Šç”Ÿæˆ

## 2. ç³»ç»Ÿæ¶æ„

### 2.1 æ¨¡å—æ¶æ„
```
app/
â”œâ”€â”€ core/                    # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ data_loader.py      # æ•°æ®åŠ è½½ä¸é¢„å¤„ç†
â”‚   â”œâ”€â”€ curve_fitting.py    # æ›²çº¿æ‹Ÿåˆç®—æ³•
â”‚   â”œâ”€â”€ optimizer.py        # ä¼˜åŒ–ç®—æ³•
â”‚   â””â”€â”€ monitor.py          # ç›‘æ§æ¨¡å—
â”œâ”€â”€ models/                 # æ•°æ®æ¨¡å‹
â”œâ”€â”€ utils/                  # å·¥å…·å‡½æ•°
â””â”€â”€ config/                 # é…ç½®ç®¡ç†
```

### 2.2 æ•°æ®æµæ¶æ„
1. **æ•°æ®è¾“å…¥**ï¼šCSVæ–‡ä»¶åŠ è½½ â†’ æ•°æ®æ¸…æ´— â†’ æ ¼å¼æ ‡å‡†åŒ–
2. **æ›²çº¿æ‹Ÿåˆ**ï¼šç‰¹æ€§æ›²çº¿å»ºæ¨¡ â†’ å‚æ•°ä¼°è®¡ â†’ æ¨¡å‹éªŒè¯
3. **å®æ—¶ç›‘æ§**ï¼šæ•°æ®é‡‡é›† â†’ çŠ¶æ€åˆ†æ â†’ å¼‚å¸¸å‘Šè­¦
4. **ä¼˜åŒ–è®¡ç®—**ï¼šç›®æ ‡è®¾å®š â†’ ç®—æ³•æ‰§è¡Œ â†’ ç»“æœè¾“å‡º

## 3. æ•°æ®å¤„ç†è§„èŒƒ

### 3.1 æ›²çº¿ç±»å‹å®šä¹‰

#### 3.1.1 åŸºç¡€æ€§èƒ½æ›²çº¿
- **æ‰¬ç¨‹ç‰¹æ€§æ›²çº¿**ï¼šH = f(Q) å…³ç³»å»ºæ¨¡
- **æ•ˆç‡ç‰¹æ€§æ›²çº¿**ï¼šÎ· = f(Q) å…³ç³»å»ºæ¨¡
- **åŠŸç‡ç‰¹æ€§æ›²çº¿**ï¼šP = f(Q) å…³ç³»å»ºæ¨¡

#### 3.1.2 æŒ¯åŠ¨ç‰¹æ€§æ›²çº¿
- **æŒ¯åŠ¨å¹…å€¼æ›²çº¿**ï¼šæŒ¯åŠ¨å¼ºåº¦éšè½¬é€Ÿ/è´Ÿè½½å˜åŒ–
- **é¢‘åŸŸåˆ†ææ›²çº¿**ï¼šæŒ¯åŠ¨é¢‘è°±ç‰¹å¾åˆ†æ

#### 3.1.3 å˜é¢‘æ³µç‰¹æ€§æ›²çº¿
- **å˜é¢‘æ‰¬ç¨‹æ›²çº¿**ï¼šä¸åŒé¢‘ç‡ä¸‹çš„H-Qç‰¹æ€§
- **å˜é¢‘æ•ˆç‡æ›²çº¿**ï¼šé¢‘ç‡å¯¹æ•ˆç‡çš„å½±å“è§„å¾‹

#### 3.1.4 è½¯å¯æ³µç‰¹æ€§æ›²çº¿
- **å¯åŠ¨ç‰¹æ€§æ›²çº¿**ï¼šå¯åŠ¨è¿‡ç¨‹å‚æ•°å˜åŒ–
- **è¿‡æ¸¡ç‰¹æ€§æ›²çº¿**ï¼šè½¯å¯åŠ¨åˆ°ç¨³æ€çš„è¿‡æ¸¡è¿‡ç¨‹

#### 3.1.5 æ³µç»„ç‰¹æ€§æ›²çº¿
- **å¹¶è”ç‰¹æ€§æ›²çº¿**ï¼šå¤šæ³µå¹¶è”è¿è¡Œç‰¹æ€§
- **ä¸²è”ç‰¹æ€§æ›²çº¿**ï¼šå¤šæ³µä¸²è”è¿è¡Œç‰¹æ€§

#### 3.1.6 ç³»ç»Ÿç‰¹æ€§æ›²çº¿
- **é˜»åŠ›ç‰¹æ€§æ›²çº¿**ï¼šç³»ç»Ÿé˜»åŠ›ä¸æµé‡å…³ç³»

### 3.2 æ•°æ®é¢„å¤„ç†

#### 3.2.1 æ•°æ®æ¸…æ´—
- å¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†
- ç¼ºå¤±å€¼æ’è¡¥ç­–ç•¥
- æ•°æ®å¹³æ»‘ä¸æ»¤æ³¢

#### 3.2.2 æ•°æ®æ ‡å‡†åŒ–
- é‡çº²ç»Ÿä¸€å¤„ç†
- æ•°å€¼èŒƒå›´å½’ä¸€åŒ–
- æ—¶é—´åºåˆ—å¯¹é½

## 4. æ›²çº¿æ‹Ÿåˆç®—æ³•

### 4.1 ç‰©ç†æ‹Ÿåˆæ–¹æ³•

#### 4.1.1 æ¬§æ‹‰æ–¹ç¨‹æ‹Ÿåˆæ³•
åŸºäºæ°´æ³µå¶è½®æ¬§æ‹‰æ–¹ç¨‹çš„ç‰©ç†æ‹Ÿåˆæ–¹æ³•ï¼Œé€‚ç”¨äºç¦»å¿ƒæ³µç†è®ºæ‰¬ç¨‹è®¡ç®—å’Œå¶è½®è®¾è®¡å‚æ•°åæ±‚ã€‚

**ç†è®ºåŸºç¡€ï¼š**
```
H_th = (uâ‚‚câ‚‚áµ¤ - uâ‚câ‚áµ¤) / g
```

**æ‹Ÿåˆæ¨¡å‹ï¼š**
```
H = A Ã— uâ‚‚Â² / g - B Ã— QÂ²
```

è¯¦ç»†å®ç°å‚è§ï¼š[æ°´æ³µç‰©ç†ç‰¹æ€§è§„èŒƒ](pump_physical_characteristics_specifications.md)

#### 4.1.2 ç›¸ä¼¼å®šå¾‹æ‹Ÿåˆæ³•
åŸºäºæ°´æ³µç›¸ä¼¼å®šå¾‹çš„æ‹Ÿåˆæ–¹æ³•ï¼Œé€‚ç”¨äºå˜é¢‘æ³µç‰¹æ€§é¢„æµ‹å’Œä¸åŒè½¬é€Ÿå·¥å†µåˆ†æã€‚

**ç›¸ä¼¼å®šå¾‹å…¬å¼ï¼š**
```
Qâ‚/Qâ‚‚ = (nâ‚/nâ‚‚) Ã— (Dâ‚/Dâ‚‚)Â³
Hâ‚/Hâ‚‚ = (nâ‚/nâ‚‚)Â² Ã— (Dâ‚/Dâ‚‚)Â²
Pâ‚/Pâ‚‚ = (Ïâ‚/Ïâ‚‚) Ã— (nâ‚/nâ‚‚)Â³ Ã— (Dâ‚/Dâ‚‚)âµ
```

#### 4.1.3 æ¯”è½¬é€Ÿæ‹Ÿåˆæ³•
åŸºäºæ¯”è½¬é€Ÿç†è®ºçš„æ‹Ÿåˆæ–¹æ³•ï¼Œé€‚ç”¨äºæ³µå‹é€‰æ‹©ä¼˜åŒ–å’Œæ•ˆç‡é¢„æµ‹ã€‚

**æ¯”è½¬é€Ÿå…¬å¼ï¼š**
```
ns = n Ã— âˆšQ / H^(3/4)
```

**æ³µå‹åˆ†ç±»ï¼š**
- ç¦»å¿ƒæ³µï¼šns = 30-150
- æ··æµæ³µï¼šns = 150-500  
- è½´æµæ³µï¼šns = 500-1500

### 4.2 ä¼ ç»Ÿæ•°å­¦æ‹Ÿåˆæ–¹æ³•

#### 4.2.1 å¤šé¡¹å¼æ‹Ÿåˆ
```python
import numpy as np
import logging
from typing import Dict, Optional, List, Any

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class PolynomialFitter:
    """å¤šé¡¹å¼æ›²çº¿æ‹Ÿåˆå™¨
    
    ç”¨äºæ°´æ³µç‰¹æ€§æ›²çº¿çš„å¤šé¡¹å¼æ‹Ÿåˆï¼Œé€‚ç”¨äºæµé‡-æ‰¬ç¨‹ã€æµé‡-åŠŸç‡ç­‰å…³ç³»å»ºæ¨¡ã€‚
    å¸¸ç”¨äºäºŒæ¬¡ã€ä¸‰æ¬¡å¤šé¡¹å¼æ‹Ÿåˆï¼Œå…·æœ‰è®¡ç®—ç®€å•ã€æ”¶æ•›ç¨³å®šçš„ä¼˜ç‚¹ã€‚
    """
    
    def __init__(self, degree: int = 3) -> None:
        """
        åˆå§‹åŒ–å¤šé¡¹å¼æ‹Ÿåˆå™¨
        
        Args:
            degree: å¤šé¡¹å¼é˜¶æ•°ï¼Œé€šå¸¸å–2-4é˜¶ï¼Œè¿‡é«˜å®¹æ˜“è¿‡æ‹Ÿåˆ
            
        Raises:
            ValueError: å½“é˜¶æ•°å°äº1æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        if degree < 1:
            raise ValueError("å¤šé¡¹å¼é˜¶æ•°å¿…é¡»å¤§äºç­‰äº1")
        self.degree = degree
        self.coefficients: Optional[np.ndarray] = None
        self.r_squared: Optional[float] = None

    def fit(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:
        """
        æ‰§è¡Œå¤šé¡¹å¼æ‹Ÿåˆ
        
        Args:
            x: è‡ªå˜é‡æ•°æ®ï¼Œå¦‚æµé‡ (mÂ³/h)
            y: å› å˜é‡æ•°æ®ï¼Œå¦‚æ‰¬ç¨‹ (m) æˆ–åŠŸç‡ (kW)
            
        Returns:
            æ‹Ÿåˆç³»æ•°æ•°ç»„ï¼Œä»é«˜æ¬¡åˆ°ä½æ¬¡æ’åˆ—
            
        Raises:
            ValueError: å½“è¾“å…¥æ•°æ®é•¿åº¦ä¸åŒ¹é…æˆ–åŒ…å«æ— æ•ˆå€¼æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        if len(x) != len(y):
            raise ValueError("xå’Œyæ•°æ®é•¿åº¦å¿…é¡»ç›¸ç­‰")
        if len(x) <= self.degree:
            raise ValueError(f"æ•°æ®ç‚¹æ•°é‡({len(x)})å¿…é¡»å¤§äºå¤šé¡¹å¼é˜¶æ•°({self.degree})")
            
        # æ£€æŸ¥å¹¶ç§»é™¤æ— æ•ˆå€¼
        valid_mask = np.isfinite(x) & np.isfinite(y)
        x_clean, y_clean = x[valid_mask], y[valid_mask]
        
        if len(x_clean) == 0:
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®ç‚¹")
        
        # æ‰§è¡Œå¤šé¡¹å¼æ‹Ÿåˆ
        self.coefficients = np.polyfit(x_clean, y_clean, self.degree)
        
        # è®¡ç®—å†³å®šç³»æ•° RÂ²
        y_pred = np.polyval(self.coefficients, x_clean)
        ss_res = np.sum((y_clean - y_pred) ** 2)
        ss_tot = np.sum((y_clean - np.mean(y_clean)) ** 2)
        self.r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0.0
        
        return self.coefficients
    
    def predict(self, x: np.ndarray) -> np.ndarray:
        """
        é¢„æµ‹æ–°æ•°æ®ç‚¹
        
        Args:
            x: å¾…é¢„æµ‹çš„è‡ªå˜é‡
            
        Returns:
            é¢„æµ‹ç»“æœ
            
        Raises:
            RuntimeError: å½“æ¨¡å‹æœªè®­ç»ƒæ—¶æŠ›å‡ºå¼‚å¸¸
        """
        if self.coefficients is None:
            raise RuntimeError("æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fitæ–¹æ³•")
        return np.polyval(self.coefficients, x)

# æœ€å°å¯è¿è¡Œç¤ºä¾‹
if __name__ == "__main__":
    # æ¨¡æ‹Ÿæ°´æ³µæµé‡-æ‰¬ç¨‹æ•°æ®
    flow = np.array([10, 20, 30, 40, 50, 60])  # æµé‡ mÂ³/h
    head = np.array([120, 115, 108, 98, 85, 70])  # æ‰¬ç¨‹ m
    
    # åˆ›å»ºæ‹Ÿåˆå™¨å¹¶è®­ç»ƒ
    fitter = PolynomialFitter(degree=2)
    coeffs = fitter.fit(flow, head)
    
    logger.info(f"æ‹Ÿåˆç³»æ•°: {coeffs}")
    logger.info(f"RÂ²: {fitter.r_squared:.4f}")
    
    # é¢„æµ‹æ–°æµé‡ç‚¹çš„æ‰¬ç¨‹
    new_flow = np.array([25, 45])
    predicted_head = fitter.predict(new_flow)
    logger.info(f"æµé‡ {new_flow} mÂ³/h å¯¹åº”æ‰¬ç¨‹: {predicted_head} m")
```

#### 4.2.2 å¹‚å‡½æ•°æ‹Ÿåˆ
```python
import numpy as np
import logging
from typing import Dict, Optional

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class PowerFitter:
    """å¹‚å‡½æ•°æ›²çº¿æ‹Ÿåˆå™¨
    
    ç”¨äºæ°´æ³µç›¸ä¼¼å¾‹å’ŒåŠŸç‡ç‰¹æ€§æ›²çº¿æ‹Ÿåˆï¼Œå½¢å¼ä¸º y = a * x^bã€‚
    ç‰¹åˆ«é€‚ç”¨äºæµé‡-åŠŸç‡å…³ç³»(é€šå¸¸bâ‰ˆ3)å’Œç›¸ä¼¼å¾‹è½¬æ¢(è½¬é€Ÿæ¯”ä¾‹å…³ç³»)ã€‚
    """
    
    def __init__(self) -> None:
        """åˆå§‹åŒ–å¹‚å‡½æ•°æ‹Ÿåˆå™¨"""
        self.parameters: Optional[Dict[str, float]] = None
        self.r_squared: Optional[float] = None
    
    def fit(self, x: np.ndarray, y: np.ndarray) -> Dict[str, float]:
        """
        æ‰§è¡Œå¹‚å‡½æ•°æ‹Ÿåˆ y = a * x^b
        
        Args:
            x: è‡ªå˜é‡æ•°æ®ï¼Œå¦‚æµé‡ (mÂ³/h) æˆ–è½¬é€Ÿ (rpm)
            y: å› å˜é‡æ•°æ®ï¼Œå¦‚åŠŸç‡ (kW) æˆ–æ‰¬ç¨‹ (m)
            
        Returns:
            æ‹Ÿåˆå‚æ•°å­—å…¸ï¼ŒåŒ…å« 'a'(ç³»æ•°) å’Œ 'b'(æŒ‡æ•°)
            
        Raises:
            ValueError: å½“è¾“å…¥æ•°æ®åŒ…å«éæ­£å€¼æˆ–é•¿åº¦ä¸åŒ¹é…æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        if len(x) != len(y):
            raise ValueError("xå’Œyæ•°æ®é•¿åº¦å¿…é¡»ç›¸ç­‰")
        
        # æ£€æŸ¥æ­£å€¼çº¦æŸ
        if np.any(x <= 0) or np.any(y <= 0):
            raise ValueError("å¹‚å‡½æ•°æ‹Ÿåˆè¦æ±‚æ‰€æœ‰æ•°æ®ç‚¹å‡ä¸ºæ­£å€¼")
        
        # å¯¹æ•°å˜æ¢ï¼šln(y) = ln(a) + b*ln(x)
        log_x = np.log(x)
        log_y = np.log(y)
        
        # æ£€æŸ¥å˜æ¢åçš„æœ‰æ•ˆæ€§
        valid_mask = np.isfinite(log_x) & np.isfinite(log_y)
        if not np.any(valid_mask):
            raise ValueError("å¯¹æ•°å˜æ¢åæ²¡æœ‰æœ‰æ•ˆæ•°æ®ç‚¹")
        
        log_x_clean = log_x[valid_mask]
        log_y_clean = log_y[valid_mask]
        
        # çº¿æ€§å›å½’æ‹Ÿåˆ
        coeffs = np.polyfit(log_x_clean, log_y_clean, 1)
        b = coeffs[0]  # æŒ‡æ•°
        a = np.exp(coeffs[1])  # ç³»æ•°
        
        # è®¡ç®—å†³å®šç³»æ•° RÂ²
        log_y_pred = coeffs[1] + b * log_x_clean
        ss_res = np.sum((log_y_clean - log_y_pred) ** 2)
        ss_tot = np.sum((log_y_clean - np.mean(log_y_clean)) ** 2)
        self.r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0.0
        
        self.parameters = {"a": a, "b": b}
        return self.parameters
    
    def predict(self, x: np.ndarray) -> np.ndarray:
        """
        é¢„æµ‹æ–°æ•°æ®ç‚¹
        
        Args:
            x: å¾…é¢„æµ‹çš„è‡ªå˜é‡
            
        Returns:
            é¢„æµ‹ç»“æœ
            
        Raises:
            RuntimeError: å½“æ¨¡å‹æœªè®­ç»ƒæ—¶æŠ›å‡ºå¼‚å¸¸
            ValueError: å½“è¾“å…¥åŒ…å«éæ­£å€¼æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        if self.parameters is None:
            raise RuntimeError("æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fitæ–¹æ³•")
        
        if np.any(x <= 0):
            raise ValueError("é¢„æµ‹è¾“å…¥å¿…é¡»ä¸ºæ­£å€¼")
        
        a, b = self.parameters["a"], self.parameters["b"]
        return a * np.power(x, b)

# æœ€å°å¯è¿è¡Œç¤ºä¾‹
if __name__ == "__main__":
    # æ¨¡æ‹Ÿæ°´æ³µæµé‡-åŠŸç‡æ•°æ®ï¼ˆç†è®ºä¸ŠåŠŸç‡ä¸æµé‡çš„ä¸‰æ¬¡æ–¹æˆæ­£æ¯”ï¼‰
    flow = np.array([10, 20, 30, 40, 50, 60])  # æµé‡ mÂ³/h
    power = np.array([0.8, 6.4, 21.6, 51.2, 100, 172.8])  # åŠŸç‡ kW
    
    # åˆ›å»ºæ‹Ÿåˆå™¨å¹¶è®­ç»ƒ
    fitter = PowerFitter()
    params = fitter.fit(flow, power)
    
    logger.info(f"æ‹Ÿåˆå‚æ•°: a={params['a']:.4f}, b={params['b']:.4f}")
    logger.info(f"RÂ²: {fitter.r_squared:.4f}")
    
    # é¢„æµ‹æ–°æµé‡ç‚¹çš„åŠŸç‡
    new_flow = np.array([25, 45])
    predicted_power = fitter.predict(new_flow)
    logger.info(f"æµé‡ {new_flow} mÂ³/h å¯¹åº”åŠŸç‡: {predicted_power:.2f} kW")
    
    # éªŒè¯ç›¸ä¼¼å¾‹ï¼šåŠŸç‡ä¸æµé‡ä¸‰æ¬¡æ–¹å…³ç³»
    logger.info(f"å®é™…æŒ‡æ•° b={params['b']:.2f}ï¼Œç†è®ºå€¼åº”æ¥è¿‘3.0")
```

#### 4.2.3 æŒ‡æ•°å‡½æ•°æ‹Ÿåˆ
```python
import numpy as np
import logging
from typing import Dict, Optional

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class ExponentialFitter:
    """æŒ‡æ•°å‡½æ•°æ›²çº¿æ‹Ÿåˆå™¨
    
    ç”¨äºæ‹Ÿåˆ y = a * exp(b*x) å½¢å¼çš„å…³ç³»ï¼Œé€‚ç”¨äºæŸäº›æ³µçš„è€åŒ–é€€åŒ–æ›²çº¿ã€
    æ³µæˆ¿è®¾å¤‡æ¸©å‡ç­‰è¿‘ä¼¼æŒ‡æ•°å…³ç³»çš„åœºæ™¯ã€‚
    """
    
    def __init__(self) -> None:
        """åˆå§‹åŒ–æŒ‡æ•°æ‹Ÿåˆå™¨"""
        self.parameters: Optional[Dict[str, float]] = None
        self.r_squared: Optional[float] = None
    
    def fit(self, x: np.ndarray, y: np.ndarray) -> Dict[str, float]:
        """
        æ‰§è¡ŒæŒ‡æ•°å‡½æ•°æ‹Ÿåˆ y = a * exp(b*x)
        
        Args:
            x: è‡ªå˜é‡æ•°æ®
            y: å› å˜é‡æ•°æ®ï¼Œå¿…é¡»ä¸ºæ­£å€¼
            
        Returns:
            æ‹Ÿåˆå‚æ•°å­—å…¸ï¼ŒåŒ…å« 'a' ä¸ 'b'
            
        Raises:
            ValueError: å½“yåŒ…å«éæ­£å€¼æˆ–é•¿åº¦ä¸åŒ¹é…æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        if len(x) != len(y):
            raise ValueError("xå’Œyæ•°æ®é•¿åº¦å¿…é¡»ç›¸ç­‰")
        if np.any(y <= 0):
            raise ValueError("æŒ‡æ•°æ‹Ÿåˆè¦æ±‚yä¸ºæ­£å€¼")
        
        # å¯¹æ•°å˜æ¢ï¼šln(y) = ln(a) + b*x
        log_y = np.log(y)
        
        # æ£€æŸ¥æœ‰æ•ˆæ€§
        valid_mask = np.isfinite(x) & np.isfinite(log_y)
        if not np.any(valid_mask):
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆæ•°æ®ç‚¹")
        x_clean = x[valid_mask]
        log_y_clean = log_y[valid_mask]
        
        # çº¿æ€§å›å½’
        coeffs = np.polyfit(x_clean, log_y_clean, 1)
        b = coeffs[0]
        a = np.exp(coeffs[1])
        
        # è®¡ç®—å†³å®šç³»æ•° RÂ²
        log_y_pred = coeffs[1] + b * x_clean
        ss_res = np.sum((log_y_clean - log_y_pred) ** 2)
        ss_tot = np.sum((log_y_clean - np.mean(log_y_clean)) ** 2)
        self.r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0.0
        
        self.parameters = {"a": a, "b": b}
        return self.parameters
    
    def predict(self, x: np.ndarray) -> np.ndarray:
        """
        é¢„æµ‹æ–°æ•°æ®ç‚¹
        
        Args:
            x: å¾…é¢„æµ‹çš„è‡ªå˜é‡
            
        Returns:
            é¢„æµ‹ç»“æœ
            
        Raises:
            RuntimeError: å½“æ¨¡å‹æœªè®­ç»ƒæ—¶æŠ›å‡ºå¼‚å¸¸
        """
        if self.parameters is None:
            raise RuntimeError("æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fitæ–¹æ³•")
        a, b = self.parameters["a"], self.parameters["b"]
        return a * np.exp(b * x)

# æœ€å°å¯è¿è¡Œç¤ºä¾‹
if __name__ == "__main__":
    # æ„é€ æŒ‡æ•°å…³ç³»æ•°æ® y = 2 * exp(0.05x) å¹¶åŠ å…¥è½»å¾®å™ªå£°
    x = np.arange(0, 100, 10)
    true_a, true_b = 2.0, 0.05
    y = true_a * np.exp(true_b * x)
    
    fitter = ExponentialFitter()
    params = fitter.fit(x, y)
    logger.info(f"æ‹Ÿåˆå‚æ•°: a={params['a']:.4f}, b={params['b']:.4f}")
    logger.info(f"RÂ²: {fitter.r_squared:.4f}")
    
    x_new = np.array([15, 55, 95])
    y_pred = fitter.predict(x_new)
    logger.info(f"é¢„æµ‹: x={x_new} -> y={y_pred}")
```

### 4.3 æœºå™¨å­¦ä¹ æ‹Ÿåˆæ–¹æ³•

#### 4.3.1 æ”¯æŒå‘é‡å›å½’
```python
import numpy as np
import logging
from typing import Union
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class SVRFitter:
    """æ”¯æŒå‘é‡å›å½’æ‹Ÿåˆå™¨
    
    ä½¿ç”¨æ”¯æŒå‘é‡æœºè¿›è¡Œéçº¿æ€§å›å½’æ‹Ÿåˆï¼Œé€‚ç”¨äºå¤æ‚çš„æ°´æ³µç‰¹æ€§æ›²çº¿å»ºæ¨¡ã€‚
    ç›¸æ¯”ä¼ ç»Ÿå¤šé¡¹å¼æ‹Ÿåˆï¼ŒSVRèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†éçº¿æ€§å…³ç³»å’Œå™ªå£°æ•°æ®ã€‚
    """
    
    def __init__(self, kernel: str = 'rbf', C: float = 1.0, gamma: Union[str, float] = 'scale') -> None:
        """
        åˆå§‹åŒ–SVRæ‹Ÿåˆå™¨
        
        Args:
            kernel: æ ¸å‡½æ•°ç±»å‹ï¼Œ'rbf'(å¾„å‘åŸºå‡½æ•°)é€‚ç”¨äºå¤§å¤šæ•°æ›²çº¿æ‹Ÿåˆ
            C: æ­£åˆ™åŒ–å‚æ•°ï¼Œå€¼è¶Šå¤§æ¨¡å‹è¶Šå¤æ‚ä½†å¯èƒ½è¿‡æ‹Ÿåˆ
            gamma: æ ¸å‡½æ•°å‚æ•°ï¼Œæ§åˆ¶å•ä¸ªè®­ç»ƒæ ·æœ¬çš„å½±å“èŒƒå›´
            
        æ³¨æ„:
            éœ€è¦å®‰è£… scikit-learn: pip install scikit-learn
        """
        self.scaler_x = StandardScaler()
        self.scaler_y = StandardScaler()
        self.model = SVR(kernel=kernel, C=C, gamma=gamma)
        self.is_fitted = False
        self.r_squared: float = 0.0
        
    def fit(self, x: np.ndarray, y: np.ndarray) -> None:
        """
        è®­ç»ƒSVRæ¨¡å‹
        
        Args:
            x: è‡ªå˜é‡æ•°æ®ï¼Œå¦‚æµé‡ (mÂ³/h)
            y: å› å˜é‡æ•°æ®ï¼Œå¦‚æ‰¬ç¨‹ (m) æˆ–åŠŸç‡ (kW)
            
        Raises:
            ValueError: å½“è¾“å…¥æ•°æ®é•¿åº¦ä¸åŒ¹é…æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        if len(x) != len(y):
            raise ValueError("xå’Œyæ•°æ®é•¿åº¦å¿…é¡»ç›¸ç­‰")
        
        # æ•°æ®æ ‡å‡†åŒ–
        x_scaled = self.scaler_x.fit_transform(x.reshape(-1, 1))
        y_scaled = self.scaler_y.fit_transform(y.reshape(-1, 1)).ravel()
        
        # è®­ç»ƒæ¨¡å‹
        self.model.fit(x_scaled, y_scaled)
        self.is_fitted = True
        
        # è®¡ç®—è®­ç»ƒé›† RÂ²
        y_pred_scaled = self.model.predict(x_scaled)
        self.r_squared = r2_score(y_scaled, y_pred_scaled)
        
    def predict(self, x: np.ndarray) -> np.ndarray:
        """
        é¢„æµ‹æ–°æ•°æ®ç‚¹
        
        Args:
            x: å¾…é¢„æµ‹çš„è‡ªå˜é‡
            
        Returns:
            é¢„æµ‹ç»“æœ
            
        Raises:
            RuntimeError: å½“æ¨¡å‹æœªè®­ç»ƒæ—¶æŠ›å‡ºå¼‚å¸¸
        """
        if not self.is_fitted:
            raise RuntimeError("æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fitæ–¹æ³•")
        
        x_scaled = self.scaler_x.transform(x.reshape(-1, 1))
        y_scaled = self.model.predict(x_scaled)
        return self.scaler_y.inverse_transform(y_scaled.reshape(-1, 1)).ravel()

# æœ€å°å¯è¿è¡Œç¤ºä¾‹
if __name__ == "__main__":
    # æ¨¡æ‹Ÿéçº¿æ€§æ°´æ³µç‰¹æ€§æ›²çº¿æ•°æ®
    flow = np.array([10, 20, 25, 30, 35, 40, 45, 50, 60])  # æµé‡ mÂ³/h
    # éçº¿æ€§æ‰¬ç¨‹ç‰¹æ€§(äºŒæ¬¡+ä¸‰æ¬¡é¡¹)
    head = 120 - 0.8 * flow - 0.01 * flow**2 + 0.0001 * flow**3
    # æ·»åŠ å™ªå£°
    np.random.seed(42)
    head += np.random.normal(0, 1, len(head))
    
    # åˆ›å»ºå¹¶è®­ç»ƒSVRæ¨¡å‹
    svr_fitter = SVRFitter(C=10.0, gamma=0.1)
    svr_fitter.fit(flow, head)
    
    logger.info(f"SVRæ¨¡å‹è®­ç»ƒå®Œæˆï¼ŒRÂ²: {svr_fitter.r_squared:.4f}")
    
    # é¢„æµ‹æ–°æµé‡ç‚¹
    new_flow = np.array([15, 28, 55])
    predicted_head = svr_fitter.predict(new_flow)
    logger.info(f"æµé‡ {new_flow} mÂ³/h å¯¹åº”æ‰¬ç¨‹: {predicted_head:.2f} m")
    
    # å¯¹æ¯”å¤šé¡¹å¼æ‹Ÿåˆ
    from sklearn.preprocessing import PolynomialFeatures
    from sklearn.linear_model import LinearRegression
    poly_features = PolynomialFeatures(degree=2)
    flow_poly = poly_features.fit_transform(flow.reshape(-1, 1))
    poly_model = LinearRegression().fit(flow_poly, head)
    new_flow_poly = poly_features.transform(new_flow.reshape(-1, 1))
    poly_pred = poly_model.predict(new_flow_poly)
    
    logger.info(f"å¤šé¡¹å¼é¢„æµ‹: {poly_pred:.2f} m")
    logger.info("æ³¨æ„: SVRåœ¨å¤„ç†å™ªå£°å’Œéçº¿æ€§æ–¹é¢é€šå¸¸è¡¨ç°æ›´å¥½")
```

### 4.4 æ·±åº¦å­¦ä¹ æ‹Ÿåˆæ–¹æ³•

#### 4.4.1 ç¥ç»ç½‘ç»œæ‹Ÿåˆ
```python
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import logging
from torch.utils.data import DataLoader, TensorDataset
from typing import Tuple, Optional

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class NeuralNetworkFitter(nn.Module):
    """ç¥ç»ç½‘ç»œæ›²çº¿æ‹Ÿåˆå™¨
    
    åŸºäºPyTorchçš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œç”¨äºå¤æ‚éçº¿æ€§æ°´æ³µç‰¹æ€§æ›²çº¿å»ºæ¨¡ã€‚
    é€‚ç”¨äºä¼ ç»Ÿæ•°å­¦æ–¹æ³•éš¾ä»¥å¤„ç†çš„å¤æ‚æ›²çº¿å…³ç³»ï¼Œå¦‚å¤šå³°ã€ä¸è¿ç»­ç­‰æƒ…å†µã€‚
    
    ä¼˜åŠ¿:
        - å¼ºå¤§çš„éçº¿æ€§æ‹Ÿåˆèƒ½åŠ›
        - è‡ªé€‚åº”ç‰¹å¾å­¦ä¹ 
        - å¯¹å™ªå£°æ•°æ®æœ‰ä¸€å®šé²æ£’æ€§
    
    æ³¨æ„:
        éœ€è¦å®‰è£… PyTorch: pip install torch
    """
    
    def __init__(self, hidden_size: int = 64, num_layers: int = 3, dropout_rate: float = 0.1) -> None:
        """
        åˆå§‹åŒ–ç¥ç»ç½‘ç»œç»“æ„
        
        Args:
            hidden_size: éšå±‚ç¥ç»å…ƒæ•°é‡ï¼Œå»ºè®®64-256ä¹‹é—´
            num_layers: éšå±‚æ•°é‡ï¼Œè¿‡å¤šå¯èƒ½è¿‡æ‹Ÿåˆ
            dropout_rate: Dropoutæ¦‚ç‡ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
            
        Raises:
            ValueError: å½“éšå±‚æ•°é‡å°äº1æˆ–dropout_rateä¸åœ¨[0,1]èŒƒå›´å†…
        """
        super().__init__()
        
        if num_layers < 1:
            raise ValueError("éšå±‚æ•°é‡å¿…é¡»è‡³å°‘ä¸º1")
        if not 0 <= dropout_rate <= 1:
            raise ValueError("dropout_rateå¿…é¡»åœ¨[0,1]èŒƒå›´å†…")
        
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.dropout_rate = dropout_rate
        
        # æ„å»ºç½‘ç»œå±‚
        layers = []
        layers.append(nn.Linear(1, hidden_size))
        layers.append(nn.ReLU())
        
        for _ in range(num_layers - 1):
            layers.append(nn.Linear(hidden_size, hidden_size))
            layers.append(nn.ReLU())
            if dropout_rate > 0:
                layers.append(nn.Dropout(dropout_rate))
            
        layers.append(nn.Linear(hidden_size, 1))
        
        self.network = nn.Sequential(*layers)
        self.is_fitted = False
        self.train_loss: float = 0.0
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­è®¡ç®—
        
        Args:
            x: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, 1)
            
        Returns:
            é¢„æµ‹è¾“å‡ºå¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, 1)
        """
        return self.network(x)
    
    def fit(self, x: np.ndarray, y: np.ndarray, epochs: int = 1000, 
            learning_rate: float = 0.001, batch_size: int = 32) -> dict:
        """
        è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹
        
        Args:
            x: è‡ªå˜é‡æ•°æ®ï¼Œå¦‚æµé‡ (mÂ³/h)
            y: å› å˜é‡æ•°æ®ï¼Œå¦‚æ‰¬ç¨‹ (m) æˆ–åŠŸç‡ (kW)
            epochs: è®­ç»ƒè½®æ•°
            learning_rate: å­¦ä¹ ç‡
            batch_size: æ‰¹æ¬¡å¤§å°
            
        Returns:
            è®­ç»ƒç»“æœå­—å…¸ï¼ŒåŒ…å«æœ€ç»ˆæŸå¤±å€¼
            
        Raises:
            ValueError: å½“è¾“å…¥æ•°æ®é•¿åº¦ä¸åŒ¹é…æˆ–ä¸ºç©ºæ—¶
        """
        if len(x) != len(y):
            raise ValueError("xå’Œyæ•°æ®é•¿åº¦å¿…é¡»ç›¸ç­‰")
        if len(x) == 0:
            raise ValueError("è¾“å…¥æ•°æ®ä¸èƒ½ä¸ºç©º")
        
        # æ•°æ®é¢„å¤„ç†
        x_tensor = torch.FloatTensor(x.reshape(-1, 1))
        y_tensor = torch.FloatTensor(y.reshape(-1, 1))
        
        # æ•°æ®æ ‡å‡†åŒ–
        self.x_mean, self.x_std = x_tensor.mean(), x_tensor.std()
        self.y_mean, self.y_std = y_tensor.mean(), y_tensor.std()
        
        x_normalized = (x_tensor - self.x_mean) / (self.x_std + 1e-8)
        y_normalized = (y_tensor - self.y_mean) / (self.y_std + 1e-8)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        dataset = torch.utils.data.TensorDataset(x_normalized, y_normalized)
        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)
        
        # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
        optimizer = optim.Adam(self.parameters(), lr=learning_rate)
        criterion = nn.MSELoss()
        
        # è®­ç»ƒå¾ªç¯
        self.train()
        for epoch in range(epochs):
            epoch_loss = 0.0
            for batch_x, batch_y in dataloader:
                optimizer.zero_grad()
                outputs = self.forward(batch_x)
                loss = criterion(outputs, batch_y)
                loss.backward()
                optimizer.step()
                epoch_loss += loss.item()
            
            if (epoch + 1) % 100 == 0:
                avg_loss = epoch_loss / len(dataloader)
                logger.info(f"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.6f}")
        
        self.train_loss = epoch_loss / len(dataloader)
        self.is_fitted = True
        return {"final_loss": self.train_loss}
    
    def predict(self, x: np.ndarray) -> np.ndarray:
        """
        é¢„æµ‹æ–°æ•°æ®ç‚¹
        
        Args:
            x: å¾…é¢„æµ‹çš„è‡ªå˜é‡
            
        Returns:
            é¢„æµ‹ç»“æœ
            
        Raises:
            RuntimeError: å½“æ¨¡å‹æœªè®­ç»ƒæ—¶
        """
        if not self.is_fitted:
            raise RuntimeError("æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fitæ–¹æ³•")
        
        self.eval()
        with torch.no_grad():
            x_tensor = torch.FloatTensor(x.reshape(-1, 1))
            x_normalized = (x_tensor - self.x_mean) / (self.x_std + 1e-8)
            y_normalized = self.forward(x_normalized)
            y_pred = y_normalized * self.y_std + self.y_mean
            return y_pred.numpy().flatten()

# æœ€å°å¯è¿è¡Œç¤ºä¾‹
if __name__ == "__main__":
    # æ£€æŸ¥PyTorchå¯ç”¨æ€§
    try:
        import torch
        logger.info(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    except ImportError:
        logger.error("è¯·å®‰è£…PyTorch: pip install torch")
        exit(1)
    
    # ç”Ÿæˆå¤æ‚éçº¿æ€§æ•°æ®ï¼ˆæ¨¡æ‹Ÿæ°´æ³µç‰¹æ€§æ›²çº¿ï¼‰
    np.random.seed(42)
    x_train = np.linspace(10, 100, 50)
    # å¤æ‚çš„ä¸‰æ¬¡+æ­£å¼¦æ³¢å½¢
    y_train = 120 - 0.8 * x_train - 0.01 * x_train**2 + 0.0001 * x_train**3 + 5 * np.sin(x_train / 10)
    # æ·»åŠ å™ªå£°
    y_train += np.random.normal(0, 2, len(y_train))
    
    logger.info("å¼€å§‹è®­ç»ƒç¥ç»ç½‘ç»œ...")
    
    # åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
    nn_fitter = NeuralNetworkFitter(hidden_size=32, num_layers=2, dropout_rate=0.1)
    training_result = nn_fitter.fit(x_train, y_train, epochs=500, learning_rate=0.01)
    
    logger.info(f"è®­ç»ƒå®Œæˆï¼Œæœ€ç»ˆæŸå¤±: {training_result['final_loss']:.6f}")
    
    # é¢„æµ‹æµ‹è¯•
    x_test = np.array([25, 50, 75])
    y_pred = nn_fitter.predict(x_test)
    
    logger.info("é¢„æµ‹ç»“æœ:")
    for xi, yi in zip(x_test, y_pred):
        logger.info(f"  æµé‡ {xi} mÂ³/h -> æ‰¬ç¨‹ {yi:.2f} m")
    
    # ä¸å¤šé¡¹å¼æ‹Ÿåˆå¯¹æ¯”
    poly_coeffs = np.polyfit(x_train, y_train, 3)
    y_poly = np.polyval(poly_coeffs, x_test)
    
    logger.info("å¤šé¡¹å¼æ‹Ÿåˆå¯¹æ¯”:")
    for xi, yi, yp in zip(x_test, y_pred, y_poly):
        logger.info(f"  æµé‡ {xi} -> ç¥ç»ç½‘ç»œ: {yi:.2f}, å¤šé¡¹å¼: {yp:.2f}")
    
    logger.info("æ³¨æ„: ç¥ç»ç½‘ç»œåœ¨å¤„ç†å¤æ‚éçº¿æ€§å…³ç³»æ–¹é¢å…·æœ‰ä¼˜åŠ¿")
```

## 5. å®æ—¶ç›‘æ§ç³»ç»Ÿ

### 5.1 æ•°æ®é‡‡é›†
- **é‡‡é›†é¢‘ç‡**ï¼š1Hzï¼ˆæ¯ç§’ä¸€æ¬¡ï¼‰
- **æ•°æ®æº**ï¼šCSVæ–‡ä»¶è‡ªåŠ¨åŠ è½½
- **ç¼“å­˜æœºåˆ¶**ï¼šæ»‘åŠ¨çª—å£ç¼“å­˜æœ€è¿‘1000ä¸ªæ•°æ®ç‚¹

### 5.2 çŠ¶æ€ç›‘æ§
```python
class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç›‘æ§å™¨"""
        self.thresholds = {
            'efficiency_min': 0.6,      # æœ€ä½æ•ˆç‡é˜ˆå€¼
            'vibration_max': 10.0,      # æœ€å¤§æŒ¯åŠ¨é˜ˆå€¼
            'temperature_max': 80.0,    # æœ€é«˜æ¸©åº¦é˜ˆå€¼
        }
        
    def check_performance(self, data: Dict[str, float]) -> Dict[str, bool]:
        """
        æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡
        
        Args:
            data: å½“å‰è¿è¡Œæ•°æ®
            
        Returns:
            æ£€æŸ¥ç»“æœå­—å…¸
        """
        results = {}
        
        # æ•ˆç‡æ£€æŸ¥
        if 'efficiency' in data:
            results['efficiency_normal'] = data['efficiency'] >= self.thresholds['efficiency_min']
            
        # æŒ¯åŠ¨æ£€æŸ¥
        if 'vibration' in data:
            results['vibration_normal'] = data['vibration'] <= self.thresholds['vibration_max']
            
        # æ¸©åº¦æ£€æŸ¥
        if 'temperature' in data:
            results['temperature_normal'] = data['temperature'] <= self.thresholds['temperature_max']
            
        return results
```

## 6. ä¼˜åŒ–ç®—æ³•

### 6.1 å•ç›®æ ‡ä¼˜åŒ–
- **é—ä¼ ç®—æ³•**ï¼šç”¨äºéçº¿æ€§ä¼˜åŒ–é—®é¢˜
- **ç²’å­ç¾¤ä¼˜åŒ–**ï¼šé€‚ç”¨äºè¿ç»­å‚æ•°ä¼˜åŒ–
- **æ¨¡æ‹Ÿé€€ç«**ï¼šå…¨å±€ä¼˜åŒ–ç®—æ³•

### 6.2 å¤šç›®æ ‡ä¼˜åŒ–
- **NSGA-IIç®—æ³•**ï¼šå¸•ç´¯æ‰˜æœ€ä¼˜è§£é›†æ±‚è§£
- **ç›®æ ‡æƒé‡æ³•**ï¼šå¤šç›®æ ‡è½¬å•ç›®æ ‡

## 7. æ•°æ®å­˜å‚¨ä¸ç®¡ç†

### 7.1 æ•°æ®æ¨¡å‹
```python
@dataclass
class PumpOperationData:
    """æ³µè¿è¡Œæ•°æ®æ¨¡å‹"""
    timestamp: datetime
    flow_rate: float        # æµé‡ (mÂ³/h)
    head: float            # æ‰¬ç¨‹ (m)
    efficiency: float      # æ•ˆç‡ (%)
    power: float          # åŠŸç‡ (kW)
    frequency: float      # é¢‘ç‡ (Hz)
    vibration: float      # æŒ¯åŠ¨ (mm/s)
    temperature: float    # æ¸©åº¦ (Â°C)
```

### 7.2 æ•°æ®éªŒè¯
```python
def validate_pump_data(data: PumpOperationData) -> bool:
    """
    éªŒè¯æ³µè¿è¡Œæ•°æ®çš„æœ‰æ•ˆæ€§
    
    Args:
        data: æ³µè¿è¡Œæ•°æ®
        
    Returns:
        æ•°æ®æ˜¯å¦æœ‰æ•ˆ
    """
    # èŒƒå›´æ£€æŸ¥
    if not (0 <= data.efficiency <= 1.0):
        return False
        
    if not (0 <= data.flow_rate <= 1000):
        return False
        
    if not (0 <= data.head <= 200):
        return False
        
    return True
```

## 8. è´¨é‡ä¿è¯

### 8.1 æµ‹è¯•è§„èŒƒ
- **å•å…ƒæµ‹è¯•**ï¼šè¦†ç›–ç‡ â‰¥ 80%
- **é›†æˆæµ‹è¯•**ï¼šå…³é”®è·¯å¾„å…¨è¦†ç›–
- **æ€§èƒ½æµ‹è¯•**ï¼šå“åº”æ—¶é—´ < 1s

### 8.2 ä»£ç è§„èŒƒ
- **ç±»å‹æ³¨è§£**ï¼šæ‰€æœ‰å…¬å¼€å‡½æ•°å¿…é¡»æœ‰ç±»å‹æ³¨è§£
- **æ–‡æ¡£å­—ç¬¦ä¸²**ï¼šä¸­æ–‡æ³¨é‡Šï¼Œè¯´æ˜å‚æ•°ã€è¿”å›å€¼ã€å¼‚å¸¸
- **é”™è¯¯å¤„ç†**ï¼šå…·ä½“å¼‚å¸¸æ•è·ï¼Œé¿å…è£¸except

## 9. éƒ¨ç½²ä¸è¿ç»´

### 9.1 ç¯å¢ƒè¦æ±‚
- **Pythonç‰ˆæœ¬**ï¼š3.13.6
- **ä¾èµ–ç®¡ç†**ï¼špyproject.toml
- **è™šæ‹Ÿç¯å¢ƒ**ï¼š.venv

### 9.2 é…ç½®ç®¡ç†
```python
@dataclass
class SystemConfig:
    """ç³»ç»Ÿé…ç½®ç±»"""
    data_path: str = "data/"
    log_level: str = "INFO"
    max_data_points: int = 10000
    fitting_algorithm: str = "polynomial"
    optimization_method: str = "genetic"
```

## 10. æ—¥å¿—è§„èŒƒ
```python
import logging

# é…ç½®ä¸­æ–‡æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('pump_system.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# ä½¿ç”¨ç¤ºä¾‹
logger.info("å¼€å§‹æ‰§è¡Œæ›²çº¿æ‹Ÿåˆï¼Œæ•°æ®ç‚¹æ•°ï¼š%d", len(data))
logger.error("æ‹Ÿåˆå¤±è´¥ï¼š%s", str(e))
```

---

**å¤‡æ³¨**ï¼šæœ¬è§„èŒƒåŸºäºå®é™…é¡¹ç›®éœ€æ±‚åˆ¶å®šï¼Œç€é‡äºCSVæ•°æ®å¤„ç†å’Œæ€§èƒ½ä¼˜åŒ–ï¼Œåˆ é™¤äº†å¤æ‚çš„ç‰©ç†å»ºæ¨¡æ–¹æ³•ï¼Œç®€åŒ–äº†ç³»ç»Ÿæ¶æ„ï¼Œæ›´é€‚åˆå½“å‰é¡¹ç›®è§„æ¨¡ã€‚