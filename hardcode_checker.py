#!/usr/bin/env python3
"""
ç¡¬ç¼–ç æ£€æŸ¥è„šæœ¬

æœ¬è„šæœ¬ç”¨äºæ‰«æä»£ç åº“ä¸­çš„ç¡¬ç¼–ç é—®é¢˜ï¼Œç¡®ä¿æ‰€æœ‰é…ç½®éƒ½å·²å¤–ç½®åŒ–ã€‚

æ£€æŸ¥é¡¹ç›®ï¼š
1. æ—¶åŒºç¡¬ç¼–ç  (Asia/Shanghai, UTCç­‰)
2. ç›®å½•è·¯å¾„ç¡¬ç¼–ç  (data/, logs/, temp/ç­‰)
3. ç«¯å£å·ç¡¬ç¼–ç  (8000, 3306ç­‰)
4. æ•°æ®åº“è¿æ¥ä¿¡æ¯ç¡¬ç¼–ç 
5. æ–‡ä»¶è·¯å¾„ç¡¬ç¼–ç 
6. IPåœ°å€ç¡¬ç¼–ç 
7. é»˜è®¤å€¼ç¡¬ç¼–ç 
"""

import os
import re
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Pattern
from dataclasses import dataclass

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°sys.path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


@dataclass
class HardcodeIssue:
    """ç¡¬ç¼–ç é—®é¢˜"""
    file_path: str
    line_number: int
    line_content: str
    issue_type: str
    matched_text: str
    severity: str  # "high", "medium", "low"


class HardcodeChecker:
    """ç¡¬ç¼–ç æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.issues: List[HardcodeIssue] = []
        self.excluded_files = {
            "__pycache__",
            ".git",
            ".pytest_cache",
            "test_config_migration.py",
            "hardcode_checker.py",
            ".venv",
            "node_modules",
        }
        self.excluded_extensions = {".pyc", ".pyo", ".log", ".json", ".md", ".txt", ".bat"}
        
        # ç¡¬ç¼–ç æ£€æµ‹è§„åˆ™
        self.hardcode_patterns = {
            "timezone": [
                (r'"Asia/Shanghai"', "æ—¶åŒºç¡¬ç¼–ç ", "medium"),
                (r"'Asia/Shanghai'", "æ—¶åŒºç¡¬ç¼–ç ", "medium"),
                (r'"UTC"(?!\s*#.*é…ç½®)', "æ—¶åŒºç¡¬ç¼–ç ", "medium"),
                (r"'UTC'(?!\s*#.*é…ç½®)", "æ—¶åŒºç¡¬ç¼–ç ", "medium"),
                (r'"Asia/Beijing"', "æ—¶åŒºç¡¬ç¼–ç ", "medium"),
                (r'"America/New_York"', "æ—¶åŒºç¡¬ç¼–ç ", "medium"),
            ],
            "directory_paths": [
                (r'"data"(?!/)', "ç›®å½•è·¯å¾„ç¡¬ç¼–ç ", "high"),
                (r"'data'(?!/)", "ç›®å½•è·¯å¾„ç¡¬ç¼–ç ", "high"), 
                (r'"logs"(?!/)', "ç›®å½•è·¯å¾„ç¡¬ç¼–ç ", "high"),
                (r"'logs'(?!/)", "ç›®å½•è·¯å¾„ç¡¬ç¼–ç ", "high"),
                (r'"temp"(?!/)', "ç›®å½•è·¯å¾„ç¡¬ç¼–ç ", "medium"),
                (r'"backup"(?!/)', "ç›®å½•è·¯å¾„ç¡¬ç¼–ç ", "medium"),
                (r'"configs"(?!/)', "ç›®å½•è·¯å¾„ç¡¬ç¼–ç ", "medium"),
            ],
            "port_numbers": [
                (r':\s*8000\b(?!.*#.*é…ç½®)', "Webç«¯å£ç¡¬ç¼–ç ", "high"),
                (r'port\s*=\s*8000\b', "ç«¯å£ç¡¬ç¼–ç ", "high"),
                (r':\s*3306\b', "æ•°æ®åº“ç«¯å£ç¡¬ç¼–ç ", "high"),
                (r':\s*5432\b', "PostgreSQLç«¯å£ç¡¬ç¼–ç ", "high"),
                (r':\s*6379\b', "Redisç«¯å£ç¡¬ç¼–ç ", "medium"),
            ],
            "database_info": [
                (r'"localhost"(?!\s*#.*é…ç½®)', "æ•°æ®åº“ä¸»æœºç¡¬ç¼–ç ", "high"),
                (r"'localhost'(?!\s*#.*é…ç½®)", "æ•°æ®åº“ä¸»æœºç¡¬ç¼–ç ", "high"),
                (r'"127\.0\.0\.1"', "IPåœ°å€ç¡¬ç¼–ç ", "high"),
                (r'"pump_station_optimization"(?!\s*#.*é…ç½®)', "æ•°æ®åº“åç¡¬ç¼–ç ", "high"),
                (r'"postgres"(?!\s*#.*é…ç½®)', "æ•°æ®åº“ç”¨æˆ·ç¡¬ç¼–ç ", "medium"),
            ],
            "file_paths": [
                (r'"config/data_mapping\.v2\.json"', "æ˜ å°„æ–‡ä»¶è·¯å¾„ç¡¬ç¼–ç ", "high"),
                (r'"config/dim_metric_config\.json"', "é…ç½®æ–‡ä»¶è·¯å¾„ç¡¬ç¼–ç ", "high"),
                (r'Path\("data"', "ç›®å½•è·¯å¾„ç¡¬ç¼–ç ", "high"),
                (r'Path\("logs"', "ç›®å½•è·¯å¾„ç¡¬ç¼–ç ", "high"),
                (r'Path\("temp"', "ç›®å½•è·¯å¾„ç¡¬ç¼–ç ", "medium"),
            ],
            "encoding_and_format": [
                (r'"utf-8"(?!\s*#.*é…ç½®)', "ç¼–ç ç¡¬ç¼–ç ", "low"),
                (r'"json"(?!\s*#.*é…ç½®|.*format)', "æ ¼å¼ç¡¬ç¼–ç ", "low"),
                (r'"csv"(?!\s*#.*é…ç½®)', "æ ¼å¼ç¡¬ç¼–ç ", "low"),
            ],
        }
        
        # å…è®¸çš„ä¾‹å¤–æƒ…å†µï¼ˆé€šè¿‡æ³¨é‡Šæˆ–ä¸Šä¸‹æ–‡åˆ¤æ–­ï¼‰
        self.allowed_contexts = [
            r"#.*é…ç½®",
            r"#.*default",
            r"#.*ç¤ºä¾‹",
            r"#.*example",
            r"test_",
            r"Test",
            r"\.yaml",
            r"\.json",
            r"config",
            r"example",
        ]

    def should_exclude_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ’é™¤è¯¥æ–‡ä»¶"""
        # æ’é™¤ç‰¹å®šç›®å½•
        for excluded in self.excluded_files:
            if excluded in str(file_path):
                return True
        
        # æ’é™¤ç‰¹å®šæ‰©å±•å
        if file_path.suffix in self.excluded_extensions:
            return True
            
        return False

    def is_allowed_context(self, line: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯å…è®¸çš„ä¸Šä¸‹æ–‡"""
        line_lower = line.lower()
        for pattern in self.allowed_contexts:
            if re.search(pattern, line_lower):
                return True
        return False

    def check_file(self, file_path: Path) -> List[HardcodeIssue]:
        """æ£€æŸ¥å•ä¸ªæ–‡ä»¶çš„ç¡¬ç¼–ç é—®é¢˜"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                
            for line_no, line in enumerate(lines, 1):
                line_stripped = line.strip()
                if not line_stripped or line_stripped.startswith('#'):
                    continue
                
                # è·³è¿‡å…è®¸çš„ä¸Šä¸‹æ–‡
                if self.is_allowed_context(line):
                    continue
                
                # æ£€æŸ¥å„ç±»ç¡¬ç¼–ç æ¨¡å¼
                for category, patterns in self.hardcode_patterns.items():
                    for pattern, issue_type, severity in patterns:
                        matches = re.finditer(pattern, line)
                        for match in matches:
                            issue = HardcodeIssue(
                                file_path=str(file_path.relative_to(project_root)),
                                line_number=line_no,
                                line_content=line.strip(),
                                issue_type=issue_type,
                                matched_text=match.group(),
                                severity=severity
                            )
                            issues.append(issue)
                            
        except (UnicodeDecodeError, PermissionError):
            # è·³è¿‡æ— æ³•è¯»å–çš„æ–‡ä»¶
            pass
        
        return issues

    def scan_directory(self, directory: Path) -> None:
        """æ‰«æç›®å½•ä¸­çš„æ‰€æœ‰Pythonæ–‡ä»¶"""
        for file_path in directory.rglob("*.py"):
            if self.should_exclude_file(file_path):
                continue
                
            file_issues = self.check_file(file_path)
            self.issues.extend(file_issues)

    def generate_report(self) -> Dict:
        """ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š"""
        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„
        issues_by_severity = {"high": [], "medium": [], "low": []}
        for issue in self.issues:
            issues_by_severity[issue.severity].append(issue)
        
        # æŒ‰æ–‡ä»¶åˆ†ç»„
        issues_by_file = {}
        for issue in self.issues:
            if issue.file_path not in issues_by_file:
                issues_by_file[issue.file_path] = []
            issues_by_file[issue.file_path].append(issue)
        
        return {
            "total_issues": len(self.issues),
            "by_severity": {k: len(v) for k, v in issues_by_severity.items()},
            "by_file": {k: len(v) for k, v in issues_by_file.items()},
            "issues": [
                {
                    "file": issue.file_path,
                    "line": issue.line_number,
                    "type": issue.issue_type,
                    "matched": issue.matched_text,
                    "severity": issue.severity,
                    "content": issue.line_content[:100] + "..." if len(issue.line_content) > 100 else issue.line_content
                }
                for issue in self.issues
            ]
        }

    def print_report(self) -> None:
        """æ‰“å°æ£€æŸ¥æŠ¥å‘Š"""
        print("ğŸ” ç¡¬ç¼–ç æ£€æŸ¥æŠ¥å‘Š")
        print("=" * 60)
        
        if not self.issues:
            print("âœ… æœªå‘ç°ç¡¬ç¼–ç é—®é¢˜ï¼")
            return
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„ç»Ÿè®¡
        high_issues = [i for i in self.issues if i.severity == "high"]
        medium_issues = [i for i in self.issues if i.severity == "medium"]  
        low_issues = [i for i in self.issues if i.severity == "low"]
        
        print(f"ğŸ“Š å‘ç° {len(self.issues)} ä¸ªæ½œåœ¨ç¡¬ç¼–ç é—®é¢˜:")
        print(f"  ğŸ”´ é«˜é£é™©: {len(high_issues)} ä¸ª")
        print(f"  ğŸŸ¡ ä¸­é£é™©: {len(medium_issues)} ä¸ª") 
        print(f"  ğŸ”µ ä½é£é™©: {len(low_issues)} ä¸ª")
        print()
        
        # æ˜¾ç¤ºé«˜é£é™©é—®é¢˜
        if high_issues:
            print("ğŸ”´ é«˜é£é™©é—®é¢˜ (éœ€è¦ç«‹å³ä¿®å¤):")
            for issue in high_issues[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"  ğŸ“ {issue.file_path}:{issue.line_number}")
                print(f"     ç±»å‹: {issue.issue_type}")
                print(f"     åŒ¹é…: {issue.matched_text}")
                print(f"     ä»£ç : {issue.line_content}")
                print()
        
        # æ˜¾ç¤ºä¸­é£é™©é—®é¢˜
        if medium_issues:
            print("ğŸŸ¡ ä¸­é£é™©é—®é¢˜ (å»ºè®®ä¿®å¤):")
            for issue in medium_issues[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"  ğŸ“ {issue.file_path}:{issue.line_number}")
                print(f"     ç±»å‹: {issue.issue_type}")
                print(f"     åŒ¹é…: {issue.matched_text}")
                print()
        
        # æ–‡ä»¶ç»Ÿè®¡
        file_stats = {}
        for issue in self.issues:
            if issue.file_path not in file_stats:
                file_stats[issue.file_path] = 0
            file_stats[issue.file_path] += 1
        
        if file_stats:
            print("ğŸ“ˆ é—®é¢˜æ–‡ä»¶ç»Ÿè®¡ (Top 5):")
            sorted_files = sorted(file_stats.items(), key=lambda x: x[1], reverse=True)
            for file_path, count in sorted_files[:5]:
                print(f"  ğŸ“ {file_path}: {count} ä¸ªé—®é¢˜")

    def check_hardcodes(self) -> Dict:
        """æ‰§è¡Œç¡¬ç¼–ç æ£€æŸ¥"""
        print("ğŸš€ å¼€å§‹ç¡¬ç¼–ç æ£€æŸ¥...")
        
        # æ‰«æappç›®å½•
        app_dir = project_root / "app"
        if app_dir.exists():
            self.scan_directory(app_dir)
        
        # æ‰«ææ ¹ç›®å½•ä¸‹çš„Pythonæ–‡ä»¶
        for file_path in project_root.glob("*.py"):
            if not self.should_exclude_file(file_path):
                file_issues = self.check_file(file_path)
                self.issues.extend(file_issues)
        
        return self.generate_report()


def main():
    """ä¸»å‡½æ•°"""
    checker = HardcodeChecker()
    report = checker.check_hardcodes()
    
    # æ‰“å°æŠ¥å‘Š
    checker.print_report()
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    import json
    report_path = project_root / "hardcode_check_report.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")
    
    # è¿”å›é€‚å½“çš„é€€å‡ºç 
    high_issues = [i for i in checker.issues if i.severity == "high"]
    sys.exit(1 if high_issues else 0)


if __name__ == "__main__":
    main()