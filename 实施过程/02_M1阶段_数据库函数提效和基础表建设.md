# 泵站优化系统实施过程 - M1阶段：数据库函数提效 + 基础表建设

## 🎯 M1阶段：数据库函数提效 + 基础表建设

### 📊 M1.1 数据库函数提效与视图扩展

#### 任务目标

优化现有 `get_*_by_time_range` 系列函数，提升查询性能20%以上，并扩展视图体系支持未来使用

#### 🤔 设计问题与方案

**问题1：是否需要增加更多视图和函数？**

- **为什么需要：**

  - 现有函数主要面向原始数据查询，缺少聚合、统计、趋势分析类视图
  - M2-M4阶段需要大量的数据聚合和计算，需要高效的数据访问接口
  - 历史数据分析、质量报告、统计特征提取需要专门的视图支持

- **推荐方案：**

  ```sql
  -- 1. 时序聚合视图系列
  CREATE OR REPLACE VIEW v_device_metrics_hourly AS
  SELECT
      station_id, device_id, metric_type,
      date_trunc('hour', metric_time) as hour_bucket,
      avg(metric_value) as avg_value,
      min(metric_value) as min_value,
      max(metric_value) as max_value,
      count(*) as sample_count,
      stddev(metric_value) as std_value
  FROM fact_measurements
  GROUP BY station_id, device_id, metric_type, hour_bucket;

  -- 2. 质量统计视图
  CREATE OR REPLACE VIEW v_data_quality_stats AS
  SELECT
      station_id, device_id, metric_type,
      date_trunc('day', metric_time) as date_bucket,
      count(*) as total_points,
      count(CASE WHEN metric_value IS NULL THEN 1 END) as null_count,
      count(CASE WHEN abs(metric_value - lag(metric_value) OVER w) > 3*stddev(metric_value) OVER w THEN 1 END) as outlier_count
  FROM fact_measurements
  WINDOW w AS (PARTITION BY station_id, device_id, metric_type ORDER BY metric_time ROWS BETWEEN 10 PRECEDING AND CURRENT ROW)
  GROUP BY station_id, device_id, metric_type, date_bucket;

  -- 3. 运行状态聚合视图
  CREATE OR REPLACE VIEW v_pump_operation_summary AS
  SELECT
      station_id, device_id,
      date_trunc('day', metric_time) as date_bucket,
      avg(CASE WHEN metric_type = 'pump_frequency' THEN metric_value END) as avg_frequency,
      avg(CASE WHEN metric_type = 'pump_active_power' THEN metric_value END) as avg_power,
      count(CASE WHEN metric_type = 'pump_frequency' AND metric_value > 5 THEN 1 END) as running_minutes
  FROM fact_measurements
  WHERE metric_type IN ('pump_frequency', 'pump_active_power')
  GROUP BY station_id, device_id, date_bucket;
  ```

- **优点：**

  - 数据库层聚合，大幅减少网络传输和Python内存使用
  - 索引友好，查询性能高
  - 模块化设计，易于维护和扩展

- **缺点：**

  - 增加数据库维护复杂度
  - 视图更新需要考虑向下兼容性

- **替代方案：**

  - 方案A：使用Redis缓存预计算结果
  - 方案B：使用ClickHouse等OLAP数据库做分析层

**问题2：如何支持新泵站、设备、指标的自适应扩展？**

- **为什么重要：**

  - 系统需要支持动态扩展，避免每次新增设备都需要修改代码
  - 不同泵站的设备类型和指标配置可能不同
  - 需要支持热插拔式的配置更新

- **推荐方案：基于配置的动态表结构管理**

  ```python
  # configs/dynamic_schema.yaml
  schema_templates:
    completion_tables:
      base_table: "completion_runs_{station_type}"
      partition_strategy: "monthly"
      indexes:
        - fields: ["station_id", "start_time"]
          type: "btree"
        - fields: ["run_id"]
          type: "hash"

    device_specific_metrics:
      pump_metrics:
        - "pump_frequency"
        - "pump_active_power"
        - "pump_flow_rate"
      valve_metrics:
        - "valve_position"
        - "valve_pressure_drop"

  auto_discovery:
    scan_interval: "1h"
    new_device_template: "device_template_v1"
    metric_validation_rules:
      numeric_range: [-999999, 999999]
      unit_validation: true
  ```

  ```python
  # app/services/schema_manager.py
  class DynamicSchemaManager:
      async def discover_new_devices(self) -> List[DeviceConfig]:
          """扫描数据映射文件，发现新设备配置"""

      async def create_device_tables(self, device_config: DeviceConfig) -> bool:
          """为新设备创建相关表结构和索引"""

      async def update_metric_config(self, new_metrics: List[MetricConfig]) -> bool:
          """动态更新指标配置"""
  ```

- **优点：**

  - 完全自动化，无需人工干预
  - 基于配置文件，易于版本控制和审计
  - 支持回滚和灰度发布

- **缺点：**

  - 系统复杂度增加
  - 需要完善的容错机制

**问题3：如何处理数据量非常大的性能问题？**

- **为什么关键：**

  - 泵站数据通常是秒级采集，数据量巨大
  - M2-M4阶段需要大量的历史数据计算和分析
  - 实时性要求高，不能影响在线业务

- **推荐方案：多层次性能优化策略**

  ```sql
  -- 1. 高级分区策略（时间 + 设备 + 指标三维分区）
  CREATE TABLE fact_measurements_optimized (
      metric_time TIMESTAMP NOT NULL,
      station_id VARCHAR(50) NOT NULL,
      device_id VARCHAR(50) NOT NULL,
      metric_type VARCHAR(50) NOT NULL,
      metric_value DECIMAL(15,6),
      -- ... other fields
  ) PARTITION BY RANGE (metric_time);

  -- 每天一个分区，再按station_id哈希子分区
  CREATE TABLE fact_measurements_y2024m01d01 PARTITION OF fact_measurements_optimized
  FOR VALUES FROM ('2024-01-01') TO ('2024-01-02')
  PARTITION BY HASH (station_id);

  -- 2. 智能索引策略
  -- 最新数据使用B-tree索引
  CREATE INDEX idx_recent_data ON fact_measurements_y2024m01d01
  USING btree (station_id, device_id, metric_time, metric_type);

  -- 历史数据使用BRIN索引
  CREATE INDEX idx_historical_data ON fact_measurements_y2023m01d01
  USING brin (metric_time, station_id);
  ```

  ```python
  # app/services/performance_optimizer.py
  class QueryPerformanceOptimizer:
      async def adaptive_query_routing(self, query_params: QueryParams) -> QueryStrategy:
          """根据查询特征选择最优查询策略"""
          if query_params.time_range.days <= 1:
              return QueryStrategy.REAL_TIME_INDEX
          elif query_params.time_range.days <= 30:
              return QueryStrategy.RECENT_PARTITION
          else:
              return QueryStrategy.HISTORICAL_AGGREGATION

      async def parallel_processing(self, large_query: Query) -> QueryResult:
          """大查询自动分片并行处理"""
          chunks = self.split_query_by_time_and_device(large_query)
          results = await asyncio.gather(*[self.execute_chunk(chunk) for chunk in chunks])
          return self.merge_results(results)
  ```

- **优点：**

  - 针对不同查询模式优化，性能提升显著
  - 支持水平扩展和负载均衡
  - 自动化程度高

- **缺点：**

  - 系统复杂度显著增加
  - 需要专业的DBA支持

- **替代方案：**

  - 方案A：使用TimescaleDB等时序数据库
  - 方案B：引入分布式数据库如ClickHouse
  - 方案C：使用列存储格式如Parquet + DuckDB

#### 工作内容

1. **函数性能分析**

   ```sql
   -- 分析现有函数执行计划
   EXPLAIN ANALYZE SELECT * FROM get_device_metrics_by_time_range(
       'STATION001', 'DEVICE001',
       '2024-01-01'::date, '2024-01-31'::date
   );
   ```

1. **索引优化**

   ```sql
   -- 复合索引优化查询性能
   CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_fact_measurements_compound
   ON fact_measurements (station_id, device_id, metric_time, metric_type);
   ```

1. **函数重构**

   - 减少不必要的JOIN操作
   - 优化WHERE条件顺序
   - 增加结果集缓存机制

#### 实施方法

1. 使用 `EXPLAIN ANALYZE` 分析当前性能瓶颈
1. 针对性创建复合索引
1. 重写函数逻辑，减少扫描数据量
1. 在gateway.py中封装优化后的函数调用

#### 验收标准

- [ ] 查询响应时间提升20%以上
- [ ] 索引命中率达到95%
- [ ] 所有API接口性能测试通过
- [ ] 并发100用户下响应时间\<2秒

### 📋 M1.2 自适应基础表建设

#### 任务目标

创建完整的数据补齐流程追踪表结构，支持自适应扩展和高性能处理

#### 🤔 设计问题与方案

**问题：增加的表是否考虑了未来新增泵站、设备、指标的自适应？**

- **为什么需要自适应：**

  - 不同泵站的设备类型、规模、指标配置差异巨大
  - 单一表结构难以适应所有场景，性能也会受影响
  - 系统需要支持热部署和动态扩展

- **推荐方案：模板化动态表结构**

  ```sql
  -- 1. 基础模板表（不直接使用，仅作为模板）
  CREATE TABLE completion_runs_template (
      run_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
      station_id VARCHAR(50) NOT NULL,
      start_time TIMESTAMP NOT NULL,
      end_time TIMESTAMP NOT NULL,
      strategy VARCHAR(20) NOT NULL CHECK (strategy IN ('FFILL', 'MEAN', 'REG')),
      status VARCHAR(20) DEFAULT 'PENDING',
      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
      completed_at TIMESTAMP,
      metrics_count INTEGER DEFAULT 0,
      filled_count INTEGER DEFAULT 0,
      -- 自适应字段
      station_type VARCHAR(50), -- 泵站类型（供水/排水/加压等）
      device_count INTEGER, -- 设备数量
      config_version VARCHAR(20), -- 配置版本
      custom_params JSONB DEFAULT '{}' -- 自定义参数
  );

  -- 2. 按泵站类型动态创建实际表
  -- completion_runs_water_supply (供水站)
  -- completion_runs_sewage_treatment (污水处理站)
  -- completion_runs_booster (加压站)

  -- 3. 指标类型自适应配置表
  CREATE TABLE metric_type_configs (
      station_type VARCHAR(50),
      device_type VARCHAR(50),
      metric_name VARCHAR(100),
      data_type VARCHAR(20),
      unit VARCHAR(20),
      valid_range_min DECIMAL(15,6),
      valid_range_max DECIMAL(15,6),
      completion_priority INTEGER, -- 补齐优先级
      computation_weight DECIMAL(5,3), -- 计算权重
      is_critical BOOLEAN DEFAULT false, -- 是否关键指标
      custom_rules JSONB DEFAULT '{}'
  );
  ```

  ```python
  # app/services/dynamic_table_manager.py
  class DynamicTableManager:
      def __init__(self):
          self.table_templates = self.load_templates()
          self.station_configs = self.load_station_configs()

      async def create_station_tables(self, station_config: StationConfig) -> bool:
          """为新泵站创建专用表结构"""
          station_type = station_config.station_type
          table_suffix = f"_{station_type}_{station_config.region}"

          for template_name, template_sql in self.table_templates.items():
              actual_table_name = f"{template_name}{table_suffix}"
              # 根据模板创建实际表
              await self.execute_template_sql(template_sql, actual_table_name, station_config)

              # 创建专用索引
              await self.create_optimized_indexes(actual_table_name, station_config)

          return True

      async def auto_discover_metrics(self, station_id: str) -> List[MetricConfig]:
          """自动发现和注册新指标"""
          # 扫描最近的数据来发现新指标
          new_metrics = await self.scan_new_metrics(station_id)

          for metric in new_metrics:
              # 自动推断数据类型和取值范围
              metric_config = await self.infer_metric_config(metric)
              # 注册到配置表
              await self.register_metric_config(metric_config)

          return new_metrics
  ```

- **优点：**

  - 完全自动化，无需人工干预
  - 按站点类型的表结构优化，性能更好
  - 支持不同类型站点的个性化配置
  - JSONB字段支持灵活扩展

- **缺点：**

  - 表数量可能会较多，影响管理复杂度
  - 需要更复杂的路由逻辑
  - 数据迁移和备份更复杂

- **替代方案：**

  - 方案A：使用单一表 + 高效分区策略
  - 方案B：使用NoSQL数据库存储非结构化数据
  - 方案C：使用微服务架构，每个站点独立数据库

#### 工作内容

1. **completion_runs 表**

   ```sql
   CREATE TABLE completion_runs (
       run_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       station_id VARCHAR(50) NOT NULL,
       start_time TIMESTAMP NOT NULL,
       end_time TIMESTAMP NOT NULL,
       strategy VARCHAR(20) NOT NULL CHECK (strategy IN ('FFILL', 'MEAN', 'REG')),
       status VARCHAR(20) DEFAULT 'PENDING',
       created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
       completed_at TIMESTAMP,
       metrics_count INTEGER DEFAULT 0,
       filled_count INTEGER DEFAULT 0
   );
   ```

1. **completion_steps 表**

   ```sql
   CREATE TABLE completion_steps (
       step_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       run_id UUID REFERENCES completion_runs(run_id),
       device_id VARCHAR(50) NOT NULL,
       metric_type VARCHAR(50) NOT NULL,
       original_value DECIMAL(15,6),
       filled_value DECIMAL(15,6),
       fill_method VARCHAR(20) NOT NULL,
       confidence_score DECIMAL(3,2),
       step_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
   );
   ```

1. **completion_audit 表**

   ```sql
   CREATE TABLE completion_audit (
       audit_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       run_id UUID REFERENCES completion_runs(run_id),
       audit_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
       total_gaps INTEGER,
       filled_gaps INTEGER,
       fill_rate DECIMAL(5,2),
       quality_score DECIMAL(3,2),
       audit_details JSONB
   );
   ```

#### 实施方法

1. 在PostgreSQL中执行DDL语句
1. 创建必要的索引和约束
1. 设置分区策略（按月分区）
1. 配置权限和安全设置

#### 验收标准

- [ ] 所有表创建成功，约束生效
- [ ] 索引创建完成，查询性能测试通过
- [ ] 权限配置正确，安全审计通过
- [ ] 分区策略有效，支持月度数据管理
