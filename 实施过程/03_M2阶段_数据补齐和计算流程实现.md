# 泵站优化系统实施过程 - M2阶段：数据补齐 + 计算流程实现

## 🔄 M2阶段：数据补齐 + 计算流程实现

### M2.1 数据补齐核心实现

#### 任务目标

实现 FFILL → MEAN → REG 三层补齐策略，基于时间窗口和数据质量智能选择

#### 🤔 设计问题与方案

**问题3：如何实现单位统一和物理约束？**

- **为什么关键：** 根据docs/缺失数据计算/jjjj.md，必须保证计算结果的物理意义和正确性

- **推荐方案：基于docs的物理约束体系**

  ```python
  # app/services/physics_constraints.py
  @dataclass
  class PhysicsConstraints:
      # 基于jjjj.md的单位统一和约束
      pressure_unit = "MPa"  # 压力统一使用MPa
      flow_unit = "m3/h"     # 流量使用m³/h
      power_unit = "kW"      # 功率使用kW
      frequency_unit = "Hz"  # 频率使用Hz

      # 默认参数（来自jjjj.md）
      g = 9.80665  # m/s²
      water_density = 1000  # kg/m³

      # 阈值参数
      f_thr_default = 3.0  # Hz
      P_thr_percent = 0.05  # P_ref的5%-15%

  class PhysicsValidator:
      def validate_pump_head(self, p_out: float, p_in: float, density: float = 1000.0) -> Tuple[bool, float, str]:
          """扬程计算和验证：H ≈ ((p_out - p_in) × 1e6) / (ρg)"""
          delta_p = p_out - p_in
          if delta_p < -0.1:  # 压差不能过度负值
              return False, 0, "泵出口压力低于进口压力过多"

          head = (delta_p * 1e6) / (density * 9.80665)
          if head < 0 or head > 200:  # 合理扬程范围
              return False, head, f"扬程{head:.2f}m超出合理范围[0,200]m"

          return True, head, "验证通过"

      def validate_pump_efficiency(self, flow_m3h: float, head_m: float, power_kw: float) -> Tuple[bool, float, str]:
          """效率计算和验证：η = (ρg(Q/3600)H) / (P × 1000)"""
          if power_kw <= 0:
              return False, 0, "功率必须大于0"

          flow_m3s = flow_m3h / 3600
          efficiency = (1000 * 9.80665 * flow_m3s * head_m) / (power_kw * 1000)

          if efficiency < 0 or efficiency > 1.0:
              return False, efficiency, f"效率{efficiency:.3f}超出合理范围[0,1]"

          return True, efficiency, "验证通过"
  ```

**问题4：如何利用现有数据库函数提高效率？**

- **推荐方案：基于gateway.py的高效调用策略**
  ```python
  # app/services/computation_pipeline.py
  class EfficientComputationPipeline:
      async def optimized_data_fetch(self, device_id: str, time_range: Tuple[datetime, datetime]) -> Dict:
          """优化的数据获取策略"""
          # 优先使用数据库函数
          result = await self.gateway.get_device_metrics_by_time_range(
              device_id, time_range[0], time_range[1], limit=10000
          )

          # 数据库层预处理，减少Python内存使用
          processed_data = await self.gateway.execute_sql("""
              WITH stable_data AS (
                  SELECT *,
                      abs(metric_value - lag(metric_value) OVER w) as value_change
                  FROM get_device_metrics_by_time_range(%s, %s, %s, %s)
                  WINDOW w AS (PARTITION BY metric_type ORDER BY metric_time)
              )
              SELECT metric_type, metric_time, metric_value
              FROM stable_data
              WHERE value_change < 3 * stddev(metric_value) OVER (PARTITION BY metric_type)
              OR value_change IS NULL
          """, device_id, time_range[0], time_range[1], 10000)

          return processed_data
  ```

#### 工作内容

1. **FFILL策略实现**

   ```python
   async def apply_ffill_strategy(
       self,
       station_id: str,
       device_id: str,
       metric_type: str,
       time_range: Tuple[datetime, datetime]
   ) -> List[FilledDataPoint]:
       """前向填充策略：使用最近的有效值填充"""

       # 1. 获取时间序列数据
       data = await self.gateway.get_device_metrics_by_time_range(
           device_id, time_range[0], time_range[1]
       )

       # 2. 识别缺失值
       missing_points = self._identify_missing_values(data, metric_type)

       # 3. 前向填充
       filled_points = []
       for missing_point in missing_points:
           last_valid_value = self._find_last_valid_value(data, missing_point.timestamp)
           if last_valid_value and self._is_recent_enough(last_valid_value, missing_point, hours=2):
               filled_points.append(FilledDataPoint(
                   timestamp=missing_point.timestamp,
                   metric_type=metric_type,
                   filled_value=last_valid_value.value,
                   method='FFILL',
                   confidence=0.9 if self._is_stable_period(data, missing_point) else 0.7
               ))

       return filled_points
   ```

1. **MEAN策略实现**

   ```python
   async def apply_mean_strategy(
       self,
       station_id: str,
       device_id: str,
       metric_type: str,
       window_hours: int = 24
   ) -> List[FilledDataPoint]:
       """均值填充策略：使用时间窗口内的平均值"""

       # 1. 获取历史数据窗口
       historical_data = await self._get_historical_window(
           device_id, metric_type, window_hours
       )

       # 2. 计算统计特征
       stats = self._calculate_statistical_features(historical_data)

       # 3. 均值填充（排除异常值）
       cleaned_values = self._remove_outliers(historical_data, method='iqr')
       mean_value = np.mean(cleaned_values)
       std_value = np.std(cleaned_values)

       # 4. 置信度计算
       confidence = min(0.9, 1.0 - std_value / mean_value) if mean_value > 0 else 0.5

       return [FilledDataPoint(
           timestamp=missing_point.timestamp,
           metric_type=metric_type,
           filled_value=mean_value,
           method='MEAN',
           confidence=confidence
       )]
   ```

1. **REG策略实现**

   ```python
   async def apply_regression_strategy(
       self,
       station_id: str,
       device_id: str,
       metric_type: str,
       model_params: Dict[str, Any]
   ) -> List[FilledDataPoint]:
       """回归填充策略：基于历史趋势和相关设备数据"""

       # 1. 获取特征数据
       features = await self._get_regression_features(station_id, device_id, metric_type)

       # 2. 特征工程
       processed_features = self._process_features(features)

       # 3. 模型训练或加载
       model = await self._get_or_train_regression_model(
           device_id, metric_type, processed_features
       )

       # 4. 预测缺失值
       predictions = model.predict(processed_features['missing_points'])

       # 5. 置信度评估
       confidence_scores = self._calculate_prediction_confidence(
           model, processed_features['missing_points']
       )

       return [FilledDataPoint(
           timestamp=missing_point.timestamp,
           metric_type=metric_type,
           filled_value=prediction,
           method='REG',
           confidence=confidence
       ) for missing_point, prediction, confidence in zip(
           missing_points, predictions, confidence_scores
       )]
   ```

#### 实施方法

1. 在 `app/services/data_completion.py` 中实现核心逻辑
1. 集成数据库访问层，使用连接池
1. 实现异步处理，支持批量操作
1. 添加详细的日志记录和错误处理

#### 验收标准

- [ ] 三种策略单元测试全部通过
- [ ] 补齐准确率：FFILL>90%, MEAN>85%, REG>80%
- [ ] 处理性能：1万条记录\<30秒
- [ ] 内存使用：峰值\<500MB

### 📋 M2.2 物理约束与8步计算流程

#### 任务目标

基于现场数据驱动方案实现完整的8步计算流程：ingest/validate/gate/select/qcalc/hcalc/etacalc/persist

#### 工作内容

1. **扬程计算**

   ```python
   def calculate_head(p_out: float, p_in: float, density: float = 1000.0) -> float:
       """计算扬程: H ≈ ((p_out - p_in) × 1e6) / (ρg)"""
       return ((p_out - p_in) * 1e6) / (density * 9.81)
   ```

1. **效率计算**

   ```python
   def calculate_efficiency(flow: float, head: float, power: float, density: float = 1000.0) -> float:
       """计算效率: η = (ρg(Q/3600)H) / (P × 1000)"""
       return (density * 9.81 * (flow / 3600) * head) / (power * 1000)
   ```

1. **流量分摊计算**

   ```python
   def calculate_flow_allocation(powers: List[float], frequencies: List[float],
                               alpha: float = 1.0, beta: float = 1.0) -> List[float]:
       """流量分摊: w_i = (P_i^α · f_i^β) / Σ(P_j^α · f_j^β)"""
       weights = []
       total_weight = 0

       for p, f in zip(powers, frequencies):
           if p > 0 and f > 0:  # 只考虑运行中的泵
               weight = (p ** alpha) * (f ** beta)
               weights.append(weight)
               total_weight += weight
           else:
               weights.append(0)

       # 归一化权重
       return [w / total_weight if total_weight > 0 else 0 for w in weights]
   ```

1. **8步计算流程实现**

   ```python
   class ComputationPipeline:
       async def execute_8_step_pipeline(self, station_id: str, time_range: Tuple[datetime, datetime]) -> ComputationResult:
           """执行8步计算管道"""

           # Step 1: Ingest - 数据摄取
           raw_data = await self._step_ingest(station_id, time_range)

           # Step 2: Validate - 数据验证
           validated_data = await self._step_validate(raw_data)

           # Step 3: Gate - 质量门槛
           gated_data = await self._step_gate(validated_data)

           # Step 4: Select - 数据选择
           selected_data = await self._step_select(gated_data)

           # Step 5: QCalc - 流量计算
           flow_results = await self._step_qcalc(selected_data)

           # Step 6: HCalc - 扬程计算
           head_results = await self._step_hcalc(flow_results)

           # Step 7: EtaCalc - 效率计算
           efficiency_results = await self._step_etacalc(head_results)

           # Step 8: Persist - 结果持久化
           persist_result = await self._step_persist(efficiency_results)

           return ComputationResult(
               station_id=station_id,
               time_range=time_range,
               steps_completed=8,
               final_results=efficiency_results,
               computation_metadata=persist_result
           )
   ```

#### 实施方法

1. 在 `app/services/calculation.py` 中实现计算引擎
1. 集成数据补齐服务，确保数据质量
1. 实现计算结果缓存机制
1. 添加计算精度验证和异常处理

#### 验收标准

- [ ] 计算公式准确性验证通过
- [ ] 计算性能：1000台设备数据\<10秒
- [ ] 结果一致性：重复计算误差\<0.1%
- [ ] 异常处理：数据异常时优雅降级

### 📊 M2.3 计算结果存储与追踪

#### 任务目标

建立完整的计算结果存储和追踪体系，支持计算过程审计和结果回溯

#### 工作内容

1. **计算结果表设计**

   ```sql
   CREATE TABLE compute_runs (
       run_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       station_id VARCHAR(50) NOT NULL,
       start_time TIMESTAMP NOT NULL,
       end_time TIMESTAMP NOT NULL,
       pipeline_version VARCHAR(20) NOT NULL,
       status VARCHAR(20) DEFAULT 'RUNNING',
       created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
       completed_at TIMESTAMP,
       total_devices INTEGER DEFAULT 0,
       processed_devices INTEGER DEFAULT 0,
       error_count INTEGER DEFAULT 0
   );

   CREATE TABLE compute_steps (
       step_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       run_id UUID REFERENCES compute_runs(run_id),
       step_name VARCHAR(20) NOT NULL, -- ingest/validate/gate/select/qcalc/hcalc/etacalc/persist
       device_id VARCHAR(50) NOT NULL,
       step_status VARCHAR(20) DEFAULT 'PENDING',
       start_time TIMESTAMP,
       end_time TIMESTAMP,
       input_count INTEGER DEFAULT 0,
       output_count INTEGER DEFAULT 0,
       error_message TEXT,
       step_details JSONB DEFAULT '{}'
   );

   CREATE TABLE compute_metrics (
       metric_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       run_id UUID REFERENCES compute_runs(run_id),
       device_id VARCHAR(50) NOT NULL,
       metric_time TIMESTAMP NOT NULL,
       pump_flow_rate DECIMAL(10,4),
       pump_head DECIMAL(10,4),
       pump_efficiency DECIMAL(5,4),
       calculation_quality DECIMAL(3,2) DEFAULT 1.0,
       data_sources JSONB DEFAULT '{}', -- 记录数据来源和补齐方法
       computed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
   );
   ```

1. **计算过程监控**

   ```python
   class ComputationMonitor:
       async def track_computation_progress(self, run_id: str) -> ComputationProgress:
           """跟踪计算进度"""

       async def analyze_computation_quality(self, run_id: str) -> QualityReport:
           """分析计算质量"""

       async def generate_computation_report(self, run_id: str) -> ComputationReport:
           """生成计算报告"""
   ```

#### 验收标准

- [ ] 所有计算过程可追踪
- [ ] 计算质量评估完整
- [ ] 支持历史结果对比
- [ ] 异常计算自动标记
