# æ³µç«™ä¼˜åŒ–ç³»ç»Ÿå®æ–½è¿‡ç¨‹ - M2é˜¶æ®µï¼šæ•°æ®è¡¥é½ + è®¡ç®—æµç¨‹å®ç°

## ğŸ”„ M2é˜¶æ®µï¼šæ•°æ®è¡¥é½ + è®¡ç®—æµç¨‹å®ç°

### M2.1 æ•°æ®è¡¥é½æ ¸å¿ƒå®ç°

#### ä»»åŠ¡ç›®æ ‡

å®ç° FFILL â†’ MEAN â†’ REG ä¸‰å±‚è¡¥é½ç­–ç•¥ï¼ŒåŸºäºæ—¶é—´çª—å£å’Œæ•°æ®è´¨é‡æ™ºèƒ½é€‰æ‹©

#### ğŸ¤” è®¾è®¡é—®é¢˜ä¸æ–¹æ¡ˆ

**é—®é¢˜3ï¼šå¦‚ä½•å®ç°å•ä½ç»Ÿä¸€å’Œç‰©ç†çº¦æŸï¼Ÿ**

- **ä¸ºä»€ä¹ˆå…³é”®ï¼š** æ ¹æ®docs/ç¼ºå¤±æ•°æ®è®¡ç®—/jjjj.mdï¼Œå¿…é¡»ä¿è¯è®¡ç®—ç»“æœçš„ç‰©ç†æ„ä¹‰å’Œæ­£ç¡®æ€§

- **æ¨èæ–¹æ¡ˆï¼šåŸºäºdocsçš„ç‰©ç†çº¦æŸä½“ç³»**

  ```python
  # app/services/physics_constraints.py
  @dataclass
  class PhysicsConstraints:
      # åŸºäºjjjj.mdçš„å•ä½ç»Ÿä¸€å’Œçº¦æŸ
      pressure_unit = "MPa"  # å‹åŠ›ç»Ÿä¸€ä½¿ç”¨MPa
      flow_unit = "m3/h"     # æµé‡ä½¿ç”¨mÂ³/h
      power_unit = "kW"      # åŠŸç‡ä½¿ç”¨kW
      frequency_unit = "Hz"  # é¢‘ç‡ä½¿ç”¨Hz

      # é»˜è®¤å‚æ•°ï¼ˆæ¥è‡ªjjjj.mdï¼‰
      g = 9.80665  # m/sÂ²
      water_density = 1000  # kg/mÂ³

      # é˜ˆå€¼å‚æ•°
      f_thr_default = 3.0  # Hz
      P_thr_percent = 0.05  # P_refçš„5%-15%

  class PhysicsValidator:
      def validate_pump_head(self, p_out: float, p_in: float, density: float = 1000.0) -> Tuple[bool, float, str]:
          """æ‰¬ç¨‹è®¡ç®—å’ŒéªŒè¯ï¼šH â‰ˆ ((p_out - p_in) Ã— 1e6) / (Ïg)"""
          delta_p = p_out - p_in
          if delta_p < -0.1:  # å‹å·®ä¸èƒ½è¿‡åº¦è´Ÿå€¼
              return False, 0, "æ³µå‡ºå£å‹åŠ›ä½äºè¿›å£å‹åŠ›è¿‡å¤š"

          head = (delta_p * 1e6) / (density * 9.80665)
          if head < 0 or head > 200:  # åˆç†æ‰¬ç¨‹èŒƒå›´
              return False, head, f"æ‰¬ç¨‹{head:.2f}mè¶…å‡ºåˆç†èŒƒå›´[0,200]m"

          return True, head, "éªŒè¯é€šè¿‡"

      def validate_pump_efficiency(self, flow_m3h: float, head_m: float, power_kw: float) -> Tuple[bool, float, str]:
          """æ•ˆç‡è®¡ç®—å’ŒéªŒè¯ï¼šÎ· = (Ïg(Q/3600)H) / (P Ã— 1000)"""
          if power_kw <= 0:
              return False, 0, "åŠŸç‡å¿…é¡»å¤§äº0"

          flow_m3s = flow_m3h / 3600
          efficiency = (1000 * 9.80665 * flow_m3s * head_m) / (power_kw * 1000)

          if efficiency < 0 or efficiency > 1.0:
              return False, efficiency, f"æ•ˆç‡{efficiency:.3f}è¶…å‡ºåˆç†èŒƒå›´[0,1]"

          return True, efficiency, "éªŒè¯é€šè¿‡"
  ```

**é—®é¢˜4ï¼šå¦‚ä½•åˆ©ç”¨ç°æœ‰æ•°æ®åº“å‡½æ•°æé«˜æ•ˆç‡ï¼Ÿ**

- **æ¨èæ–¹æ¡ˆï¼šåŸºäºgateway.pyçš„é«˜æ•ˆè°ƒç”¨ç­–ç•¥**
  ```python
  # app/services/computation_pipeline.py
  class EfficientComputationPipeline:
      async def optimized_data_fetch(self, device_id: str, time_range: Tuple[datetime, datetime]) -> Dict:
          """ä¼˜åŒ–çš„æ•°æ®è·å–ç­–ç•¥"""
          # ä¼˜å…ˆä½¿ç”¨æ•°æ®åº“å‡½æ•°
          result = await self.gateway.get_device_metrics_by_time_range(
              device_id, time_range[0], time_range[1], limit=10000
          )

          # æ•°æ®åº“å±‚é¢„å¤„ç†ï¼Œå‡å°‘Pythonå†…å­˜ä½¿ç”¨
          processed_data = await self.gateway.execute_sql("""
              WITH stable_data AS (
                  SELECT *,
                      abs(metric_value - lag(metric_value) OVER w) as value_change
                  FROM get_device_metrics_by_time_range(%s, %s, %s, %s)
                  WINDOW w AS (PARTITION BY metric_type ORDER BY metric_time)
              )
              SELECT metric_type, metric_time, metric_value
              FROM stable_data
              WHERE value_change < 3 * stddev(metric_value) OVER (PARTITION BY metric_type)
              OR value_change IS NULL
          """, device_id, time_range[0], time_range[1], 10000)

          return processed_data
  ```

#### å·¥ä½œå†…å®¹

1. **FFILLç­–ç•¥å®ç°**

   ```python
   async def apply_ffill_strategy(
       self,
       station_id: str,
       device_id: str,
       metric_type: str,
       time_range: Tuple[datetime, datetime]
   ) -> List[FilledDataPoint]:
       """å‰å‘å¡«å……ç­–ç•¥ï¼šä½¿ç”¨æœ€è¿‘çš„æœ‰æ•ˆå€¼å¡«å……"""

       # 1. è·å–æ—¶é—´åºåˆ—æ•°æ®
       data = await self.gateway.get_device_metrics_by_time_range(
           device_id, time_range[0], time_range[1]
       )

       # 2. è¯†åˆ«ç¼ºå¤±å€¼
       missing_points = self._identify_missing_values(data, metric_type)

       # 3. å‰å‘å¡«å……
       filled_points = []
       for missing_point in missing_points:
           last_valid_value = self._find_last_valid_value(data, missing_point.timestamp)
           if last_valid_value and self._is_recent_enough(last_valid_value, missing_point, hours=2):
               filled_points.append(FilledDataPoint(
                   timestamp=missing_point.timestamp,
                   metric_type=metric_type,
                   filled_value=last_valid_value.value,
                   method='FFILL',
                   confidence=0.9 if self._is_stable_period(data, missing_point) else 0.7
               ))

       return filled_points
   ```

1. **MEANç­–ç•¥å®ç°**

   ```python
   async def apply_mean_strategy(
       self,
       station_id: str,
       device_id: str,
       metric_type: str,
       window_hours: int = 24
   ) -> List[FilledDataPoint]:
       """å‡å€¼å¡«å……ç­–ç•¥ï¼šä½¿ç”¨æ—¶é—´çª—å£å†…çš„å¹³å‡å€¼"""

       # 1. è·å–å†å²æ•°æ®çª—å£
       historical_data = await self._get_historical_window(
           device_id, metric_type, window_hours
       )

       # 2. è®¡ç®—ç»Ÿè®¡ç‰¹å¾
       stats = self._calculate_statistical_features(historical_data)

       # 3. å‡å€¼å¡«å……ï¼ˆæ’é™¤å¼‚å¸¸å€¼ï¼‰
       cleaned_values = self._remove_outliers(historical_data, method='iqr')
       mean_value = np.mean(cleaned_values)
       std_value = np.std(cleaned_values)

       # 4. ç½®ä¿¡åº¦è®¡ç®—
       confidence = min(0.9, 1.0 - std_value / mean_value) if mean_value > 0 else 0.5

       return [FilledDataPoint(
           timestamp=missing_point.timestamp,
           metric_type=metric_type,
           filled_value=mean_value,
           method='MEAN',
           confidence=confidence
       )]
   ```

1. **REGç­–ç•¥å®ç°**

   ```python
   async def apply_regression_strategy(
       self,
       station_id: str,
       device_id: str,
       metric_type: str,
       model_params: Dict[str, Any]
   ) -> List[FilledDataPoint]:
       """å›å½’å¡«å……ç­–ç•¥ï¼šåŸºäºå†å²è¶‹åŠ¿å’Œç›¸å…³è®¾å¤‡æ•°æ®"""

       # 1. è·å–ç‰¹å¾æ•°æ®
       features = await self._get_regression_features(station_id, device_id, metric_type)

       # 2. ç‰¹å¾å·¥ç¨‹
       processed_features = self._process_features(features)

       # 3. æ¨¡å‹è®­ç»ƒæˆ–åŠ è½½
       model = await self._get_or_train_regression_model(
           device_id, metric_type, processed_features
       )

       # 4. é¢„æµ‹ç¼ºå¤±å€¼
       predictions = model.predict(processed_features['missing_points'])

       # 5. ç½®ä¿¡åº¦è¯„ä¼°
       confidence_scores = self._calculate_prediction_confidence(
           model, processed_features['missing_points']
       )

       return [FilledDataPoint(
           timestamp=missing_point.timestamp,
           metric_type=metric_type,
           filled_value=prediction,
           method='REG',
           confidence=confidence
       ) for missing_point, prediction, confidence in zip(
           missing_points, predictions, confidence_scores
       )]
   ```

#### å®æ–½æ–¹æ³•

1. åœ¨ `app/services/data_completion.py` ä¸­å®ç°æ ¸å¿ƒé€»è¾‘
1. é›†æˆæ•°æ®åº“è®¿é—®å±‚ï¼Œä½¿ç”¨è¿æ¥æ± 
1. å®ç°å¼‚æ­¥å¤„ç†ï¼Œæ”¯æŒæ‰¹é‡æ“ä½œ
1. æ·»åŠ è¯¦ç»†çš„æ—¥å¿—è®°å½•å’Œé”™è¯¯å¤„ç†

#### éªŒæ”¶æ ‡å‡†

- [ ] ä¸‰ç§ç­–ç•¥å•å…ƒæµ‹è¯•å…¨éƒ¨é€šè¿‡
- [ ] è¡¥é½å‡†ç¡®ç‡ï¼šFFILL>90%, MEAN>85%, REG>80%
- [ ] å¤„ç†æ€§èƒ½ï¼š1ä¸‡æ¡è®°å½•\<30ç§’
- [ ] å†…å­˜ä½¿ç”¨ï¼šå³°å€¼\<500MB

### ğŸ“‹ M2.2 ç‰©ç†çº¦æŸä¸8æ­¥è®¡ç®—æµç¨‹

#### ä»»åŠ¡ç›®æ ‡

åŸºäºç°åœºæ•°æ®é©±åŠ¨æ–¹æ¡ˆå®ç°å®Œæ•´çš„8æ­¥è®¡ç®—æµç¨‹ï¼šingest/validate/gate/select/qcalc/hcalc/etacalc/persist

#### å·¥ä½œå†…å®¹

1. **æ‰¬ç¨‹è®¡ç®—**

   ```python
   def calculate_head(p_out: float, p_in: float, density: float = 1000.0) -> float:
       """è®¡ç®—æ‰¬ç¨‹: H â‰ˆ ((p_out - p_in) Ã— 1e6) / (Ïg)"""
       return ((p_out - p_in) * 1e6) / (density * 9.81)
   ```

1. **æ•ˆç‡è®¡ç®—**

   ```python
   def calculate_efficiency(flow: float, head: float, power: float, density: float = 1000.0) -> float:
       """è®¡ç®—æ•ˆç‡: Î· = (Ïg(Q/3600)H) / (P Ã— 1000)"""
       return (density * 9.81 * (flow / 3600) * head) / (power * 1000)
   ```

1. **æµé‡åˆ†æ‘Šè®¡ç®—**

   ```python
   def calculate_flow_allocation(powers: List[float], frequencies: List[float],
                               alpha: float = 1.0, beta: float = 1.0) -> List[float]:
       """æµé‡åˆ†æ‘Š: w_i = (P_i^Î± Â· f_i^Î²) / Î£(P_j^Î± Â· f_j^Î²)"""
       weights = []
       total_weight = 0

       for p, f in zip(powers, frequencies):
           if p > 0 and f > 0:  # åªè€ƒè™‘è¿è¡Œä¸­çš„æ³µ
               weight = (p ** alpha) * (f ** beta)
               weights.append(weight)
               total_weight += weight
           else:
               weights.append(0)

       # å½’ä¸€åŒ–æƒé‡
       return [w / total_weight if total_weight > 0 else 0 for w in weights]
   ```

1. **8æ­¥è®¡ç®—æµç¨‹å®ç°**

   ```python
   class ComputationPipeline:
       async def execute_8_step_pipeline(self, station_id: str, time_range: Tuple[datetime, datetime]) -> ComputationResult:
           """æ‰§è¡Œ8æ­¥è®¡ç®—ç®¡é“"""

           # Step 1: Ingest - æ•°æ®æ‘„å–
           raw_data = await self._step_ingest(station_id, time_range)

           # Step 2: Validate - æ•°æ®éªŒè¯
           validated_data = await self._step_validate(raw_data)

           # Step 3: Gate - è´¨é‡é—¨æ§›
           gated_data = await self._step_gate(validated_data)

           # Step 4: Select - æ•°æ®é€‰æ‹©
           selected_data = await self._step_select(gated_data)

           # Step 5: QCalc - æµé‡è®¡ç®—
           flow_results = await self._step_qcalc(selected_data)

           # Step 6: HCalc - æ‰¬ç¨‹è®¡ç®—
           head_results = await self._step_hcalc(flow_results)

           # Step 7: EtaCalc - æ•ˆç‡è®¡ç®—
           efficiency_results = await self._step_etacalc(head_results)

           # Step 8: Persist - ç»“æœæŒä¹…åŒ–
           persist_result = await self._step_persist(efficiency_results)

           return ComputationResult(
               station_id=station_id,
               time_range=time_range,
               steps_completed=8,
               final_results=efficiency_results,
               computation_metadata=persist_result
           )
   ```

#### å®æ–½æ–¹æ³•

1. åœ¨ `app/services/calculation.py` ä¸­å®ç°è®¡ç®—å¼•æ“
1. é›†æˆæ•°æ®è¡¥é½æœåŠ¡ï¼Œç¡®ä¿æ•°æ®è´¨é‡
1. å®ç°è®¡ç®—ç»“æœç¼“å­˜æœºåˆ¶
1. æ·»åŠ è®¡ç®—ç²¾åº¦éªŒè¯å’Œå¼‚å¸¸å¤„ç†

#### éªŒæ”¶æ ‡å‡†

- [ ] è®¡ç®—å…¬å¼å‡†ç¡®æ€§éªŒè¯é€šè¿‡
- [ ] è®¡ç®—æ€§èƒ½ï¼š1000å°è®¾å¤‡æ•°æ®\<10ç§’
- [ ] ç»“æœä¸€è‡´æ€§ï¼šé‡å¤è®¡ç®—è¯¯å·®\<0.1%
- [ ] å¼‚å¸¸å¤„ç†ï¼šæ•°æ®å¼‚å¸¸æ—¶ä¼˜é›…é™çº§

### ğŸ“Š M2.3 è®¡ç®—ç»“æœå­˜å‚¨ä¸è¿½è¸ª

#### ä»»åŠ¡ç›®æ ‡

å»ºç«‹å®Œæ•´çš„è®¡ç®—ç»“æœå­˜å‚¨å’Œè¿½è¸ªä½“ç³»ï¼Œæ”¯æŒè®¡ç®—è¿‡ç¨‹å®¡è®¡å’Œç»“æœå›æº¯

#### å·¥ä½œå†…å®¹

1. **è®¡ç®—ç»“æœè¡¨è®¾è®¡**

   ```sql
   CREATE TABLE compute_runs (
       run_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       station_id VARCHAR(50) NOT NULL,
       start_time TIMESTAMP NOT NULL,
       end_time TIMESTAMP NOT NULL,
       pipeline_version VARCHAR(20) NOT NULL,
       status VARCHAR(20) DEFAULT 'RUNNING',
       created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
       completed_at TIMESTAMP,
       total_devices INTEGER DEFAULT 0,
       processed_devices INTEGER DEFAULT 0,
       error_count INTEGER DEFAULT 0
   );

   CREATE TABLE compute_steps (
       step_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       run_id UUID REFERENCES compute_runs(run_id),
       step_name VARCHAR(20) NOT NULL, -- ingest/validate/gate/select/qcalc/hcalc/etacalc/persist
       device_id VARCHAR(50) NOT NULL,
       step_status VARCHAR(20) DEFAULT 'PENDING',
       start_time TIMESTAMP,
       end_time TIMESTAMP,
       input_count INTEGER DEFAULT 0,
       output_count INTEGER DEFAULT 0,
       error_message TEXT,
       step_details JSONB DEFAULT '{}'
   );

   CREATE TABLE compute_metrics (
       metric_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       run_id UUID REFERENCES compute_runs(run_id),
       device_id VARCHAR(50) NOT NULL,
       metric_time TIMESTAMP NOT NULL,
       pump_flow_rate DECIMAL(10,4),
       pump_head DECIMAL(10,4),
       pump_efficiency DECIMAL(5,4),
       calculation_quality DECIMAL(3,2) DEFAULT 1.0,
       data_sources JSONB DEFAULT '{}', -- è®°å½•æ•°æ®æ¥æºå’Œè¡¥é½æ–¹æ³•
       computed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
   );
   ```

1. **è®¡ç®—è¿‡ç¨‹ç›‘æ§**

   ```python
   class ComputationMonitor:
       async def track_computation_progress(self, run_id: str) -> ComputationProgress:
           """è·Ÿè¸ªè®¡ç®—è¿›åº¦"""

       async def analyze_computation_quality(self, run_id: str) -> QualityReport:
           """åˆ†æè®¡ç®—è´¨é‡"""

       async def generate_computation_report(self, run_id: str) -> ComputationReport:
           """ç”Ÿæˆè®¡ç®—æŠ¥å‘Š"""
   ```

#### éªŒæ”¶æ ‡å‡†

- [ ] æ‰€æœ‰è®¡ç®—è¿‡ç¨‹å¯è¿½è¸ª
- [ ] è®¡ç®—è´¨é‡è¯„ä¼°å®Œæ•´
- [ ] æ”¯æŒå†å²ç»“æœå¯¹æ¯”
- [ ] å¼‚å¸¸è®¡ç®—è‡ªåŠ¨æ ‡è®°
