#!/usr/bin/env python
"""
æµ‹è¯•å¢å¼ºæ—¥å¿—åŠŸèƒ½

è¿™ä¸ªè„šæœ¬ç”¨äºæµ‹è¯•æ–°å¢çš„æ—¥å¿—åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. å‡½æ•°å†…éƒ¨æ‰§è¡Œè¿‡ç¨‹æ—¥å¿—
2. SQLæ‰§è¡Œæ—¥å¿—é…ç½®
3. å…³é”®æŒ‡æ ‡æ—¥å¿—è®°å½•
4. æ¡ä»¶åˆ†æ”¯å’Œå¾ªç¯æ—¥å¿—
"""

import logging
import time
from pathlib import Path
from app.core.config.loader import load_settings
from app.utils.logging_decorators import (
    enhanced_logger,
    create_internal_step_logger,
    log_business_milestone,
    log_data_quality_check,
    log_key_metrics,
    business_logger
)
from app.adapters.logging.init import init_logging


def setup_test_logging():
    """è®¾ç½®æµ‹è¯•æ—¥å¿—ç¯å¢ƒ"""
    settings = load_settings(Path('configs'))
    run_dir = Path('logs/test_run')
    run_dir.mkdir(parents=True, exist_ok=True)
    
    init_logging(settings, run_dir)
    return settings


@enhanced_logger(
    log_entry=True,
    log_exit=True,
    log_parameters=True,
    log_performance=True,
    business_context="æµ‹è¯•å‡½æ•°"
)
def test_basic_logging_features(data_size: int, enable_validation: bool = True):
    """æµ‹è¯•åŸºæœ¬æ—¥å¿—åŠŸèƒ½"""
    logger = logging.getLogger(__name__)
    
    # åˆ›å»ºå†…éƒ¨æ­¥éª¤æ—¥å¿—è®°å½•å™¨
    step_logger = create_internal_step_logger("test_basic_logging_features", logger)
    
    step_logger.step("å¼€å§‹å¤„ç†æ•°æ®", data_size=data_size)
    
    # æ¨¡æ‹Ÿæ•°æ®å¤„ç†
    processed_items = 0
    
    # æµ‹è¯•æ¡ä»¶åˆ†æ”¯æ—¥å¿—
    if enable_validation:
        step_logger.branch("æ•°æ®éªŒè¯å¯ç”¨æ£€æŸ¥", True, "å¯ç”¨æ•°æ®éªŒè¯")
        
        # æµ‹è¯•æ•°æ®éªŒè¯æ—¥å¿—
        step_logger.validation("æ•°æ®å¤§å°æ£€æŸ¥", data_size > 0, f"æ•°æ®å¤§å°: {data_size}")
        step_logger.validation("æ•°æ®èŒƒå›´æ£€æŸ¥", data_size < 10000, f"æ•°æ®åœ¨åˆç†èŒƒå›´å†…")
    else:
        step_logger.branch("æ•°æ®éªŒè¯å¯ç”¨æ£€æŸ¥", False, "è·³è¿‡æ•°æ®éªŒè¯")
    
    # æµ‹è¯•å¾ªç¯è¿­ä»£æ—¥å¿—
    if data_size > 0:
        step_logger.step("å¼€å§‹æ•°æ®å¤„ç†å¾ªç¯")
        iteration_logger = step_logger.iteration_start("æ•°æ®å¤„ç†", data_size)
        
        for i in range(data_size):
            # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            time.sleep(0.001)
            processed_items += 1
            
            # æ¯100é¡¹æ›´æ–°ä¸€æ¬¡è¿›åº¦
            if i % 100 == 0 or i == data_size - 1:
                iteration_logger.update(1 if i == 0 else 100, f"å¤„ç†é¡¹ç›® {i+1}")
        
        iteration_logger.complete(f"æˆåŠŸå¤„ç† {processed_items} é¡¹æ•°æ®")
    
    # æµ‹è¯•æ•°æ®è½¬æ¢æ—¥å¿—
    step_logger.transformation("æ•°æ®æ ¼å¼è½¬æ¢", f"{data_size} åŸå§‹é¡¹", f"{processed_items} å¤„ç†åé¡¹")
    
    # æµ‹è¯•æ£€æŸ¥ç‚¹æ—¥å¿—
    step_logger.checkpoint("æ•°æ®å¤„ç†å®Œæˆ", {
        "input_size": data_size,
        "output_size": processed_items,
        "success_rate": processed_items / data_size if data_size > 0 else 0
    })
    
    return processed_items


@business_logger("æ–‡ä»¶å¤„ç†æ¨¡æ‹Ÿ", enable_progress=True)
def test_file_processing_simulation():
    """æµ‹è¯•æ–‡ä»¶å¤„ç†æ¨¡æ‹Ÿåœºæ™¯"""
    logger = logging.getLogger(__name__)
    
    # è®°å½•ä¸šåŠ¡é‡Œç¨‹ç¢‘
    log_business_milestone("æ–‡ä»¶å¤„ç†å¼€å§‹", {
        "file_count": 5,
        "expected_size": "1MB",
        "processing_mode": "batch"
    }, logger)
    
    # æ¨¡æ‹Ÿæ–‡ä»¶å¤„ç†
    files_processed = 0
    total_size = 0
    
    for i in range(5):
        file_size = (i + 1) * 1024  # æ¨¡æ‹Ÿæ–‡ä»¶å¤§å°
        files_processed += 1
        total_size += file_size
        
        # è®°å½•å…³é”®æŒ‡æ ‡
        log_key_metrics("æ–‡ä»¶å¤„ç†è¿›åº¦", {
            "current_file": i + 1,
            "total_files": 5,
            "file_size_bytes": file_size,
            "cumulative_size_bytes": total_size,
            "progress_percent": (i + 1) / 5 * 100
        }, logger)
        
        time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    
    # æ•°æ®è´¨é‡æ£€æŸ¥
    log_data_quality_check("æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥", True, {
        "files_processed": files_processed,
        "total_size_mb": round(total_size / 1024 / 1024, 2),
        "error_count": 0
    }, logger)
    
    log_business_milestone("æ–‡ä»¶å¤„ç†å®Œæˆ", {
        "files_processed": files_processed,
        "total_size_mb": round(total_size / 1024 / 1024, 2),
        "processing_time_seconds": 0.5
    }, logger)
    
    return files_processed, total_size


def test_sql_execution_logging():
    """æµ‹è¯•SQLæ‰§è¡Œæ—¥å¿—åŠŸèƒ½"""
    from app.utils.logging_decorators import log_sql_execution, log_sql_statement
    
    logger = logging.getLogger("sql")
    
    # æµ‹è¯•SQLè¯­å¥è®°å½•
    test_sql = "SELECT * FROM test_table WHERE id = %s AND status = %s"
    test_params = {"id": 123, "status": "active", "password": "secret123"}
    
    log_sql_statement(test_sql, test_params, logger)
    
    # æµ‹è¯•SQLæ‰§è¡Œç»“æœè®°å½•
    log_sql_execution(
        sql_type="SELECT",
        sql_summary="æŸ¥è¯¢æµ‹è¯•è¡¨ä¸­çš„æ´»è·ƒè®°å½•",
        execution_time_ms=45.67,
        affected_rows=10,
        table_name="test_table",
        parameters=test_params,
        logger=logger
    )
    
    # æµ‹è¯•æ…¢æŸ¥è¯¢è®°å½•
    log_sql_execution(
        sql_type="UPDATE",
        sql_summary="æ‰¹é‡æ›´æ–°ç”¨æˆ·çŠ¶æ€",
        execution_time_ms=1500.0,  # è¶…è¿‡é˜ˆå€¼
        affected_rows=1000,
        table_name="users",
        logger=logger
    )
    
    # æµ‹è¯•SQLæ‰§è¡Œå¤±è´¥è®°å½•
    log_sql_execution(
        sql_type="INSERT",
        sql_summary="æ’å…¥æ–°ç”¨æˆ·è®°å½•",
        execution_time_ms=25.3,
        affected_rows=0,
        table_name="users",
        error="é‡å¤çš„ä¸»é”®å€¼",
        logger=logger
    )


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•å¢å¼ºæ—¥å¿—åŠŸèƒ½...")
    
    # è®¾ç½®æ—¥å¿—ç¯å¢ƒ
    settings = setup_test_logging()
    print("âœ… æ—¥å¿—ç¯å¢ƒè®¾ç½®å®Œæˆ")
    
    # æµ‹è¯•åŸºæœ¬æ—¥å¿—åŠŸèƒ½
    print("\nğŸ“ æµ‹è¯•åŸºæœ¬æ—¥å¿—åŠŸèƒ½...")
    result1 = test_basic_logging_features(500, True)
    print(f"âœ… åŸºæœ¬æ—¥å¿—åŠŸèƒ½æµ‹è¯•å®Œæˆï¼Œå¤„ç†äº† {result1} é¡¹æ•°æ®")
    
    # æµ‹è¯•æ–‡ä»¶å¤„ç†æ¨¡æ‹Ÿ
    print("\nğŸ“ æµ‹è¯•æ–‡ä»¶å¤„ç†æ¨¡æ‹Ÿ...")
    files, size = test_file_processing_simulation()
    print(f"âœ… æ–‡ä»¶å¤„ç†æ¨¡æ‹Ÿå®Œæˆï¼Œå¤„ç†äº† {files} ä¸ªæ–‡ä»¶ï¼Œæ€»å¤§å° {size} å­—èŠ‚")
    
    # æµ‹è¯•SQLæ‰§è¡Œæ—¥å¿—
    print("\nğŸ—ƒï¸ æµ‹è¯•SQLæ‰§è¡Œæ—¥å¿—...")
    test_sql_execution_logging()
    print("âœ… SQLæ‰§è¡Œæ—¥å¿—æµ‹è¯•å®Œæˆ")
    
    # è®°å½•æµ‹è¯•å®Œæˆé‡Œç¨‹ç¢‘
    logger = logging.getLogger(__name__)
    log_business_milestone("å¢å¼ºæ—¥å¿—åŠŸèƒ½æµ‹è¯•å®Œæˆ", {
        "test_cases": 3,
        "basic_logging": "é€šè¿‡",
        "file_processing": "é€šè¿‡", 
        "sql_logging": "é€šè¿‡",
        "config_features": {
            "detailed_logging": len([attr for attr in dir(settings.logging.detailed_logging) if not attr.startswith('_')]),
            "key_metrics": len([attr for attr in dir(settings.logging.key_metrics) if not attr.startswith('_')]),
            "sql_execution": len([attr for attr in dir(settings.logging.sql_execution) if not attr.startswith('_')]),
            "internal_execution": len([attr for attr in dir(settings.logging.internal_execution) if not attr.startswith('_')])
        }
    }, logger)
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼è¯·æŸ¥çœ‹ logs/test_run/ ç›®å½•ä¸‹çš„æ—¥å¿—æ–‡ä»¶")
    print("ğŸ“‹ æ–°å¢åŠŸèƒ½æ€»ç»“ï¼š")
    print("   - âœ… å‡½æ•°å†…éƒ¨æ‰§è¡Œæ­¥éª¤æ—¥å¿—")
    print("   - âœ… æ¡ä»¶åˆ†æ”¯æ‰§è¡Œæ—¥å¿—") 
    print("   - âœ… å¾ªç¯è¿­ä»£è¿›åº¦æ—¥å¿—")
    print("   - âœ… æ•°æ®éªŒè¯å’Œè½¬æ¢æ—¥å¿—")
    print("   - âœ… æ£€æŸ¥ç‚¹å’Œé‡Œç¨‹ç¢‘æ—¥å¿—")
    print("   - âœ… SQLæ‰§è¡Œè¯¦ç»†æ—¥å¿—")
    print("   - âœ… ä¸šåŠ¡å…³é”®æŒ‡æ ‡æ—¥å¿—")
    print("   - âœ… é€šè¿‡ logging.yaml å®Œå…¨é…ç½®æ§åˆ¶")


if __name__ == "__main__":
    main()